<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-loading-bar.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.10.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="swimminghao的学习博客">
<meta property="og:type" content="website">
<meta property="og:title" content="swimminghao&#39;s blog">
<meta property="og:url" content="http://example.com/page/10/index.html">
<meta property="og:site_name" content="swimminghao&#39;s blog">
<meta property="og:description" content="swimminghao的学习博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="swimminghao">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/10/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/10/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>swimminghao's blog</title>
  




<link rel="dns-prefetch" href="waline-server-nu.vercel.app"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.css"><style>
#needsharebutton-postbottom {
  cursor: pointer;
  height: 26px;
  margin-top: 10px;
  position: relative;
}
#needsharebutton-postbottom .btn {
  border: 1px solid $btn-default-border-color;
  border-radius: 3px;
  display: initial;
  padding: 1px 4px;
}
</style>
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">swimminghao's blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">学习博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">30</span></a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">8</span></a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">129</span></a></li>
        <li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="swimminghao"
      src="/images/lion.png">
  <p class="site-author-name" itemprop="name">swimminghao</p>
  <div class="site-description" itemprop="description">swimminghao的学习博客</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">129</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/swimminghao" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;swimminghao" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:swimminghao0@gmail.com" title="E-Mail → mailto:swimminghao0@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/swimminghao" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;swimminghao" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://plus.google.com/yourname" title="Google → https:&#x2F;&#x2F;plus.google.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-google fa-fw"></i>Google</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>


<!-- recent posts -->
    <div class="links-of-blogroll motion-element links-of-blogroll-block">
        <div class="links-of-blogroll-title recent-posts-title">
	    <i class="fa fa-history " aria-hidden="true"></i>
            近期文章
	</div>
	<ul class="links-of-blogroll-list recent-posts-list">
	        <li class="my-links-of-blogroll-item">
		    <a href="/posts/e76dbe41/" title="renren-fast开发文档3.0最新版" target="">
		    renren-fast开发文档3.0最新版
		    </a>
		</li>
	        <li class="my-links-of-blogroll-item">
		    <a href="/posts/61fc1c97/" title="emby-server媒体库硬链接" target="">
		    emby-server媒体库硬链接
		    </a>
		</li>
	        <li class="my-links-of-blogroll-item">
		    <a href="/posts/55ff28b4/" title="Spring Boot 2.0 集成 redis" target="">
		    Spring Boot 2.0 集成 redis
		    </a>
		</li>
	        <li class="my-links-of-blogroll-item">
		    <a href="/posts/79603c56/" title="超详细从0开始搭建 Spring Boot 项目" target="">
		    超详细从0开始搭建 Spring Boot 项目
		    </a>
		</li>
	        <li class="my-links-of-blogroll-item">
		    <a href="/posts/30ffdeaa/" title="xkeysnail for ubuntu 键盘映射" target="">
		    xkeysnail for ubuntu 键盘映射
		    </a>
		</li>
	</ul>
    </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/3973d3db/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lion.png">
      <meta itemprop="name" content="swimminghao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="swimminghao's blog">
      <meta itemprop="description" content="swimminghao的学习博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | swimminghao's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/3973d3db/" class="post-title-link" itemprop="url">26、【对线面试官】双亲委派机制</a>
        </h2>

        <div class="post-meta-container">

          

          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 19:57:47" itemprop="dateCreated datePublished" datetime="2022-02-28T19:57:47+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-03-10 09:48:07" itemprop="dateModified" datetime="2022-03-10T09:48:07+08:00">2022-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">技术</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/posts/3973d3db/#waline-comments" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" id="/posts/3973d3db/" data-xid="/posts/3973d3db/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="26、【对线面试官】双亲委派机制"><a href="#26、【对线面试官】双亲委派机制" class="headerlink" title="26、【对线面试官】双亲委派机制"></a>26、【对线面试官】双亲委派机制</h1><h2 id="接着上次的话题吧，要不你来详细讲讲双亲委派机制？"><a href="#接着上次的话题吧，要不你来详细讲讲双亲委派机制？" class="headerlink" title="接着上次的话题吧，要不你来详细讲讲双亲委派机制？"></a>接着上次的话题吧，要不你来详细讲讲双亲委派机制？</h2><ul>
<li>上次提到了：class文件是通过「类加载器」装载至JVM中的</li>
<li>为了防止内存中存在多份同样的字节码，使用了双亲委派机制（它不会自己去尝试加载类，而是把请求委托给父加载器去完成，依次向上）</li>
<li>JDK中的本地方法类一般由根加载器（Bootstrp loader）装载JDK中内部实现的扩展类一般由扩展加载器（ExtClassLoader）实现装载入而程序中的类文件则由系统加载器（AppClassLoader）实现装载。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/aWnCRl_20211229133925.png" alt="java类加载结构图"></p>
<h2 id="打破双亲委派机制是什么意思？"><a href="#打破双亲委派机制是什么意思？" class="headerlink" title="打破双亲委派机制是什么意思？"></a>打破双亲委派机制是什么意思？</h2><ul>
<li>很好理解啊，意思就是：只要我加载类的时候，不是从App ClassLoader-》ExtClassLoader-&gt;BootStrap ClassLoader这个顺序找，那就算是打破了啊</li>
<li>因为加载classi核心的方法在LoaderClass类的loadClass方法上（双亲委派机制的核心实现）</li>
<li>那只要我自定义个ClassLoader，重写loadClass方法（不依照往上开始寻找类加载器），那就算是打破双亲委派机制了。</li>
</ul>
<h2 id="那你知道有哪个场景破坏了双亲委派机制吗？"><a href="#那你知道有哪个场景破坏了双亲委派机制吗？" class="headerlink" title="那你知道有哪个场景破坏了双亲委派机制吗？"></a>那你知道有哪个场景破坏了双亲委派机制吗？</h2><ul>
<li>tomcat</li>
<li>部署项目时，会把war包放到tomcat的webapp下，这意味着一个tomcat可以运行多个Web应用程序<ul>
<li>那假设我现在有两个Web应用程序，它们都有一个类，叫做User，并且它们的类全限定名都一样，比如都是com.yyy.User。但是他们的具体实现是不一样的</li>
<li>那么Tomcat是如何保证它们是不会冲突的呢？</li>
</ul>
</li>
<li>答案就是，那就是tomcat做了Web应用层级的隔离。Tomcat给每个Web应用创建一个类加载器实例（WebAppClassLoader），该加载器重写了loadClass方法，优先加载当前应用目录下的类，如果当前找不到了，才一层一层往上找</li>
</ul>
<h2 id="Tomcat还有哪些类加载器吗？"><a href="#Tomcat还有哪些类加载器吗？" class="headerlink" title="Tomcat还有哪些类加载器吗？"></a>Tomcat还有哪些类加载器吗？</h2><ul>
<li><p>并不是Web应用程序下的所有依赖都需要隔离的，比如Redis，因为如果版本相同，没必要每个Web应用程序都独自加载一份，就可以Web应用程序之间共享</p>
<ul>
<li>做法也很简单，Tomcat就在WebAppClassLoader.上加了个父类加载器（SharedClassLoader），如果WebAppClassLoader自身没有加载到某个类，那就委托SharedClassLoader去加载。</li>
<li>（无非就是把需要应用程序之间需要共享的类放到一个共享目录下，Share ClassLoader读共享目录的类就好了）</li>
</ul>
</li>
<li><p>为了隔绝Web应用程序与Tomcat本身的类，又有类加载器（CatalinaClassLoader）来装载Tomcat本身的依赖</p>
</li>
<li><p>如果Tomcat本身的依赖和Web应用还需要共享，那么还有类加载器（CommonClassLoader）来装载进而达到共享</p>
</li>
<li><p>各个类加载器的加载目录可以到tomcat的catalina.properties配置文件上查看</p>
<center>Tomcat的类加载结构图</center>
![](https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/Q0RM1Q_20211229140203.png)</li>
</ul>
<h2 id="JDBC你不是知道吗，听说它也是破坏了双亲委派模型的，你是怎么理解的？"><a href="#JDBC你不是知道吗，听说它也是破坏了双亲委派模型的，你是怎么理解的？" class="headerlink" title="JDBC你不是知道吗，听说它也是破坏了双亲委派模型的，你是怎么理解的？"></a>JDBC你不是知道吗，听说它也是破坏了双亲委派模型的，你是怎么理解的？</h2><ul>
<li><p>JDBC定义了接口。具体实现类由各个厂商进行实现嘛（比如MySQL）</p>
<ul>
<li>类加载有个规则：如里一个类由类加载器A加载那么，这个类的依赖类也是由「相同的类加载器」加载。</li>
<li>我们用JDBC的时候，是用DriverManager进而获取Connection，DriverManager在java.sql包下，显然是由BootStrap类加载器进行装载</li>
<li>当我们使用DriverManager.getConnection()时，得到的一定是厂商实现的类.</li>
<li>但因为这些实现类又不在java包中，BootStrap ClassLoaders并不能加载到各个厂商实现的类</li>
</ul>
</li>
<li><p>DriverManager的解决方案就是，在DriverManager切始化的时候，得到「线程上下文加载器」</p>
<ul>
<li>获取Connection的时候，是使用「线程上下文加载器」去加载Connection的，而这里的线程上下文加载器实际上还是App ClassLoader</li>
<li>所以在获取Connection的时候，还是先找ExtClassLoader和BootStrapClassLoader，只不过这两加载器肯定是加载不到的，最终会由AppClassLoader进行加载</li>
</ul>
</li>
</ul>
<ul>
<li>那这种情况，有的人觉得破坏了双亲委派机制，因为本来明明应该是由BootStrapClassLoader进行加载的，结果来了手「线程上下文加载器」，改掉了<br>类加载器</li>
<li>有的人觉得没破坏双亲委派机制，只是改成由「线程上下文加载器」进行类载，但还是遵守着：「依次往上找父类加载器进行加载，都找不到时才由自身加载」。认为“原则“上是没变的。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>前置知识</strong>：JDK中默认类加载器有三个：AppClassLoader、Ext ClassLoader、BootStrap ClassLoader。AppClassLoader的父加载器为Ext ClassLoader、Ext ClassLoader的父加载器为BootStrap ClassLoader。这里的父子关系并不是通过继承实现的，而是组合。</p>
<p><strong>什么是双亲委派机制</strong>：加载器在加载过程中，先把类交由父类加载器进行加载，父类加载器没找到才由自身加载。</p>
<p><strong>双亲委派机制目的</strong>：为了防止内存中存在多份同样的字节码（安全）</p>
<p><strong>类加载规则</strong>：如果一个类由类加载器A加载，那么这个类的依赖类也是由「相同的类加载器」加载。</p>
<p><strong>如何打破双亲委派机制</strong>：自定义ClassLoader，重写loadClass方法（只要不依次往上交给父加载器进行加载，就算是打破双亲委派机制）</p>
<p><strong>打破双亲委派机制案例</strong>：Tomcat</p>
<ol>
<li>为了Web应用程序类之间隔离，为每个应用程序创建WebAppClassLoader类加载器</li>
<li>为了Web应用程序类之间共享，把ShareClassLoader作为WebAppClassLoader的父类加载器，如果WebAppClassLoader加载器找不到，则尝试用ShareClassLoader进行加载</li>
<li>为了Tomcat本身与Web应用程序类隔离，用CatalinaClassLoader类加载器进行隔离，CatalinaClassLoader加载Tomcat本身的类</li>
<li>为了Tomcat与Web应用程序类共享，用CommonClassLoader作为CatalinaClassLoader和ShareClassLoader的父类加载器</li>
<li>ShareClassLoader、CatalinaClassLoader、CommonClassLoader的目录可以在Tomcat的catalina.properties进行配置</li>
</ol>
<p><strong>线程上下文加载器</strong>：由于类加载的规则，很可能导致父加载器加载时依赖子加载器的类，导致无法加载成功（BootStrap ClassLoader无法加载第三方库的类），所以存在「线程上下文加载器」来进行加载。</p>

      
    </div>

    
    
    


    <div>
      
    </div>

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>l




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/e1774332/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lion.png">
      <meta itemprop="name" content="swimminghao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="swimminghao's blog">
      <meta itemprop="description" content="swimminghao的学习博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | swimminghao's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/e1774332/" class="post-title-link" itemprop="url">27、【对线面试官】深入浅出Java内存模型</a>
        </h2>

        <div class="post-meta-container">

          

          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 19:57:47" itemprop="dateCreated datePublished" datetime="2022-02-28T19:57:47+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-03-10 09:48:07" itemprop="dateModified" datetime="2022-03-10T09:48:07+08:00">2022-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">技术</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/posts/e1774332/#waline-comments" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" id="/posts/e1774332/" data-xid="/posts/e1774332/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="27、【对线面试官】深入浅出Java内存模型"><a href="#27、【对线面试官】深入浅出Java内存模型" class="headerlink" title="27、【对线面试官】深入浅出Java内存模型"></a>27、【对线面试官】深入浅出Java内存模型</h1><h2 id="上一次已经问过了为什么要有Java内存模型"><a href="#上一次已经问过了为什么要有Java内存模型" class="headerlink" title="上一次已经问过了为什么要有Java内存模型"></a>上一次已经问过了为什么要有Java内存模型</h2><ul>
<li>答案是：Java为了屏蔽硬件和操作系统访问内存的各种差异，提出了「Java内存模型」的规范，保证了Java程序在各种平台下对内存的访问都能得到一致效果</li>
<li>强调下：Java内存模型它是一种「规范」，Java虚拟机会实现这个规范。</li>
</ul>
<h2 id="先聊下Java内存模型的抽象结构？"><a href="#先聊下Java内存模型的抽象结构？" class="headerlink" title="先聊下Java内存模型的抽象结构？"></a>先聊下Java内存模型的抽象结构？</h2><ul>
<li>Java内存模型定义了：Java线程对内存数据进行交互的规范。<ul>
<li>线程之间的「共享变量」存储在「主内存」中，每个线程都有自己私有的「本地内存」，「本地内存」存储了该线程以读&#x2F;写共享变量的副本。</li>
<li>本地内存是Java内存模型的抽象概念，并不是真实存在的。</li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/xjTbHO_20211229144348.png"></p>
<ul>
<li>Java内存模型规定了：线程对变量的所有操作都必须在「本地内存」进行，「不能直接读写主内存」的变量<ul>
<li>Java内存模型定义了8种操作来完成「变量如何从主内存到本地内存，以及变量如何从本地内存到主内存」</li>
<li>分别是read&#x2F;load&#x2F;use&#x2F;assign&#x2F;store&#x2F;write&#x2F;lock&#x2F;unlock操作</li>
<li>对变量一个读写操作就涵盖这些操作</li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/IIGEvs_20211229144725.png"></p>
<h2 id="happen-before规则"><a href="#happen-before规则" class="headerlink" title="happen-before规则"></a>happen-before规则</h2><ul>
<li><p>按我的理解下，happen-before实际上也是一套「规则」。Java内存模型定义了这套规则，目的是为了阐述「操作之间」的内存「可见性」</p>
<ul>
<li>从上次讲述「指令重排」就提到了，在CPU和编译器层面上都有指令重排的问题。</li>
</ul>
</li>
<li><p>但：在某些重要的场景下，这一组操作都不能进行重排序，「前面一个操作的结果对后续操作必须是可见的」。</p>
<ul>
<li><p>Java内存模型就提出了happen-before这套规则，规则总共有8条</p>
<ul>
<li>比如传递性、volatile变量规则、程序顺序规则、监视器锁的规则…</li>
</ul>
</li>
</ul>
</li>
<li><p>有了happen-before这些规则。我们写的代码只要在这些规则下，前一个操作的结果对后续操作是可见的，是不会发生重排序的。</p>
</li>
</ul>
<h2 id="volatile内存语义"><a href="#volatile内存语义" class="headerlink" title="volatile内存语义"></a>volatile内存语义</h2><ul>
<li><p>volatile是java的一个关键字</p>
</li>
<li><p>特性：可见性和有序性（禁止重排序）</p>
</li>
<li><p>java内存模型这个规范，很大程度下就为了解决可见性和有序性的问题。</p>
</li>
</ul>
<h2 id="volatile是怎么做到可见性和有序性的"><a href="#volatile是怎么做到可见性和有序性的" class="headerlink" title="volatile是怎么做到可见性和有序性的"></a>volatile是怎么做到可见性和有序性的</h2><ul>
<li><p>为了实现volatile有序性和可见性，定义了4种内存屏障的「规范」，</p>
</li>
<li><p>分别是LoadLoad&#x2F;LoadStore&#x2F;StroreLoad&#x2F;StoreStrore</p>
</li>
<li><p>本质上，就是在volatile前后加上了内存屏障，使得编译器和CPU无法进行重排序，致使有序，并且对volatile变量对其他线程可见</p>
</li>
<li><p>Hotspot虚拟机实现</p>
<ul>
<li>在「汇编」层面上实际是通过Lock前缀指令来实现的（lock支持大部分平台，而fence指令是x86平台的）</li>
<li>locK指令能保证：禁止CPU和编译器的重排序（保证了有序性）、保证CPU写核<br>  心的指令可以立即生效且其他核心的缓存数据失效（保证了可见性）。</li>
</ul>
</li>
</ul>
<h2 id="volatile和MESl协议是啥关系？"><a href="#volatile和MESl协议是啥关系？" class="headerlink" title="volatile和MESl协议是啥关系？"></a>volatile和MESl协议是啥关系？</h2><ul>
<li>没有直接关联</li>
<li>Java内存模型关注的是编程语言层面上，它是高维度的抽象。</li>
<li>MESI是CPU缓存一致性协议，不同的CPU架构都不一样，可能有的CPU压根就没用MESI协议.</li>
<li>只不过MESI名声大，大家就都拿他来举例子了。</li>
<li>MESI可能只是在「特定的场景下」为实现volatile的可见性&#x2F;有序性而使用到的一部分罢了</li>
<li>为了让Java程序员屏蔽上面这些底层知识，快速地入门使用volatile变量</li>
<li>Java内存模型的happen-before规则中就有对volatile变量规则的定义：对一个volatile变量的写操作相对于后续对这个volatile变量的读操作可见</li>
<li>只要变量声明了volatile关键字，写后再读，读必须可见写的值。（可见性、有序性）</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>为什么存在Java内存模型</strong>：Java为了屏蔽硬件和操作系统访问内存的各种差异，提出了「Java内存模型」的规范，保证了Java程序在各种平台下对内存的访问都能得到一致效果</p>
<p><strong>Java内存模型抽象结构</strong>：线程之间的「共享变量」存储在「主内存」中，每个线程都有自己私有的「本地内存」，「本地内存」存储了该线程以读&#x2F;写共享变量的副本。线程对变量的所有操作都必须在「本地内存」进行，而「不能直接读写主内存」的变量</p>
<p><strong>happen-before规则</strong>：Java内存模型规定在某些场景下（一共8条），前面一个操作的结果对后续操作必须是可见的。这8条规则成为happen-before规则</p>
<p><strong>volatile</strong>：volatile是Java的关键字，修饰的变量是可见性且有序的（不会被重排序）。可见性&amp;&amp;有序性，由Java内存模型定义的「内存屏障」完成，实际HotSpot虚拟机实现Java内存模型规范，汇编底层是通过Lock指令来实现。</p>

      
    </div>

    
    
    


    <div>
      
    </div>

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>l




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/6f64b3a6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lion.png">
      <meta itemprop="name" content="swimminghao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="swimminghao's blog">
      <meta itemprop="description" content="swimminghao的学习博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | swimminghao's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/6f64b3a6/" class="post-title-link" itemprop="url">28、【对线面试官】JVM内存模型</a>
        </h2>

        <div class="post-meta-container">

          

          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 19:57:47" itemprop="dateCreated datePublished" datetime="2022-02-28T19:57:47+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-03-10 09:48:07" itemprop="dateModified" datetime="2022-03-10T09:48:07+08:00">2022-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">技术</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/posts/6f64b3a6/#waline-comments" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" id="/posts/6f64b3a6/" data-xid="/posts/6f64b3a6/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="28、【对线面试官】JVM内存模型"><a href="#28、【对线面试官】JVM内存模型" class="headerlink" title="28、【对线面试官】JVM内存模型"></a>28、【对线面试官】JVM内存模型</h1><h2 id="聊聊JVM的内存结构吧？"><a href="#聊聊JVM的内存结构吧？" class="headerlink" title="聊聊JVM的内存结构吧？"></a>聊聊JVM的内存结构吧？</h2><ul>
<li>class文件会被类加载器装载至JVM中，并且JVM会负责程序「运行时」的「内存管理」</li>
<li>而JVM的内存结构，往往指的就是JVM定义的「运行时数据区域」</li>
<li>简单来说就分为了5大块：方法区、堆、程序计数器、虚拟机栈、本地方法栈</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/VHXC3i_20211229151038.png"></p>
<h2 id="顺便讲下你这图上每个区域的内容"><a href="#顺便讲下你这图上每个区域的内容" class="headerlink" title="顺便讲下你这图上每个区域的内容"></a>顺便讲下你这图上每个区域的内容</h2><ul>
<li>程序计数器<ul>
<li>Java是多线程的语言，假设线程数大于CPU数，就很会有「线程切換」现象，切换意昧着「中断」和「恢复」，那自然就需要有一块区域来保存「当前线程的执行信息」</li>
<li>所以，程序计数器就是用于记录各个线程执行的字节码的地址（分支、循环跳转、异常、线程恢复等都依赖于计数器）</li>
</ul>
</li>
<li>虚拟机栈<ul>
<li>每个线程在创建的时候都会创建一个虚拟机栈，每次方法调用都会创建一个「栈帧」。每个「栈帧」会包含几块内容：局部变量表、操作数栈、动态连接和返回地址</li>
<li>作用：它保存方法的局部变量、部分变量的计算并参与了方法的调用和返回。</li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/GOLAU2_20211229151640.png"></p>
<ul>
<li><p>本地方法栈</p>
<ul>
<li>本地方法栈跟虚拟机栈的功能类似，虚拟机栈用于管理Java函数的调用，而本地方法栈则用于管理本地方法的调用。这里的「本地方法」指的是「非Java方法」，一般本地方法是使用C语言实现的。</li>
</ul>
</li>
<li><p>方法区</p>
<ul>
<li>前面提到了运行时数据区这个「分区」是JVM的「规范」，具体的落地实现，不同的虚拟机厂商可能是不一样的</li>
<li>所以「方法区」也只是JVM中规范的一部分</li>
<li>Hotspot虚拟机，就会常常提到「永久代」这个词。 Hotspotl虚拟机在「JDK8前」用「永久代」实现了「方法区」，而很多其他厂商的虚拟机其实是没有「永久代」的概念的</li>
<li>在JDK8中，已经用「元空间」来替代了「永久代」作为「方法区」的实现了</li>
<li>方法区主要是用来存放已被虚拟机加载的「类相关信息」：包括类信息、常量池<ul>
<li>类信息又包括了类的版本、字段、方法、接口和父类等信息。</li>
<li>常量池又可以分「静态常量池」和「运行时常量池」<ul>
<li>静态常量池主要存储的是「字面量」以及「符号引用」等信息，静态常量池也包括了我们说的「字符串常量池」。</li>
<li>「运行时常量池」存储的是「类加载」时生成的「直接引用」等信息</li>
<li>值得注意的是：从「逻辑分区」的角度而言「常量池」是属于「方法区」的</li>
<li>但自从在「JDK7」以后，就已经把「运行时常量池」和「静态常量池」转移到了「堆」内存中进行存储</li>
<li>对于「物理分区」来说「运行时常量池」和「静态常量池』就属于堆</li>
</ul>
</li>
<li>总体来说，就是逻辑分区和物理实际存储的位置，是不一样的</li>
</ul>
</li>
</ul>
</li>
<li><p>堆</p>
<ul>
<li><p>「堆」是线程共享的区域，几乎类的实例和数组分配的内存都来自于它</p>
</li>
<li><p>「堆」被划分为「新生代」和「老年代」，「新生代」又被进一步划分为Eden和 Survivor区，最后 Survivor由From Survivor 和 To Survivor组成</p>
</li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/Xm317A_20211229152833.png"></p>
<h2 id="从「JDK8」已经把「方法区」的实现从「永久代」变成「元空间」，有什么区别？"><a href="#从「JDK8」已经把「方法区」的实现从「永久代」变成「元空间」，有什么区别？" class="headerlink" title="从「JDK8」已经把「方法区」的实现从「永久代」变成「元空间」，有什么区别？"></a>从「JDK8」已经把「方法区」的实现从「永久代」变成「元空间」，有什么区别？</h2><ul>
<li>最主要的区别就是：「元空间」存储不在虚拟机中，而是使用本地内存，JVM不会再出现方法区的内存溢出，以往「永久代」经常因为内存不够用导致跑出OOM异常。</li>
<li>按JDK8版本，总结起来其实就相当于：「类信息」是存储在「元空间」的（也有人把「类信息」这块叫做「类信息常量池」）</li>
<li>而「常量池」用JDK7开始，从「物理存储」角度上就在「堆中」，这是没有变化的。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/5Ha0EV_20211229152636.png"></p>
<h2 id="JVM内存结构和Java內存模型有啥区别吧？"><a href="#JVM内存结构和Java內存模型有啥区别吧？" class="headerlink" title="JVM内存结构和Java內存模型有啥区别吧？"></a>JVM内存结构和Java內存模型有啥区别吧？</h2><ul>
<li>Java内存模型是跟「并发」相关的，它是为了屏蔽底层细节而提出的规范，希望在上层（Java层面上）在操作内存时在不同的平台上也有相同的效果</li>
<li>JVM内存结构（又称为运行时数据区域），它描述着当我们的 class文件加载至虚拟机后，各个分区的「逻辑结构」是如何的，每个分区承担的作用</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>JVM内存结构组成</strong>：JVM内存结构又称为「运行时数据区域」。主要有五部分组成：虚拟机栈、本地方法栈、程序计数器、方法区和堆。其中方法区和堆是线程共享的。虚拟机栈、本地方法栈以及程序计数器是线程隔离的。</p>

      
    </div>

    
    
    


    <div>
      
    </div>

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>l




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/9544a93a/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lion.png">
      <meta itemprop="name" content="swimminghao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="swimminghao's blog">
      <meta itemprop="description" content="swimminghao的学习博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | swimminghao's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/9544a93a/" class="post-title-link" itemprop="url">29、【对线面试官】垃圾回收机制</a>
        </h2>

        <div class="post-meta-container">

          

          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 19:57:47" itemprop="dateCreated datePublished" datetime="2022-02-28T19:57:47+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-03-10 09:48:07" itemprop="dateModified" datetime="2022-03-10T09:48:07+08:00">2022-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">技术</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/posts/9544a93a/#waline-comments" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" id="/posts/9544a93a/" data-xid="/posts/9544a93a/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="29、【对线面试官】垃圾回收机制"><a href="#29、【对线面试官】垃圾回收机制" class="headerlink" title="29、【对线面试官】垃圾回收机制"></a>29、【对线面试官】垃圾回收机制</h1><h2 id="聊聊Java的垃圾回收机制"><a href="#聊聊Java的垃圾回收机制" class="headerlink" title="聊聊Java的垃圾回收机制?"></a>聊聊Java的垃圾回收机制?</h2><p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/Xm317A_20211229152833.png"></p>
<ul>
<li>我们使用Java的时候，会创建很多对象，但我们未曾「手动」将这些对象进行清除,而如果用C++语言的时候，用完是需要自己free（释放）掉的</li>
<li>写Java的时候不用自己手动释放”垃圾”呢？原因很简单，JVM帮我们做了（自动回收垃圾）</li>
<li>垃圾的定义：只要对象不再被使用了，那我们就认为该对象就是垃圾，对象所占用的空间就可以被回收·</li>
</ul>
<h2 id="是怎么判断对象不再被使用的呢？"><a href="#是怎么判断对象不再被使用的呢？" class="headerlink" title="是怎么判断对象不再被使用的呢？"></a>是怎么判断对象不再被使用的呢？</h2><ul>
<li><p>常用的算法有两个「引用计数法」和「可达性分析法」</p>
<ul>
<li><p>引用计数法思路很简单：当对象被引用则+1，但对象引用失败则-1。当计数器为0时，说明对象不再被引用，可以被可回收</p>
</li>
<li><p>缺点就是：如果对象存在循环依赖，那就无法定位该对象，是否应该被回收（A依赖B，B依赖A）</p>
</li>
<li><p>是可达性分析法：它从「GC Roots」开始向下搜索，当对象到「GC Roots」都没有任何引用相连时，说明对象是不可用的，可以被回收</p>
<ul>
<li><p>「 GC Roots」是一组必须「活跃」的引用</p>
</li>
<li><p>从「 GC Root」出发，程序通过直接引用或者间接引用，能够找到可能正在被使用的对象</p>
<ul>
<li>比如：JVM内存结构中的虚拟机栈，虚拟机栈里的栈帧，栈帧中的局部变量，局部变量就存储着引用。</li>
<li>那如果栈帧位于虚拟机栈的栈顶，是不是说明这个栈帧是活跃的（换言之，是线程正在被调用的）</li>
<li>既然是线程正在调用的，那栈帧里的指向「堆」的对象引用，就一定是「活跃」的引用</li>
<li>所以，当前活跃的栈帧指向堆里的对象引用就可以是「 GC Roots」</li>
</ul>
</li>
<li><p>当然了，能作为「 GC Roots」也不单单只有上面那一块</p>
<ul>
<li>比如类的静态变量引用是「 GC Roots」，被「Java本地方法」所引用的对象也是「 GC Roots」等等</li>
</ul>
</li>
<li><p>「 GC Roots」是一组必须「活跃」的「引用」，只要跟「GC Roots」没有直接或者间接引用相连，那就是垃圾。JVM用的就是「可达性分析算法」来判断对象是否为垃圾</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="标记完，怎么删除的（垃圾回收算法）"><a href="#标记完，怎么删除的（垃圾回收算法）" class="headerlink" title="标记完，怎么删除的（垃圾回收算法）"></a>标记完，怎么删除的（垃圾回收算法）</h2><ul>
<li>标记清除<ul>
<li>缺点：直接清除会有「内存碎片」的问题：可能我有10M的空余内存，但程序申请9M内存空间却申请不下来（10M的内存空间是垃圾清除后的，不连续的）</li>
</ul>
</li>
<li>标记复制<ul>
<li>「标记」存活的对象「复制」到另一块空间，复制完了之后，直接把原有的整块空间给干掉！这样就没有内存碎片的问题了</li>
<li>缺点：内存利用率低，得有一块新的区域给我复制（移动）过去</li>
</ul>
</li>
<li>标记整理<ul>
<li>当前区域内进行移动，存活对象一到一边，垃圾移到一边，再统一删除，就不会有内存碎片了</li>
</ul>
</li>
</ul>
<h2 id="老年代、年轻代"><a href="#老年代、年轻代" class="headerlink" title="老年代、年轻代"></a>老年代、年轻代</h2><ul>
<li>大部分对象的生命周期都很短，而只有少部分对象可能会存活很长时间</li>
<li>回收垃圾的时候，程序是有短暂的时间不能正常继续运作啊。（JVM在回收的时候，用户线程不能继续分配修改引用），为了使「 stop the word」持续的时间尽可能短以及提高并发式GC所能应付的内存分配速率</li>
<li>所以很多的垃圾收集器上都会在「物理」或者「逻辑」上，把这两类对象进行区分<ul>
<li>死得快的对象所占的区域叫做「年轻代」，活得久的对象所占的区域叫做「老年代」</li>
<li>但也不是所有的「垃圾收集器」都会有，只不过我们现在线上用的可能都是JDK8，JDK8及以下所使用到的垃圾收集器都是有「分代」概念的</li>
</ul>
</li>
</ul>
<h2 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h2><ul>
<li><p>垃圾回收的过程，其实就对应着几种「垃圾回收算法」分别是</p>
<ul>
<li>标记清除算法、标记复制算法和标记整理算法【「标记」「复制」「整理」】</li>
</ul>
</li>
<li><p>「年轻代」的垃圾收集器有： Seria、Parallel Scavenge、 Pardew</p>
<ul>
<li>年轻代的垃圾回收器使用的都是「标记复制算法」</li>
<li>所以在「堆内存」划分中，将年轻代划分出 Survivor区（ Survivor From和 ourvor To），目的就是为了有一块完整的内存空间供垃圾回收器进行拷贝（移动）</li>
<li>新对象则放入Eden区</li>
<li>堆内存大小默认比例：</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/6qtuUz_20211229160130.png"></p>
</li>
<li><p>「老年代」的垃圾收集器有： Serial Old、 Parallel Old、CMS</p>
</li>
<li><p>Serial是单线程的， Parallel是多线程。这些垃圾收集器实际上就是「实现了」垃圾回收算法（标记复制、标记整理以及标记清除算法）</p>
</li>
<li><p>CMS是「JDK8之前」是比较新的垃圾收集器，它的特点是能够尽可能减少「stop the word」时间。在垃圾回收时让用户线程和GC线程能够并发执行」</p>
</li>
</ul>
<h2 id="新创建的对象一般是在「新生代」嘛，那在什么时候会到「老年代」中呢？"><a href="#新创建的对象一般是在「新生代」嘛，那在什么时候会到「老年代」中呢？" class="headerlink" title="新创建的对象一般是在「新生代」嘛，那在什么时候会到「老年代」中呢？"></a>新创建的对象一般是在「新生代」嘛，那在什么时候会到「老年代」中呢？</h2><ul>
<li>两种情况<ul>
<li>如果对象太大了，就会直接进入老年代（对象创建时就很大 或者 Survivor区没办法存下该对象）</li>
<li>如果对象太老了，那就会晋升至老年代（每发生一次 Monor GC，存活的对象年龄+1，达到默认值15则晋升老年代）或者（动态对象年龄判定可以进入老年代）</li>
</ul>
</li>
</ul>
<h2 id="那-Monor-GC什么时候会触发呢？"><a href="#那-Monor-GC什么时候会触发呢？" class="headerlink" title="那 Monor GC什么时候会触发呢？"></a>那 Monor GC什么时候会触发呢？</h2><ul>
<li>当Eden区空间不足时，就会触发 Monor GC</li>
</ul>
<h2 id="那在「年轻代」GC的时候，从-GC-Roots出发，那不也会扫描到「老年代」的对象吗？那那那-不就相当于全堆扫描吗？那这分代还有意义吗？"><a href="#那在「年轻代」GC的时候，从-GC-Roots出发，那不也会扫描到「老年代」的对象吗？那那那-不就相当于全堆扫描吗？那这分代还有意义吗？" class="headerlink" title="那在「年轻代」GC的时候，从 GC Roots出发，那不也会扫描到「老年代」的对象吗？那那那.不就相当于全堆扫描吗？那这分代还有意义吗？"></a>那在「年轻代」GC的时候，从 GC Roots出发，那不也会扫描到「老年代」的对象吗？那那那.不就相当于全堆扫描吗？那这分代还有意义吗？</h2><ul>
<li><p>JVM解决方案</p>
<ul>
<li>Hotspot虚拟机「老的GC」（G1以下）是要求整个GC堆在连续的地址空间上</li>
<li>所以会有一条分界线（一侧是老年代，另一侧是年轻代），所以可以通过「地址」就可以判断对象在哪个分代上、</li>
<li>当做 Monor GCI的时候，从 GC Roots出发，如果发现「老年代」的对象，那就不往下走了（ Monor GC对老年代的区域毫无兴趣）</li>
</ul>
</li>
</ul>
<h2 id="但又有个问题，那如果「年轻代」的对象被「老年代」引用了呢？（老年代对象持有年轻代对象的引用），那时候肯定是不能回收掉「年轻代」的对象的？"><a href="#但又有个问题，那如果「年轻代」的对象被「老年代」引用了呢？（老年代对象持有年轻代对象的引用），那时候肯定是不能回收掉「年轻代」的对象的？" class="headerlink" title="但又有个问题，那如果「年轻代」的对象被「老年代」引用了呢？（老年代对象持有年轻代对象的引用），那时候肯定是不能回收掉「年轻代」的对象的？"></a>但又有个问题，那如果「年轻代」的对象被「老年代」引用了呢？（老年代对象持有年轻代对象的引用），那时候肯定是不能回收掉「年轻代」的对象的？</h2><ul>
<li>解决方案<ul>
<li>Hotspot虚拟机下有「 card table」（卡表）来避免全局扫描「老年代」对象</li>
<li>「堆内存」的每一小块区域形成「卡页」，卡表实际上就是卡页的集合。当判断一个卡页中有存在对象的跨代引用时，将这个页标记为「脏页」</li>
<li>那知道了「卡表」之后，就很好办了。每次 Monor GC的时候只需要去「卡表找到「脏页」，找到后加入至 GC Root，而不用去遍历整个「老年代」的对象了。</li>
</ul>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>什么是垃圾</strong>：只要对象不再被使用，那即是垃圾</p>
<p><strong>如何判断为垃圾</strong>：可达性分析算法和引用计算算法，JVM使用的是可达性分析算法</p>
<p><strong>什么是GC Roots</strong>：GC Roots是一组必须活跃的引用，跟GC Roots无关联的引用即是垃圾，可被回收</p>
<p><strong>常见的垃圾回收算法</strong>：标记清除、标记复制、标记整理</p>
<p><strong>为什么需要分代</strong>：大部分对象都死得早，只有少部分对象会存活很长时间。在堆内存上都会在物理或逻辑上进行分代，为了使「stop the word」持续的时间尽可能短以及提高并发式GC所能应付的内存分配速率。</p>
<p><strong>Minor GC</strong>：当Eden区满了则触发，从GC Roots往下遍历，年轻代GC不关心老年代对象</p>
<p><strong>什么是card table</strong>【卡表】：空间换时间（类似bitmap），能够避免扫描老年代的所有对象，进而顺利进行Minor GC （案例：老年代对象持有年轻代对象引用）</p>
<p><strong>堆内存占比</strong>：年轻代占堆内存1&#x2F;3，老年代占堆内存2&#x2F;3。Eden区占年轻代8&#x2F;10，Survivor区占年轻代2&#x2F;10（其中From 和To 各站1&#x2F;10)</p>

      
    </div>

    
    
    


    <div>
      
    </div>

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>l




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/498f0b66/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lion.png">
      <meta itemprop="name" content="swimminghao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="swimminghao's blog">
      <meta itemprop="description" content="swimminghao的学习博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | swimminghao's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/498f0b66/" class="post-title-link" itemprop="url">JAVA</a>
        </h2>

        <div class="post-meta-container">

          

          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 19:57:47" itemprop="dateCreated datePublished" datetime="2022-02-28T19:57:47+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-03-13 12:56:04" itemprop="dateModified" datetime="2022-03-13T12:56:04+08:00">2022-03-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">技术</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/posts/498f0b66/#waline-comments" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" id="/posts/498f0b66/" data-xid="/posts/498f0b66/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>116k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1:46</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><a href="#%E4%B8%80%E5%9F%BA%E7%A1%80%E7%AF%87">一、基础篇</a><ul>
<li><a href="#%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80">网络基础</a><ul>
<li><a href="#tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B"><strong>TCP三次握手</strong></a><ul>
<li><a href="#1osi%E4%B8%8Etcpip-%E6%A8%A1%E5%9E%8B"><strong>1、OSI与TCP&#x2F;IP 模型</strong></a></li>
<li><a href="#2%E5%B8%B8%E8%A7%81%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%E5%88%86%E5%B1%82"><strong>2、常见网络服务分层</strong></a></li>
<li><a href="#3tcp%E4%B8%8Eudp%E5%8C%BA%E5%88%AB%E5%8F%8A%E5%9C%BA%E6%99%AF"><strong>3、TCP与UDP区别及场景</strong></a></li>
<li><a href="#4tcp%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6"><strong>4、TCP滑动窗口，拥塞控制</strong></a></li>
<li><a href="#5tcp%E7%B2%98%E5%8C%85%E5%8E%9F%E5%9B%A0%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95"><strong>5、TCP粘包原因和解决方法</strong></a></li>
<li><a href="#6tcpudp%E6%8A%A5%E6%96%87%E6%A0%BC%E5%BC%8F"><strong>6、TCP、UDP报文格式</strong></a></li>
</ul>
</li>
<li><a href="#http%E5%8D%8F%E8%AE%AE"><strong>HTTP协议</strong></a><ul>
<li><a href="#1http%E5%8D%8F%E8%AE%AE10_11_20">1、HTTP协议<em>1.0_1.1_2.0</em></a></li>
<li><a href="#2http%E4%B8%8Ehttps%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB">2、HTTP与HTTPS之间的区别</a></li>
<li><a href="#3get%E5%92%8Cpost%E8%AF%B7%E6%B1%82%E5%8C%BA%E5%88%AB"><strong>3、Get和Post请求区别</strong></a></li>
<li><a href="#4http%E5%B8%B8%E8%A7%81%E5%93%8D%E5%BA%94%E7%8A%B6%E6%80%81%E7%A0%81"><strong>4、HTTP常见响应状态码</strong></a></li>
<li><a href="#5%E9%87%8D%E5%AE%9A%E5%90%91%E5%92%8C%E8%BD%AC%E5%8F%91%E5%8C%BA%E5%88%AB"><strong>5、重定向和转发区别</strong></a></li>
<li><a href="#6cookie%E5%92%8Csession%E5%8C%BA%E5%88%AB"><strong>6、Cookie和Session区别。</strong></a></li>
</ul>
</li>
<li><a href="#%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5url%E8%BF%87%E7%A8%8B"><strong>浏览器输入URL过程</strong></a></li>
</ul>
</li>
<li><a href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80"><strong>操作系统基础</strong></a><ul>
<li><a href="#%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB"><strong>进程和线程的区别</strong></a><ul>
<li><a href="#1%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8Fipc"><strong>1、进程间通信方式IPC</strong></a></li>
<li><a href="#2%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E6%A0%B8%E5%BF%83%E6%80%81"><strong>2、用户态和核心态</strong></a></li>
<li><a href="#3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BF%9B%E7%A8%8B%E7%A9%BA%E9%97%B4"><strong>3、操作系统的进程空间</strong></a></li>
</ul>
</li>
<li><a href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86">操作系统内存管理</a><ul>
<li><a href="#1%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95fifolru"><strong>1、页面置换算法FIFO、LRU</strong></a></li>
<li><a href="#2%E6%AD%BB%E9%94%81%E6%9D%A1%E4%BB%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E5%BC%8F"><strong>2、死锁条件、解决方式。</strong></a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#java%E5%9F%BA%E7%A1%80"><strong>Java基础</strong></a><ul>
<li><a href="#%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7">面向对象三大特性</a><ul>
<li><a href="#1java%E4%B8%8Ec%E5%8C%BA%E5%88%AB"><strong>1、Java与C++区别</strong></a></li>
<li><a href="#2%E5%A4%9A%E6%80%81%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><strong>2、多态实现原理</strong></a></li>
<li><a href="#3static%E5%92%8Cfinal%E5%85%B3%E9%94%AE%E5%AD%97">3、static和final关键字</a></li>
<li><a href="#4%E6%8A%BD%E8%B1%A1%E7%B1%BB%E5%92%8C%E6%8E%A5%E5%8F%A3">4、抽象类和接口</a></li>
<li><a href="#5%E6%B3%9B%E5%9E%8B%E4%BB%A5%E5%8F%8A%E6%B3%9B%E5%9E%8B%E6%93%A6%E9%99%A4">5、泛型以及泛型擦除</a></li>
<li><a href="#6%E5%8F%8D%E5%B0%84%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><strong>6、反射原理以及使用场景</strong></a></li>
<li><a href="#7java%E5%BC%82%E5%B8%B8%E4%BD%93%E7%B3%BB"><strong>7、Java异常体系</strong></a></li>
</ul>
</li>
<li><a href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">数据结构</a><ul>
<li><a href="#1arraylist%E5%92%8Clinkedlist"><strong>1、ArrayList和LinkedList</strong></a></li>
<li><a href="#2list%E9%81%8D%E5%8E%86%E5%BF%AB%E9%80%9F%E5%92%8C%E5%AE%89%E5%85%A8%E5%A4%B1%E8%B4%A5"><strong>2、List遍历快速和安全失败</strong></a></li>
<li><a href="#3%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8Dhashmap"><strong>3、详细介绍HashMap</strong></a></li>
<li><a href="#4concurrenthashmap-">**4、ConcurrentHashMap **</a></li>
<li><a href="#5%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96"><strong>5、序列化和反序列化</strong></a></li>
<li><a href="#6string"><strong>6、String</strong></a></li>
</ul>
</li>
<li><a href="#%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%8E%E5%8E%9F%E5%88%99">设计模式与原则</a><ul>
<li><a href="#1%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F">1、单例模式</a></li>
<li><a href="#2%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F">2、工厂模式</a></li>
<li><a href="#3%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F">3、抽象工厂模式</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E9%9D%A2%E8%AF%95%E9%A2%98">面试题</a><ul>
<li><a href="#%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95">构造方法</a></li>
<li><a href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%9D%97">初始化块</a></li>
<li><a href="#this">This</a></li>
<li><a href="#%E9%87%8D%E5%86%99%E5%92%8C%E9%87%8D%E8%BD%BD%E7%9A%84%E5%8C%BA%E5%88%AB"><strong>重写和重载的区别</strong></a></li>
<li><a href="#object%E7%B1%BB%E6%96%B9%E6%B3%95">Object类方法</a></li>
<li><a href="#%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%8C%85%E8%A3%85%E7%B1%BB">基本数据类型和包装类</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%BA%8Cjvm%E7%AF%87">二、JVM篇</a><ul>
<li><a href="#jvm%E5%86%85%E5%AD%98%E5%88%92%E5%88%86"><strong>JVM内存划分</strong></a><ul>
<li><a href="#1jvm%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9F"><strong>1、JVM运行时数据区域</strong></a></li>
<li><a href="#2%E5%A0%86%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><strong>2、堆内存分配策略</strong></a></li>
<li><a href="#3%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%AD%A5%E9%AA%A4"><strong>3、创建一个对象的步骤</strong></a></li>
<li><a href="#4%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8">4、<strong>对象引用</strong></a></li>
</ul>
</li>
<li><a href="#jvm%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B"><strong>JVM类加载过程</strong></a><ul>
<li><a href="#1%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6"><strong>1、双亲委派机制</strong></a></li>
<li><a href="#2tomcat%E7%9A%84%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6"><strong>2、tomcat的类加载机制</strong></a></li>
</ul>
</li>
<li><a href="#jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6">JVM垃圾回收</a><ul>
<li><a href="#1%E5%AD%98%E6%B4%BB%E7%AE%97%E6%B3%95%E5%92%8C%E4%B8%A4%E6%AC%A1%E6%A0%87%E8%AE%B0%E8%BF%87%E7%A8%8B"><strong>1、存活算法和两次标记过程</strong></a></li>
<li><a href="#2%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95"><strong>2、垃圾回收算法</strong></a><ul>
<li><a href="#minorgcmajorgcfullgc"><strong>MinorGC、MajorGC、FullGC</strong></a></li>
</ul>
</li>
<li><a href="#3%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8"><strong>3、垃圾收集器</strong></a></li>
<li><a href="#4%E9%85%8D%E7%BD%AE%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8"><strong>4、配置垃圾收集器</strong></a></li>
<li><a href="#4jvm%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98"><strong>4、JVM性能调优</strong></a></li>
<li><a href="#5jdk%E6%96%B0%E7%89%B9%E6%80%A7">5、JDK新特性</a></li>
</ul>
</li>
<li><a href="#%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5">线上故障排查</a><ul>
<li><a href="#1%E7%A1%AC%E4%BB%B6%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5">1、硬件故障排查</a></li>
<li><a href="#2%E6%8A%A5%E8%A1%A8%E5%BC%82%E5%B8%B8--jvm%E8%B0%83%E4%BC%98">2、报表异常 | JVM调优</a></li>
<li><a href="#3%E5%A4%A7%E5%B1%8F%E5%BC%82%E5%B8%B8--juc%E8%B0%83%E4%BC%98">3、大屏异常 | JUC调优</a></li>
<li><a href="#4%E6%8E%A5%E5%8F%A3%E5%BB%B6%E8%BF%9F--swap%E8%B0%83%E4%BC%98"><strong>4、接口延迟 | SWAP调优</strong></a></li>
<li><a href="#5%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA--cache%E8%B0%83%E4%BC%98">5、<strong>内存溢出 | Cache调优</strong></a></li>
<li><a href="#6cpu%E9%A3%99%E9%AB%98--%E6%AD%BB%E5%BE%AA%E7%8E%AF">6：CPU飙高 | 死循环</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%B8%89%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%AF%87">三、多线程篇</a><ul>
<li><a href="#%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6">线程调度</a><ul>
<li><a href="#1%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81"><strong>1、线程状态</strong></a></li>
<li><a href="#2%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%88%87%E6%8D%A2"><strong>2、线程状态切换</strong></a></li>
<li><a href="#3%E9%98%BB%E5%A1%9E%E5%94%A4%E9%86%92%E8%BF%87%E7%A8%8B"><strong>3、阻塞唤醒过程</strong></a></li>
<li><a href="#4wait%E5%92%8Csleep%E5%8C%BA%E5%88%AB"><strong>4、wait和sleep区别</strong></a></li>
<li><a href="#5%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E6%96%B9%E5%BC%8F">5、创建线程方式</a></li>
</ul>
</li>
<li><a href="#%E7%BA%BF%E7%A8%8B%E6%B1%A0">线程池</a><ul>
<li><a href="#1%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0"><strong>1、线程池构造函数</strong></a></li>
<li><a href="#2%E7%BA%BF%E7%A8%8B%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E8%BF%87%E7%A8%8B"><strong>2、线程处理任务过程：</strong></a></li>
<li><a href="#3%E7%BA%BF%E7%A8%8B%E6%8B%92%E7%BB%9D%E7%AD%96%E7%95%A5"><strong>3、线程拒绝策略</strong></a></li>
<li><a href="#4execuors%E7%B1%BB%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E6%B1%A0"><strong>4、Execuors类实现线程池</strong></a></li>
<li><a href="#5%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%A4%A7%E5%B0%8F%E8%AE%BE%E7%BD%AE"><strong>5、线程池大小设置</strong></a></li>
</ul>
</li>
<li><a href="#%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8">线程安全</a><ul>
<li><a href="#1%E4%B9%90%E8%A7%82%E9%94%81cas%E6%80%9D%E6%83%B3"><strong>1、乐观锁，CAS思想</strong></a></li>
<li><a href="#2synchronized%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0"><strong>2、synchronized底层实现</strong></a></li>
<li><a href="#3reentrantlock%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0"><strong>3、ReenTrantLock底层实现</strong></a></li>
<li><a href="#4%E5%85%AC%E5%B9%B3%E9%94%81%E5%92%8C%E9%9D%9E%E5%85%AC%E5%B9%B3%E9%94%81%E5%8C%BA%E5%88%AB"><strong>4、公平锁和非公平锁区别</strong></a></li>
<li><a href="#5%E4%BD%BF%E7%94%A8%E5%B1%82%E9%9D%A2%E9%94%81%E4%BC%98%E5%8C%96"><strong>5、使用层面锁优化</strong></a></li>
<li><a href="#6%E7%B3%BB%E7%BB%9F%E5%B1%82%E9%9D%A2%E9%94%81%E4%BC%98%E5%8C%96">6、系统层面锁优化</a></li>
<li><a href="#7threadlocal%E5%8E%9F%E7%90%86"><strong>7、ThreadLocal原理</strong></a></li>
<li><a href="#8hashmap%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8"><strong>8、HashMap线程安全</strong></a></li>
<li><a href="#9string%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%8E%9F%E5%9B%A0">9、String不可变原因</a></li>
</ul>
</li>
<li><a href="#%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B">内存模型</a><ul>
<li><a href="#1volatile%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0"><strong>1、volatile底层实现</strong></a></li>
<li><a href="#2aqs%E6%80%9D%E6%83%B3"><strong>2、AQS思想</strong></a></li>
<li><a href="#3happens-before">3、happens-before</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E5%9B%9Bmysql%E7%AF%87">四、MySQL篇</a><ul>
<li><a href="#whymysql">WhyMysql？</a><ul>
<li><a href="#%E6%B5%B7%E9%87%8Faerospike">海量Aerospike</a></li>
<li><a href="#%E5%9B%BE%E8%B0%B1neo4j">图谱Neo4j</a></li>
<li><a href="#%E6%96%87%E6%A1%A3mongodb"><strong>文档MongoDB</strong></a></li>
<li><a href="#%E4%BA%91%E5%AD%98%E5%82%A8"><strong>云存储</strong></a></li>
<li><a href="#fastdfs"><strong>FastDFS</strong></a></li>
</ul>
</li>
<li><a href="#%E4%BA%8B%E5%8A%A1">事务</a><ul>
<li><a href="#1%E4%BA%8B%E5%8A%A14%E5%A4%A7%E7%89%B9%E6%80%A7"><strong>1、事务4大特性</strong></a></li>
<li><a href="#2%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB"><strong>2、事务隔离级别</strong></a></li>
<li><a href="#3%E9%BB%98%E8%AE%A4%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB-rr"><strong>3、默认隔离级别-RR</strong></a></li>
<li><a href="#4rr%E5%92%8Crc%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><strong>4、RR和RC使用场景</strong></a></li>
<li><a href="#5%E8%A1%8C%E9%94%81%E8%A1%A8%E9%94%81%E6%84%8F%E5%90%91%E9%94%81"><strong>5、行锁，表锁，意向锁</strong></a></li>
<li><a href="#6mvcc%E5%A4%9A%E7%89%88%E6%9C%AC%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6"><strong>6、MVCC多版本并发控制</strong></a></li>
</ul>
</li>
<li><a href="#%E7%B4%A2%E5%BC%95">索引</a><ul>
<li><a href="#1innodb%E5%92%8Cmyisam%E5%BC%95%E6%93%8E"><strong>1、Innodb和Myisam引擎</strong></a></li>
<li><a href="#2%E5%93%88%E5%B8%8C%E7%B4%A2%E5%BC%95"><strong>2、哈希索引</strong></a></li>
<li><a href="#3b%E6%A0%91%E7%B4%A2%E5%BC%95"><strong>3、B+树索引</strong></a></li>
<li><a href="#4%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95">4、创建索引</a></li>
<li><a href="#5%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%E5%92%8C%E9%9D%9E%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95"><strong>5、聚簇索引和非聚簇索引</strong></a></li>
<li><a href="#6%E6%9C%80%E5%B7%A6%E5%89%8D%E7%BC%80%E9%97%AE%E9%A2%98">6、最左前缀问题</a></li>
</ul>
</li>
<li><a href="#sql%E6%9F%A5%E8%AF%A2">SQL查询</a><ul>
<li><a href="#1sql%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B"><strong>1、SQL语句的执行过程</strong></a></li>
<li><a href="#2%E5%9B%9E%E8%A1%A8%E6%9F%A5%E8%AF%A2%E5%92%8C%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95"><strong>2、回表查询和覆盖索引</strong></a></li>
<li><a href="#3explain%E5%8F%8A%E4%BC%98%E5%8C%96">3、Explain及优化</a></li>
<li><a href="#4join%E6%9F%A5%E8%AF%A2">4、JOIN查询</a></li>
</ul>
</li>
<li><a href="#%E9%9B%86%E7%BE%A4"><strong>集群</strong></a><ul>
<li><a href="#1%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E8%BF%87%E7%A8%8B">1、主从复制过程</a></li>
<li><a href="#2%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98">2、数据一致性问题</a></li>
<li><a href="#3%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84">3、集群架构</a></li>
<li><a href="#4%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E5%92%8C%E6%81%A2%E5%A4%8D">4、故障转移和恢复</a></li>
</ul>
</li>
<li><a href="#%E9%9D%A2%E8%AF%95%E9%A2%98-1">面试题</a><ul>
<li><a href="#%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8">分库分表</a><ul>
<li><a href="#%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8">如何进行分库分表</a></li>
</ul>
</li>
<li><a href="#%E5%A6%82%E4%BD%95%E5%B0%86%E8%80%81%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E8%BF%81%E7%A7%BB">如何将老数据进行迁移</a></li>
<li><a href="#%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E7%9A%84%E8%AF%84%E4%BC%B0%E5%8F%8A%E6%89%A9%E5%AE%B9">系统性能的评估及扩容</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E8%87%AA%E5%A2%9E%E7%9A%84id%E4%B8%BB%E9%94%AE">如何生成自增的id主键</a></li>
</ul>
</li>
<li><a href="#%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E5%8F%8A%E4%BC%98%E5%8C%96">线上故障及优化</a><ul>
<li><a href="#%E6%9B%B4%E6%96%B0%E5%A4%B1%E8%B4%A5--%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%BB%B6%E6%97%B6">更新失败 | 主从同步延时</a></li>
<li><a href="#%E5%BA%94%E7%94%A8%E5%B4%A9%E6%BA%83--%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E4%BC%98%E5%8C%96"><strong>应用崩溃 | 分库分表优化</strong></a></li>
<li><a href="#%E6%9F%A5%E8%AF%A2%E5%BC%82%E5%B8%B8--sql-%E8%B0%83%E4%BC%98">查询异常 | SQL 调优</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%BA%94redis%E7%AF%87"><strong>五、Redis篇</strong></a><ul>
<li><a href="#whyredis">WhyRedis</a><ul>
<li><a href="#1%E7%AE%80%E5%8D%95%E9%AB%98%E6%95%88">1、简单高效</a></li>
<li><a href="#2memcache">2、Memcache</a></li>
<li><a href="#3tair">3、Tair</a></li>
<li><a href="#4guava">4、Guava</a></li>
<li><a href="#5evcache">5、EVCache</a></li>
<li><a href="#6etcd">6、ETCD</a></li>
</ul>
</li>
<li><a href="#redis%E5%BA%95%E5%B1%82">Redis底层</a><ul>
<li><a href="#1redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B">1、redis数据类型</a></li>
<li><a href="#2%E7%9B%B8%E5%85%B3api"><strong>2、相关API</strong></a></li>
<li><a href="#3redis%E5%BA%95%E5%B1%82%E7%BB%93%E6%9E%84">3、redis底层结构</a></li>
<li><a href="#4zset%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0">4、Zset底层实现</a></li>
</ul>
</li>
<li><a href="#redis%E5%8F%AF%E7%94%A8%E6%80%A7"><strong>Redis可用性</strong></a><ul>
<li><a href="#1redis%E6%8C%81%E4%B9%85%E5%8C%96">1、redis持久化</a></li>
<li><a href="#2redis%E4%BA%8B%E5%8A%A1">2、redis事务</a></li>
<li><a href="#3redis%E5%A4%B1%E6%95%88%E7%AD%96%E7%95%A5">3、redis失效策略</a></li>
<li><a href="#4redis%E8%AF%BB%E5%86%99%E6%A8%A1%E5%BC%8F">4、redis读写模式</a></li>
<li><a href="#5%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98">5、多级缓存</a></li>
</ul>
</li>
<li><a href="#redis%E4%B8%83%E5%A4%A7%E7%BB%8F%E5%85%B8%E9%97%AE%E9%A2%98">Redis七大经典问题</a><ul>
<li><a href="#1%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9">1、缓存雪崩</a></li>
<li><a href="#2%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F"><strong>2、缓存穿透</strong></a></li>
<li><a href="#3%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF"><strong>3、缓存击穿</strong></a></li>
<li><a href="#4%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4">4、数据不一致</a></li>
<li><a href="#5%E6%95%B0%E6%8D%AE%E5%B9%B6%E5%8F%91%E7%AB%9E%E4%BA%89">5、数据并发竞争</a></li>
<li><a href="#6%E7%83%AD%E7%82%B9key%E9%97%AE%E9%A2%98">6、热点key问题</a></li>
<li><a href="#7bigkey%E9%97%AE%E9%A2%98">7、BigKey问题</a></li>
</ul>
</li>
<li><a href="#redis%E5%88%86%E5%8C%BA%E5%AE%B9%E9%94%99">Redis分区容错</a><ul>
<li><a href="#1redis%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA"><strong>1、redis数据分区</strong></a></li>
<li><a href="#2%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F%E7%AE%80%E5%8D%95"><strong>2、主从模式&#x3D;简单</strong></a></li>
<li><a href="#3%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E8%AF%BB%E5%A4%9A">3、<strong>哨兵模式</strong>&#x3D;读多</a></li>
<li><a href="#4%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E5%86%99%E5%A4%9A">4、集群模式&#x3D;写多</a></li>
<li><a href="#5%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81">5、分布式锁</a></li>
<li><a href="#6redis%E5%BF%83%E8%B7%B3%E6%A3%80%E6%B5%8B">6、redis心跳检测</a></li>
</ul>
</li>
<li><a href="#redis%E5%AE%9E%E6%88%98">Redis实战</a><ul>
<li><a href="#1redis%E4%BC%98%E5%8C%96">1、Redis优化</a></li>
<li><a href="#2redis%E7%83%AD%E5%8D%87%E7%BA%A7">2、Redis热升级</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E5%85%ADkafka%E7%AF%87">六、Kafka篇</a><ul>
<li><a href="#why-kafka">Why kafka</a></li>
<li><a href="#what-kafka">What Kafka</a></li>
<li><a href="#how-kafka">How Kafka</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E6%B6%88%E8%B4%B9%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B"><strong>生产消费基本流程</strong></a></li>
<li><a href="#%E4%B8%80%E8%87%B4%E6%80%A7">一致性</a></li>
<li><a href="#%E5%8F%AF%E7%94%A8%E6%80%A7">可用性</a></li>
<li><a href="#%E9%9D%A2%E8%AF%95%E9%A2%98-2">面试题</a><ul>
<li><a href="#%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98rebalance"><strong>线上问题rebalance</strong></a></li>
<li><a href="#zookeeper-%E7%9A%84%E4%BD%9C%E7%94%A8">ZooKeeper 的作用</a></li>
<li><a href="#replica%E5%89%AF%E6%9C%AC%E7%9A%84%E4%BD%9C%E7%94%A8">Replica副本的作用</a></li>
<li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%94%AF%E6%8C%81%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB">为什么不支持读写分离?</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9">如何防止重复消费</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%BC%9A%E4%B8%A2%E5%A4%B1"><strong>如何保证数据不会丢失</strong></a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E9%A1%BA%E5%BA%8F%E6%B6%88%E8%B4%B9"><strong>如何保证顺序消费</strong></a></li>
<li><a href="#%E7%BA%BF%E4%B8%8A%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E7%A7%AF%E5%8E%8B%E6%B6%88%E8%B4%B9">【线上】如何解决积压消费</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B">如何避免消息积压</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97">如何设计消息队列</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%B8%83spring%E7%AF%87">七、Spring篇</a><ul>
<li><a href="#%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3beans">设计思想&amp;Beans</a><ul>
<li><a href="#1ioc-%E6%8E%A7%E5%88%B6%E5%8F%8D%E8%BD%AC"><strong>1、IOC 控制反转</strong></a></li>
<li><a href="#2aop-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86"><strong>2、AOP 动态代理</strong></a></li>
<li><a href="#3bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F"><strong>3、Bean生命周期</strong></a></li>
<li><a href="#4bean%E4%BD%9C%E7%94%A8%E5%9F%9F"><strong>4</strong>、Bean作用域</a></li>
<li><a href="#5%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96">5、循环依赖</a></li>
</ul>
</li>
<li><a href="#spring%E6%B3%A8%E8%A7%A3">Spring注解</a><ul>
<li><a href="#1springboot">1、@SpringBoot</a></li>
<li><a href="#2springmvc"><strong>2、@SpringMVC</strong></a></li>
<li><a href="#3springmybatis">3、@SpringMybatis</a></li>
<li><a href="#4transactional">4、@Transactional</a></li>
</ul>
</li>
<li><a href="#spring%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB">Spring源码阅读</a><ul>
<li><a href="#1spring%E4%B8%AD%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F"><strong>1、Spring中的设计模式</strong></a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E5%85%ABspringcloud%E7%AF%87">八、SpringCloud篇</a><br>- <a href="#why-springcloud">Why SpringCloud</a><br>- <a href="#spring-boot">Spring Boot</a><br>- <a href="#gateway--zuul">GateWay &#x2F; Zuul</a><br>- <a href="#eureka--zookeeper">Eureka &#x2F; Zookeeper</a><br>- <a href="#feign--ribbon">Feign &#x2F; Ribbon</a><br>- <a href="#hystrix--sentinel">Hystrix &#x2F; Sentinel</a><br>- <a href="#config--nacos">Config &#x2F; Nacos</a><br>- <a href="#bus--stream">Bus &#x2F; Stream</a><br>- <a href="#sleuth--zipkin"><strong>Sleuth &#x2F; Zipkin</strong></a><ul>
<li><a href="#%E5%AE%89%E5%85%A8%E8%AE%A4%E8%AF%81"><strong>安全认证</strong></a></li>
<li><a href="#%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83">灰度发布</a></li>
<li><a href="#%E5%A4%9A%E7%89%88%E6%9C%AC%E9%9A%94%E7%A6%BB">多版本隔离</a><ul>
<li><a href="#%E5%90%84%E7%BB%84%E4%BB%B6%E8%B0%83%E4%BC%98"><strong>各组件调优</strong></a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%B9%9D%E5%88%86%E5%B8%83%E5%BC%8F%E7%AF%87"><strong>九、分布式篇</strong></a><ul>
<li><a href="#%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B"><strong>发展历程</strong></a></li>
<li><a href="#cap">CAP</a></li>
<li><a href="#%E4%B8%80%E8%87%B4%E6%80%A7-1">一致性</a><ul>
<li><a href="#xa%E6%96%B9%E6%A1%88">XA方案</a></li>
<li><a href="#paxos%E7%AE%97%E6%B3%95"><strong>Paxos算法</strong></a></li>
<li><a href="#zab%E7%AE%97%E6%B3%95"><strong>ZAB算法</strong></a></li>
<li><a href="#raft%E7%AE%97%E6%B3%95">Raft算法</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8Credis%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7">数据库和Redis的一致性</a></li>
</ul>
</li>
<li><a href="#%E5%8F%AF%E7%94%A8%E6%80%A7-1">可用性</a><ul>
<li><a href="#%E5%BF%83%E8%B7%B3%E6%A3%80%E6%B5%8B"><strong>心跳检测</strong></a></li>
<li><a href="#%E5%A4%9A%E6%9C%BA%E6%88%BF%E5%AE%9E%E6%97%B6%E7%83%AD%E5%A4%87"><strong>多机房实时热备</strong></a></li>
</ul>
</li>
<li><a href="#%E5%88%86%E5%8C%BA%E5%AE%B9%E9%94%99%E6%80%A7">分区容错性</a><ul>
<li><a href="#%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6">日志复制</a></li>
<li><a href="#%E4%B8%BB%E5%A4%87master-slave"><strong>主备（Master-Slave）</strong></a></li>
<li><a href="#%E4%BA%92%E5%A4%87active-active"><strong>互备（Active-Active）</strong></a></li>
<li><a href="#%E9%9B%86%E7%BE%A4cluster%E6%A8%A1%E5%BC%8F"><strong>集群（Cluster）模式</strong></a></li>
</ul>
</li>
<li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1">分布式事务</a><ul>
<li><a href="#xa%E6%96%B9%E6%A1%88-1">XA方案</a></li>
<li><a href="#tcc%E6%96%B9%E6%A1%88">TCC方案</a></li>
<li><a href="#saga%E6%96%B9%E6%A1%88"><strong>Saga方案</strong></a></li>
<li><a href="#%E6%9C%AC%E5%9C%B0%E6%B6%88%E6%81%AF%E8%A1%A8ebay"><strong>本地消息表（eBay）</strong></a></li>
<li><a href="#mq%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7"><strong>MQ最终一致性</strong></a></li>
<li><a href="#%E6%9C%80%E5%A4%A7%E5%8A%AA%E5%8A%9B%E9%80%9A%E7%9F%A5%E6%96%B9%E6%A1%88%E8%AE%A2%E5%8D%95---%E7%A7%AF%E5%88%86">最大努力通知方案（订单 -&gt; 积分）</a></li>
</ul>
</li>
<li><a href="#%E9%9D%A2%E8%AF%95%E9%A2%98-3">面试题</a><ul>
<li><a href="#%E5%88%86%E5%B8%83%E5%BC%8Fsession%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88">分布式Session实现方案</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="一、基础篇"><a href="#一、基础篇" class="headerlink" title="一、基础篇"></a>一、基础篇</h1><h2 id="网络基础"><a href="#网络基础" class="headerlink" title="网络基础"></a>网络基础</h2><h3 id="TCP三次握手"><a href="#TCP三次握手" class="headerlink" title="TCP三次握手"></a><strong>TCP三次握手</strong></h3><p>​    <strong>三次握手过程：</strong></p>
<p>​        客户端——发送带有SYN标志的数据包——服务端       <strong>一次握手</strong>  Client进入syn_sent状态</p>
<p>​        服务端——发送带有SYN&#x2F;ACK标志的数据包——客户端   <strong>二次握手</strong>  服务端进入syn_rcvd</p>
<p>​        客户端——发送带有ACK标志的数据包——服务端               <strong>三次握手</strong>   连接就进入Established状态</p>
<p>​    <strong>为什么三次：</strong></p>
<p>​        主要是为了建立可靠的通信信道，保证客户端与服务端同时具备发送、接收数据的能力</p>
<p>​    <strong>为什么两次不行？</strong></p>
<p>​        1、防止已失效的请求报文又传送到了服务端，建立了多余的链接，浪费资源</p>
<p>​        2、 两次握手只能保证单向连接是畅通的。（为了实现可靠数据传输， TCP 协议的通信双方， 都必须维    护一个序列号， 以标识发送出去的数据包中， 哪些是已经被对方收到的。 三次握手的过程即是通信双方    相互告知序列号起始值， 并确认对方已经收到了序列号起始值的必经步骤；如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认）</p>
<p>**TCP四次挥手过程 **</p>
<p><strong>四次挥手过程：</strong></p>
<p>​    客户端——发送带有FIN标志的数据包——服务端，关闭与服务端的连接 ，客户端进入FIN-WAIT-1状态</p>
<p>​    服务端收到这个 FIN，它发回⼀ 个 ACK，确认序号为收到的序号加1，服务端就进入了CLOSE-WAIT状态</p>
<p>​    服务端——发送⼀个FIN数据包——客户端，关闭与客户端的连接，客户端就进入FIN-WAIT-2状态</p>
<p>​    客户端收到这个 FIN，发回 ACK 报⽂确认，并将确认序号设置为收到序号加1，TIME-WAIT状态</p>
<p><strong>为什么四次：</strong></p>
<p>​    因为需要确保客户端与服务端的数据能够完成传输。</p>
<p><strong>CLOSE-WAIT：</strong></p>
<p>​    这种状态的含义其实是表示在等待关闭</p>
<p><strong>TIME-WAIT：</strong></p>
<p>​    为了解决网络的丢包和网络不稳定所带来的其他问题，确保连接方能在时间范围内，关闭自己的连接</p>
<p><strong>如何查看TIME-WAIT状态的链接数量？</strong>        </p>
<p>​    netstat -an |grep TIME_WAIT|wc -l  查看连接数等待time_wait状态连接数</p>
<p><strong>为什么会TIME-WAIT过多？解决方法是怎样的？</strong></p>
<p>​    <strong>可能原因：</strong> 高并发短连接的TCP服务器上，当服务器处理完请求后立刻按照主动正常关闭连接</p>
<p>​    <strong>解决：</strong>负载均衡服务器；Web服务器首先关闭来自负载均衡服务器的连接</p>
<h4 id="1、OSI与TCP-x2F-IP-模型"><a href="#1、OSI与TCP-x2F-IP-模型" class="headerlink" title="1、OSI与TCP&#x2F;IP 模型"></a><strong>1、OSI与TCP&#x2F;IP 模型</strong></h4><p>​        OSI七层：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层</p>
<p>​        TCP&#x2F;IP五层：物理层、数据链路层、网络层、传输层、应用层</p>
<h4 id="2、常见网络服务分层"><a href="#2、常见网络服务分层" class="headerlink" title="2、常见网络服务分层"></a><strong>2、常见网络服务分层</strong></h4><p>​        应用层：HTTP、SMTP、DNS、FTP</p>
<p>​        传输层：TCP 、UDP</p>
<p>​        网络层：ICMP 、IP、路由器、防火墙</p>
<p>​        数据链路层：网卡、网桥、交换机</p>
<p>​        物理层：中继器、集线器</p>
<h4 id="3、TCP与UDP区别及场景"><a href="#3、TCP与UDP区别及场景" class="headerlink" title="3、TCP与UDP区别及场景"></a><strong>3、TCP与UDP区别及场景</strong></h4><table>
<thead>
<tr>
<th>类型</th>
<th align="center">特点</th>
<th align="center">性能</th>
<th align="center">应用过场景</th>
<th align="center">首部字节</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>TCP</td>
<td align="center">面向连接、可靠、字节流</td>
<td align="center">传输效率慢、所需资源多</td>
<td align="center">文件、邮件传输</td>
<td align="center">20-60</td>
<td></td>
</tr>
<tr>
<td>UDP</td>
<td align="center">无连接、不可靠、数据报文段</td>
<td align="center">传输效率快、所需资源少</td>
<td align="center">语音、视频、直播</td>
<td align="center">8个字节</td>
<td></td>
</tr>
</tbody></table>
<p>​    <strong>基于TCP的协议：</strong>HTTP、FTP、SMTP</p>
<p>​    <strong>基于UDP的协议：</strong>RIP、DNS、SNMP</p>
<h4 id="4、TCP滑动窗口，拥塞控制"><a href="#4、TCP滑动窗口，拥塞控制" class="headerlink" title="4、TCP滑动窗口，拥塞控制"></a><strong>4、TCP滑动窗口，拥塞控制</strong></h4><p>​        <strong>TCP通过：</strong>应用数据分割、对数据包进行编号、校验和、流量控制、拥塞控制、超时重传等措施保证数据的可靠传输；</p>
<p>​        <strong>拥塞控制目的：</strong>为了防止过多的数据注入到网络中，避免网络中的路由器、链路过载</p>
<p>​        <strong>拥塞控制过程：</strong>TCP维护一个拥塞窗口，该窗口随着网络拥塞程度动态变化，通过慢开始、拥塞避免等算法减少网络拥塞的发生。</p>
<h4 id="5、TCP粘包原因和解决方法"><a href="#5、TCP粘包原因和解决方法" class="headerlink" title="5、TCP粘包原因和解决方法"></a><strong>5、TCP粘包原因和解决方法</strong></h4><p>​    <strong>TCP粘包是指</strong>：发送方发送的若干包数据到接收方接收时粘成一包</p>
<p>​    <strong>发送方原因：</strong></p>
<p>​        TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量）：</p>
<p>​            收集多个小分组，在一个确认到来时一起发送、导致发送方可能会出现粘包问题</p>
<p>​    <strong>接收方原因：</strong></p>
<p>​            TCP将接收到的数据包保存在接收缓存里，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。</p>
<p>​    <strong>解决粘包问题：</strong></p>
<p>​        最本质原因在与接收对等方无法分辨消息与消息之间的边界在哪，通过使用某种方案给出边界，例如：</p>
<ul>
<li><p>发送定长包。每个消息的大小都是一样的，接收方只要累计接收数据，直到数据等于一个定长的数值就将它作为一个消息。</p>
</li>
<li><p>包尾加上\r\n标记。FTP协议正是这么做的。但问题在于如果数据正文中也含有\r\n，则会误判为消息的边界。</p>
</li>
<li><p>包头加上包体长度。包头是定长的4个字节，说明了包体的长度。接收对等方先接收包体长度，依据包体长度来接收包体。</p>
</li>
</ul>
<h4 id="6、TCP、UDP报文格式"><a href="#6、TCP、UDP报文格式" class="headerlink" title="6、TCP、UDP报文格式"></a><strong>6、TCP、UDP报文格式</strong></h4><p>​    <strong>TCP报文格式：</strong></p>
<p>​        <img src="https://farm1.staticflickr.com/792/27194088468_4cb0141fc8_b.jpg" style="zoom: 67%;" /></p>
<p>​    <strong>源端口号和目的端口号</strong>：</p>
<p>​        用于寻找发端和收端应用进程。这两个值加上ip首部源端ip地址和目的端ip地址唯一确定一个tcp连接。</p>
<p>​    <strong>序号字段：</strong></p>
<p>​        序号用来标识从T C P发端向T C P收端发送的数据字节流，它表示在这个报文段中的的第一个数据字节。如果将字节流看作在两个应用程序间的单向流动，则 T C P用序号对每个字节进行计数。序号是32 bit的无符号数，序号到达 2^32-1后又从0开始。</p>
<p>　　当建立一个新的连接时，SYN标志变1。序号字段包含由这个主机选择的该连接的初始序号ISN（Initial Sequence Number）。该主机要发送数据的第一个字节序号为这个ISN加1，因为SYN标志消耗了一个序号</p>
<p>​    <strong>确认序号</strong>：</p>
<p>​        既然每个传输的字节都被计数，确认序号包含发送确认的一端所期望收到的下一个序号。因此，确认序号应当是上次已成功收到数据字节序号加 1。只有ACK标志为 1时确认序号字段才有效。发送ACK无需任何代价，因为 32 bit的确认序号字段和A C K标志一样，总是T C P首部的一部分。因此，我们看到一旦一个连接建立起来，这个字段总是被设置， ACK标志也总是被设置为1。TCP为应用层提供全双工服务。这意味数据能在两个方向上独立地进行传输。因此，连接的每一端必须保持每个方向上的传输数据序号。</p>
<p>​    <strong>首都长度</strong>：</p>
<p>​        首部长度给出首部中 32 bit字的数目。需要这个值是因为任选字段的长度是可变的。这个字段占4 bit，因此T C P最多有6 0字节的首部。然而，没有任选字段，正常的长度是 2 0字节。</p>
<p>​    <strong>标志字段</strong>：在T C P首部中有 6个标志比特。它们中的多个可同时被设置为1.<br>　　URG紧急指针（u rgent pointer）有效<br>　　ACK确认序号有效。<br>　　PSH接收方应该尽快将这个报文段交给应用层。<br>　　RST重建连接。<br>　　SYN同步序号用来发起一个连接。这个标志和下一个标志将在第 1 8章介绍。<br>　　FIN发端完成发送任务。</p>
<p>​    <strong>窗口大小</strong>：</p>
<p>​        T C P的流量控制由连接的每一端通过声明的窗口大小来提供。窗口大小为字节数，起始于确认序号字段指明的值，这个值是接收端期望接收的字节。窗口大小是一个 16 bit字段，因而窗口大小最大为 65535字节。</p>
<p>​    <strong>检验和：</strong></p>
<p>​        检验和覆盖了整个的 T C P报文段：T C P首部和T C P数据。这是一个强制性的字段，一定是由发端计算和存储，并由收端进行验证。</p>
<p>​    <strong>紧急指针</strong>：</p>
<p>​        只有当URG标志置1时紧急指针才有效。紧急指针是一个正的偏移量，和序号字段中的值相加表示紧急数据最后一个字节的序号。 T C P的紧急方式是发送端向另一端发送紧急数据的一种方式。</p>
<p>​    <strong>选项</strong>：</p>
<p>​        最常见的可选字段是最长报文大小，又称为 MSS (Maximum Segment Size)。每个连接方通常都在通信的第一个报文段（为建立连接而设置 S Y N标志的那个段）中指明这个选项。它指明本端所能接收的最大长度的报文段。</p>
<p>​    <strong>UDP报文格式：</strong></p>
<p>​    <img src="https://appwk.baidu.com/naapi/doc/view?ih=482&o=png_6_0_0_176_917_504_247_892.979_1262.879&iw=986&ix=0&iy=0&aimw=986&rn=1&doc_id=182d935c3186bceb18e8bb77&pn=1&sign=b88bda03b9954e506622f97b8b2ae438&type=1&app_ver=2.9.8.2&ua=bd_800_800_IncredibleS_2.9.8.2_2.3.7&bid=1&app_ua=IncredibleS&uid=&cuid=&fr=3&Bdi_bear=WIFI&from=3_10000&bduss=&pid=1&screen=800_800&sys_ver=2.3.7" style="zoom:50%;" /></p>
<p>​    <strong>端口号</strong>：</p>
<p>​        用来表示发送和接受进程。由于 I P层已经把I P数据报分配给T C P或U D P（根据I P首部中协议字段值），因此T C P端口号由T C P来查看，而 U D P端口号由UDP来查看。T C P端口号与UDP端口号是相互独立的。</p>
<p>​    <strong>长度</strong>：</p>
<p>​        UDP长度字段指的是UDP首部和UDP数据的字节长度。该字段的最小值为 8字节（发送一份0字节的UDP数据报是 O K）。</p>
<p>​    <strong>检验和</strong>：</p>
<p>​        UDP检验和是一个端到端的检验和。它由发送端计算，然后由接收端验证。其目的是为了发现UDP首部和数据在发送端到接收端之间发生的任何改动。</p>
<p>​    <strong>IP报文格式：</strong>普通的IP首部长为20个字节，除非含有可选项字段。</p>
<p>​                <img src="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=1614312792,1954581760&fm=26&gp=0.jpg" style="zoom:67%;" /></p>
<p>​    <strong>4位版本</strong>：</p>
<p>​        目前协议版本号是4，因此IP有时也称作IPV4.</p>
<p>​    <strong>4位首部长度</strong>：</p>
<p>​        首部长度指的是首部占32bit字的数目，包括任何选项。由于它是一个4比特字段，因此首部长度最长为60个字节。</p>
<p>​    <strong>服务类型（TOS）</strong>：</p>
<p>​        服务类型字段包括一个3bit的优先权字段（现在已经被忽略），4bit的TOS子字段和1bit未用位必须置0。4bit的TOS分别代表：最小时延，最大吞吐量，最高可靠性和最小费用。4bit中只能置其中1比特。如果所有4bit均为0，那么就意味着是一般服务。</p>
<p>​    <strong>总长度</strong>：</p>
<p>​        总长度字段是指整个IP数据报的长度，以字节为单位。利用首部长度和总长度字段，就可以知道IP数据报中数据内容的起始位置和长度。由于该字段长16bit，所以IP数据报最长可达65535字节。当数据报被分片时，该字段的值也随着变化。</p>
<p>​    <strong>标识字段</strong>：</p>
<p>​        标识字段唯一地标识主机发送的每一份数据报。通常每发送一份报文它的值就会加1。</p>
<p>​    <strong>生存时间</strong>：</p>
<p>​        TTL（time-to-live）生存时间字段设置了数据报可以经过的最多路由器数。它指定了数据报的生存时间。TTL的初始值由源主机设置（通常为 3 2或6 4），一旦经过一个处理它的路由器，它的值就减去 1。当该字段的值为 0时，数据报就被丢弃，并发送 ICMP 报文通知源主机。</p>
<p>​    <strong>首部检验和</strong>：</p>
<p>​        首部检验和字段是根据 I P首部计算的检验和码。它不对首部后面的数据进行计算。 ICMP、IGMP、UDP和TCP在它们各自的首部中均含有同时覆盖首部和数据检验和码。</p>
<p>​    <strong>以太网报文格式：</strong></p>
<p><img src="https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=2733576797,55677727&fm=26&gp=0.jpg"></p>
<p>​    <strong>目的地址和源地址：</strong></p>
<p>​        是指网卡的硬件地址（也叫MAC 地址），长度是48 位，是在网卡出厂时固化的。</p>
<p>​    <strong>数据：</strong></p>
<p>​        以太网帧中的数据长度规定最小46 字节，最大1500 字节，ARP 和RARP 数据包的长度不够46 字节，要在后面补填充位。最大值1500 称为以太网的最大传输单元（MTU），不同的网络类型有不同的MTU，如果一个数据包从以太网路由到拨号链路上，数据包度大于拨号链路的MTU了，则需要对数据包进行分片fragmentation）。ifconfig 命令的输出中也有“MTU:1500”。注意，MTU 个概念指数据帧中有效载荷的最大长度，不包括帧首部的长度。</p>
<h3 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a><strong>HTTP协议</strong></h3><h4 id="1、HTTP协议1-0-1-1-2-0"><a href="#1、HTTP协议1-0-1-1-2-0" class="headerlink" title="1、HTTP协议1.0_1.1_2.0"></a>1、HTTP协议1.0_1.1_2.0</h4><p>​    <strong>HTTP1.0：</strong>服务器处理完成后立即断开TCP连接（<strong>无连接</strong>），服务器不跟踪每个客户端也不记录过去的请求（<strong>无状态</strong>）</p>
<p>​    <strong>HTTP1.1：</strong>KeepAlived<strong>长连接</strong>避免了连接建立和释放的开销；通过Content-Length来判断当前请求数据是否已经全部接受（<strong>有状态</strong>）</p>
<p>​    <strong>HTTP2.0：</strong>引入二进制数据帧和流的概念，其中帧对数据进行顺序标识；因为有了序列，服务器可以<strong>并行</strong>的传输数据。</p>
<p>​    <strong>http1.0和http1.1的主要区别如下：</strong><br>​        1、缓存处理：1.1添加更多的缓存控制策略（如：Entity tag，If-Match）<br>​        2、网络连接的优化：1.1支持断点续传<br>​        3、错误状态码的增多：1.1新增了24个错误状态响应码，丰富的错误码更加明确各个状态<br>​        4、Host头处理：支持Host头域，不在以IP为请求方标志<br>​        5、长连接：减少了建立和关闭连接的消耗和延迟。</p>
<p>​    <strong>http1.1和http2.0的主要区别：</strong><br>​        1、新的传输格式：2.0使用二进制格式，1.0依然使用基于文本格式<br>​        2、多路复用：连接共享，不同的request可以使用同一个连接传输（最后根据每个request上的id号组合成正常的请求）<br>​        3、header压缩：由于1.X中header带有大量的信息，并且得重复传输，2.0使用encoder来减少需要传输的hearder大小<br>​        4、服务端推送：同google的SPDUY（1.0的一种升级）一样</p>
<h4 id="2、HTTP与HTTPS之间的区别"><a href="#2、HTTP与HTTPS之间的区别" class="headerlink" title="2、HTTP与HTTPS之间的区别"></a>2、HTTP与HTTPS之间的区别</h4><p>​        <strong>HTTP与HTTPS之间的区别：</strong></p>
<table>
<thead>
<tr>
<th align="center">HTTP</th>
<th align="center">HTTPS</th>
</tr>
</thead>
<tbody><tr>
<td align="center">默认端口80</td>
<td align="center">HTTPS默认使用端口443</td>
</tr>
<tr>
<td align="center">明文传输、数据未加密、安全性差</td>
<td align="center">传输过程ssl加密、安全性较好</td>
</tr>
<tr>
<td align="center">响应速度快、消耗资源少</td>
<td align="center">响应速度较慢、消耗资源多、需要用到CA证书</td>
</tr>
</tbody></table>
<p>​        <strong>HTTPS链接建立的过程：</strong></p>
<p>​            1.首先客户端先给服务器发送一个请求</p>
<p>​            2.服务器发送一个SSL证书给客户端，内容包括：证书的发布机构、有效期、所有者、签名以及公钥</p>
<p>​            3.客户端对发来的公钥进行真伪校验，校验为真则使用公钥对对称加密算法以及对称密钥进行加密</p>
<p>​            4.服务器端使用私钥进行解密并使用对称密钥加密确认信息发送给客户端</p>
<p>​            5.随后客户端和服务端就使用对称密钥进行信息传输</p>
<p>​        <strong>对称加密算法：</strong></p>
<p>​            双方持有相同的密钥，且加密速度快，典型对称加密算法：DES、AES</p>
<p>​        <strong>非对称加密算法：</strong></p>
<p>​            密钥成对出现（私钥、公钥），私钥只有自己知道，不在网络中传输；而公钥可以公开。相比对称加密速度较慢，典型的非对称加密算法有：RSA、DSA</p>
<h4 id="3、Get和Post请求区别"><a href="#3、Get和Post请求区别" class="headerlink" title="3、Get和Post请求区别"></a><strong>3、Get和Post请求区别</strong></h4><p><strong>HTTP请求：</strong></p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">GET</td>
<td>向特定资源发送请求，查询数据，并返回实体</td>
</tr>
<tr>
<td align="left">POST</td>
<td>向指定资源提交数据进行处理请求，可能会导致新的资源建立、已有资源修改</td>
</tr>
<tr>
<td align="left">PUT</td>
<td>向服务器上传新的内容</td>
</tr>
<tr>
<td align="left">HEAD</td>
<td>类似GET请求，返回的响应中没有具体的内容，用于获取报头</td>
</tr>
<tr>
<td align="left">DELETE</td>
<td>请求服务器删除指定标识的资源</td>
</tr>
<tr>
<td align="left">OPTIONS</td>
<td>可以用来向服务器发送请求来测试服务器的功能性</td>
</tr>
<tr>
<td align="left">TRACE</td>
<td>回显服务器收到的请求，用于测试或诊断</td>
</tr>
<tr>
<td align="left">CONNECT</td>
<td>HTTP&#x2F;1.1协议中预留给能够将连接改为管道方式的代理服务器</td>
</tr>
</tbody></table>
<p><strong>get和Post区别：</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>GET</th>
<th>POST</th>
</tr>
</thead>
<tbody><tr>
<td>可见性</td>
<td>数据在URL中对所有人可见</td>
<td>数据不会显示在URL中</td>
</tr>
<tr>
<td>安全性</td>
<td>与post相比，get的安全性较差，因为所<br/>发送的数据是URL的一部分</td>
<td>安全，因为参数不会被保存在浏览器<br/>历史或web服务器日志中</td>
</tr>
<tr>
<td>数据长度</td>
<td>受限制，最长2kb</td>
<td>无限制</td>
</tr>
<tr>
<td>编码类型</td>
<td>application&#x2F;x-www-form-urlencoded</td>
<td>multipart&#x2F;form-data</td>
</tr>
<tr>
<td>缓存</td>
<td>能被缓存</td>
<td>不能被缓存</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h4 id="4、HTTP常见响应状态码"><a href="#4、HTTP常见响应状态码" class="headerlink" title="4、HTTP常见响应状态码"></a><strong>4、HTTP常见响应状态码</strong></h4><p>​        100：Continue — 继续。客户端应继续其请求。</p>
<p>​        200：OK — 请求成功。一般用于GET与POST请求。</p>
<p>​        301：Moved Permanently — 永久重定向。</p>
<p>​        302：Found — 暂时重定向。</p>
<p>​        400：Bad Request — 客户端请求的语法错误，服务器无法理解。</p>
<p>​        403：Forbideen — 服务器理解请求客户端的请求，但是拒绝执行此请求。</p>
<p>​        404：Not Found — 服务器无法根据客户端的请求找到资源（网页）。</p>
<p>​        500：Internal Server Error — 服务器内部错误，无法完成请求。</p>
<p>​        502：Bad Gateway — 作为网关或者代理服务器尝试执行请求时，从远程服务器接收到了无效的响应。</p>
<h4 id="5、重定向和转发区别"><a href="#5、重定向和转发区别" class="headerlink" title="5、重定向和转发区别"></a><strong>5、重定向和转发区别</strong></h4><p>​    <strong>重定向：redirect：</strong></p>
<p>​            地址栏发生变化    </p>
<p>​            重定向可以访问其他站点（服务器）的资源</p>
<p>​            重定向是两次请求。不能使用request对象来共享数据</p>
<p>​    <strong>转发：forward：</strong></p>
<p>​            转发地址栏路径不变</p>
<p>​            转发只能访问当前服务器下的资源</p>
<p>​            转发是一次请求，可以使用request对象共享数据</p>
<h4 id="6、Cookie和Session区别。"><a href="#6、Cookie和Session区别。" class="headerlink" title="6、Cookie和Session区别。"></a><strong>6、Cookie和Session区别。</strong></h4><p>​    Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但两者有所区别：</p>
<p>​            Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。</p>
<p>​            cookie不是很安全，别人可以分析存放在本地的COOKIE并进行欺骗,考虑到安全应当使用session。</p>
<p>​            Cookie ⼀般⽤来保存⽤户信息，Session 的主要作⽤就是通过服务端记录⽤户的状态</p>
<h3 id="浏览器输入URL过程"><a href="#浏览器输入URL过程" class="headerlink" title="浏览器输入URL过程"></a><strong>浏览器输入URL过程</strong></h3><p>​    <strong>过程：</strong>DNS解析、TCP连接、发送HTTP请求、服务器处理请求并返回HTTP报文、浏览器渲染、结束</p>
<table>
<thead>
<tr>
<th>过程</th>
<th>使用的协议</th>
</tr>
</thead>
<tbody><tr>
<td>1、浏览器查找域名DNS的IP地址<br />DNS查找过程（浏览器缓存、路由器缓存、DNS缓存）</td>
<td>DNS：获取域名对应的ip</td>
</tr>
<tr>
<td>2、根据ip建立TCP连接</td>
<td>TCP：与服务器建立连接</td>
</tr>
<tr>
<td>3、浏览器向服务器发送HTTP请求</td>
<td>HTTP：发送请求</td>
</tr>
<tr>
<td>4、服务器响应HTTP响应</td>
<td>HTTP</td>
</tr>
<tr>
<td>5、浏览器进行渲染</td>
<td></td>
</tr>
</tbody></table>
<div style="page-break-after: always;"></div>

<h2 id="操作系统基础"><a href="#操作系统基础" class="headerlink" title="操作系统基础"></a><strong>操作系统基础</strong></h2><h3 id="进程和线程的区别"><a href="#进程和线程的区别" class="headerlink" title="进程和线程的区别"></a><strong>进程和线程的区别</strong></h3><p>​        <strong>进程：</strong>是资源分配的最小单位，一个进程可以有多个线程，多个线程共享进程的堆和方法区资源，不共享栈、程序计数器</p>
<p>​        <strong>线程：</strong>是任务调度和执行的最小单位，线程并行执行存在资源竞争和上下文切换的问题</p>
<p>​        <strong>协程：</strong>是一种比线程更加轻量级的存在，正如一个进程可以拥有多个线程一样，一个线程可以拥有多个协程。</p>
<h4 id="1、进程间通信方式IPC"><a href="#1、进程间通信方式IPC" class="headerlink" title="1、进程间通信方式IPC"></a><strong>1、进程间通信方式IPC</strong></h4><p><strong>管道pipe：</strong></p>
<p>​        亲缘关系使用匿名管道，非亲缘关系使用命名管道，管道遵循FIFO，半双工，数据只能单向通信；</p>
<p><strong>信号：</strong></p>
<p>​        信号是一种比较复杂的通信方式，用户调用kill命令将信号发送给其他进程。</p>
<p><strong>消息队列：</strong></p>
<p>​        消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点。</p>
<p><strong>共享内存(share memory)：</strong></p>
<ul>
<li>使得多个进程可以可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。</li>
<li>由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。</li>
</ul>
<p><strong>信号量(Semaphores) ：</strong></p>
<p>​        信号量是⼀个计数器，⽤于多进程对共享数据的访问，这种通信⽅式主要⽤于解决与同步相关的问题并避免竞争条件。</p>
<p><strong>套接字(Sockets) :</strong> </p>
<p>​        简单的说就是通信的两⽅的⼀种约定，⽤套接字中的相关函数来完成通信过程。</p>
<h4 id="2、用户态和核心态"><a href="#2、用户态和核心态" class="headerlink" title="2、用户态和核心态"></a><strong>2、用户态和核心态</strong></h4><p><strong>用户态：</strong>只能受限的访问内存，运行所有的应用程序</p>
<p><strong>核心态：</strong>运行操作系统程序，cpu可以访问内存的所有数据，包括外围设备</p>
<p><strong>为什么要有用户态和内核态：</strong></p>
<p>​        由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络</p>
<p><strong>用户态切换到内核态的3种方式：</strong></p>
<p>​    <strong>a. 系统调用</strong></p>
<p>​        主动调用，系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。</p>
<p>​    <strong>b. 异常</strong></p>
<p>​        当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，比如缺页异常，这时会触发切换内核态处理异常。</p>
<p>​    <strong>c. 外围设备的中断</strong></p>
<p>​        当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会由用户态到内核态的切换。</p>
<h4 id="3、操作系统的进程空间"><a href="#3、操作系统的进程空间" class="headerlink" title="3、操作系统的进程空间"></a><strong>3、操作系统的进程空间</strong></h4><p>​    栈区（stack）— 由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。</p>
<p>​    堆区（heap）— 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。</p>
<p>​    静态区（static）—存放全局变量和静态变量的存储</p>
<p>​    代码区(text)—存放函数体的二进制代码。</p>
<p>​    <strong>线程共享堆区、静态区</strong></p>
<h3 id="操作系统内存管理"><a href="#操作系统内存管理" class="headerlink" title="操作系统内存管理"></a>操作系统内存管理</h3><p><strong>存管理方式：</strong>页式管理、段式管理、段页式管理</p>
<p><strong>分段管理：</strong></p>
<p>​        将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）</p>
<p><strong>分页管理：</strong></p>
<p>​        在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的页框，程序加载时，可以将任意一页放入内存中任意一个页框，这些页框不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）</p>
<p><strong>段页式管理：</strong></p>
<p>​        段⻚式管理机制结合了段式管理和⻚式管理的优点。简单来说段⻚式管理机制就是把主存先分成若⼲段，每个段⼜分成若⼲⻚，也就是说 段⻚式管理机制 中段与段之间以及段的内部的都是离散的</p>
<h4 id="1、页面置换算法FIFO、LRU"><a href="#1、页面置换算法FIFO、LRU" class="headerlink" title="1、页面置换算法FIFO、LRU"></a><strong>1、页面置换算法FIFO、LRU</strong></h4><p><strong>置换算法：</strong>先进先出FIFO、最近最久未使用LRU、最佳置换算法OPT</p>
<p><strong>先进先出FIFO:</strong></p>
<p>​        缺点：没有考虑到实际的页面使用频率，性能差、与通常页面使用的规则不符合，实际应用较少</p>
<p><strong>最近最久未使用LRU:</strong></p>
<p>​        原理：选择最近且最久未使用的页面进行淘汰</p>
<p>​        优点：考虑到了程序访问的时间局部性，有较好的性能，实际应用也比较多</p>
<p>​        缺点：没有合适的算法，只有适合的算法，lFU、random都可以</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@program</span>: Java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span>: LRU最近最久未使用置换算法，通过LinkedHashMap实现</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: Mr.Li</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span>: 2020-07-17 10:29</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LRUCache</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> LinkedHashMap&lt;Integer,Integer&gt; cache;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> capacity;   <span class="comment">//容量大小</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *初始化构造函数</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> capacity</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">LRUCache</span><span class="params">(<span class="type">int</span> capacity)</span> &#123;</span><br><span class="line">        cache = <span class="keyword">new</span> <span class="title class_">LinkedHashMap</span>&lt;&gt;(capacity);</span><br><span class="line">        <span class="built_in">this</span>.capacity = capacity;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">get</span><span class="params">(<span class="type">int</span> key)</span> &#123;</span><br><span class="line">        <span class="comment">//缓存中不存在此key，直接返回</span></span><br><span class="line">        <span class="keyword">if</span>(!cache.containsKey(key)) &#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">res</span> <span class="operator">=</span> cache.get(key);</span><br><span class="line">        cache.remove(key);   <span class="comment">//先从链表中删除</span></span><br><span class="line">        cache.put(key,res);  <span class="comment">//再把该节点放到链表末尾处</span></span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">put</span><span class="params">(<span class="type">int</span> key,<span class="type">int</span> value)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(cache.containsKey(key)) &#123;</span><br><span class="line">            cache.remove(key); <span class="comment">//已经存在，在当前链表移除</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(capacity == cache.size()) &#123;</span><br><span class="line">            <span class="comment">//cache已满，删除链表头位置</span></span><br><span class="line">            Set&lt;Integer&gt; keySet = cache.keySet();</span><br><span class="line">            Iterator&lt;Integer&gt; iterator = keySet.iterator();</span><br><span class="line">            cache.remove(iterator.next());</span><br><span class="line">        &#125;</span><br><span class="line">        cache.put(key,value);  <span class="comment">//插入到链表末尾</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@program</span>: Java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span>: LRU最近最久未使用置换算法，通过LinkedHashMap内部removeEldestEntry方法实现</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: Mr.Li</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span>: 2020-07-17 10:59</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LRUCache</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;Integer, Integer&gt; map;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> capacity;</span><br><span class="line">	</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *初始化构造函数</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> capacity</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">LRUCache</span><span class="params">(<span class="type">int</span> capacity)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.capacity = capacity;</span><br><span class="line">        map = <span class="keyword">new</span> <span class="title class_">LinkedHashMap</span>&lt;Integer, Integer&gt;(capacity, <span class="number">0.75f</span>, <span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">protected</span> <span class="type">boolean</span> <span class="title function_">removeEldestEntry</span><span class="params">(Map.Entry eldest)</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> size() &gt; capacity;  <span class="comment">// 容量大于capacity 时就删除</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">get</span><span class="params">(<span class="type">int</span> key)</span> &#123;</span><br><span class="line">        <span class="comment">//返回key对应的value值，若不存在，返回-1</span></span><br><span class="line">        <span class="keyword">return</span> map.getOrDefault(key, -<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">put</span><span class="params">(<span class="type">int</span> key, <span class="type">int</span> value)</span> &#123;</span><br><span class="line">        map.put(key, value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>最佳置换算法OPT:</strong></p>
<p>​        原理：每次选择当前物理块中的页面在未来长时间不被访问的或未来不再使用的页面进行淘汰</p>
<p>​        优点：具有较好的性能，可以保证获得最低的缺页率</p>
<p>​        缺点：过于理想化，但是实际上无法实现（没办法预知未来的页面）</p>
<h4 id="2、死锁条件、解决方式。"><a href="#2、死锁条件、解决方式。" class="headerlink" title="2、死锁条件、解决方式。"></a><strong>2、死锁条件、解决方式。</strong></h4><p>​    死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的相互等待的现象；</p>
<p>​    <strong>死锁的条件：</strong></p>
<p>​        互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待至占有该资源的进程释放该资源；</p>
<p>​        请求与保持条件：进程获得一定的资源后，又对其他资源发出请求，阻塞过程中不会释放自己已经占有的资源</p>
<p>​        非剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放</p>
<p>​        循环等待条件：系统中若干进程组成环路，环路中每个进程都在等待相邻进程占用的资源</p>
<p>​    <strong>解决方法：</strong>破坏死锁的任意一条件</p>
<p>​        乐观锁，破坏资源互斥条件，<strong>CAS</strong></p>
<p>​        资源一次性分配，从而剥夺请求和保持条件、<strong>tryLock</strong></p>
<p>​        可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件，<strong>数据库deadlock超时</strong></p>
<p>​        资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，从而破坏环路等待的条件，<strong>转账场景</strong></p>
<div style="page-break-after: always;"></div>

<h2 id="Java基础"><a href="#Java基础" class="headerlink" title="Java基础"></a><strong>Java基础</strong></h2><h3 id="面向对象三大特性"><a href="#面向对象三大特性" class="headerlink" title="面向对象三大特性"></a>面向对象三大特性</h3><p><strong>特性：</strong>封装、继承、多态</p>
<p>​    <strong>封装：</strong>对抽象的事物抽象化成一个对象，并对其对象的属性私有化，同时提供一些能被外界访问属性的方法；</p>
<p>​    <strong>继承</strong>：子类扩展新的数据域或功能，并复用父类的属性与功能，单继承，多实现；</p>
<p>​    <strong>多态：</strong>通过继承（多个⼦类对同⼀⽅法的重写）、也可以通过接⼝（实现接⼝并覆盖接⼝）</p>
<h4 id="1、Java与C-区别"><a href="#1、Java与C-区别" class="headerlink" title="1、Java与C++区别"></a><strong>1、Java与C++区别</strong></h4><p>​    不同点：c++支持多继承，并且有指针的概念，由程序员自己管理内存；Java是单继承，可以用接口实现多继承，Java 不提供指针来直接访问内存，程序内存更加安全，并且Java有JVM⾃动内存管理机制，不需要程序员⼿动释放⽆⽤内存</p>
<h4 id="2、多态实现原理"><a href="#2、多态实现原理" class="headerlink" title="2、多态实现原理"></a><strong>2、多态实现原理</strong></h4><p>多态的底层实现是动态绑定，即在运行时才把方法调用与方法实现关联起来。</p>
<p><strong>静态绑定与动态绑定：</strong></p>
<p>​    一种是在编译期确定，被称为静态分派，比如方法的重载；</p>
<p>​    一种是在运行时确定，被称为动态分派，比如方法的覆盖（重写）和接口的实现。</p>
<p><strong>多态的实现</strong></p>
<p>​        虚拟机栈中会存放当前方法调用的栈帧（局部变量表、操作栈、动态连接 、返回地址）。多态的实现过程，就是方法调用动态分派的过程，如果子类覆盖了父类的方法，则在多态调用中，动态绑定过程会首先确定实际类型是子类，从而先搜索到子类中的方法。这个过程便是方法覆盖的本质。</p>
<h4 id="3、static和final关键字"><a href="#3、static和final关键字" class="headerlink" title="3、static和final关键字"></a>3、static和final关键字</h4><p><strong>static：</strong>可以修饰属性、方法</p>
<p>​    <strong>static修饰属性：</strong></p>
<p>​        类级别属性，所有对象共享一份，随着类的加载而加载（只加载一次），先于对象的创建；可以使用类名直接调用。</p>
<p>​    <strong>static修饰方法：</strong></p>
<p>​        随着类的加载而加载；可以使用类名直接调用；静态方法中，只能调用静态的成员，不可用this；</p>
<p><strong>final：</strong>关键字主要⽤在三个地⽅：变量、⽅法、类。</p>
<p>​    <strong>final修饰变量：</strong></p>
<p>​        如果是基本数据类型的变量，则其数值⼀旦在初始化之后便不能更改；</p>
<p>​        如果是引⽤类型的变量，则在对其初始化之后便不能再让其指向另⼀个对象。</p>
<p>​    <strong>final修饰方法：</strong></p>
<p>​        把⽅法锁定，以防任何继承类修改它的含义（重写）；类中所有的 private ⽅法都隐式地指定为 final。</p>
<p>​    <strong>final修饰类：</strong></p>
<p>​         final 修饰类时，表明这个类不能被继承。final 类中的所有成员⽅法都会被隐式地指定为 final ⽅法。</p>
<p>一个类不能被继承，除了final关键字之外，还有可以私有化构造器。（内部类无效）</p>
<h4 id="4、抽象类和接口"><a href="#4、抽象类和接口" class="headerlink" title="4、抽象类和接口"></a>4、抽象类和接口</h4><p><strong>抽象类：</strong>包含抽象方法的类，即使用abstract修饰的类；抽象类只能被继承，所以不能使用final修饰，抽象类不能被实例化，</p>
<p><strong>接口：</strong>接口是一个抽象类型，是抽象方法的集合，接口支持多继承，接口中定义的方法，默认是public abstract修饰的抽象方法</p>
<p><strong>相同点：</strong></p>
<p>​    ① 抽象类和接口都不能被实例化</p>
<p>​    ② 抽象类和接口都可以定义抽象方法，子类&#x2F;实现类必须覆写这些抽象方法</p>
<p><strong>不同点：</strong></p>
<p>​    ① 抽象类有构造方法，接口没有构造方法</p>
<p>​    ③抽象类可以包含普通方法，接口中只能是public abstract修饰抽象方法（Java8之后可以）</p>
<p>​    ③ 抽象类只能单继承，接口可以多继承</p>
<p>​    ④ 抽象类可以定义各种类型的成员变量，接口中只能是public static final修饰的静态常量</p>
<p><strong>抽象类的使用场景：</strong></p>
<p>​    既想约束子类具有共同的行为（但不再乎其如何实现），又想拥有缺省的方法，又能拥有实例变量</p>
<p><strong>接口的应用场景：</strong></p>
<p>​    约束多个实现类具有统一的行为，但是不在乎每个实现类如何具体实现；实现类中各个功能之间可能没有任何联系</p>
<h4 id="5、泛型以及泛型擦除"><a href="#5、泛型以及泛型擦除" class="headerlink" title="5、泛型以及泛型擦除"></a>5、泛型以及泛型擦除</h4><p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/baoyinwang/article/details/107341997">https://blog.csdn.net/baoyinwang/article/details/107341997</a></p>
<p><strong>泛型：</strong></p>
<p>​        泛型的本质是参数化类型。这种参数类型可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口和泛型方法。</p>
<p><strong>泛型擦除：</strong></p>
<p>​        Java的泛型是伪泛型，使用泛型的时候加上类型参数，在编译器编译生成的字节码的时候会去掉，这个过程成为类型擦除。</p>
<p>​        如List<String>等类型，在编译之后都会变成 List。JVM 看到的只是 List，而由泛型附加的类型信息对 JVM 来说是不可见的。</p>
<p>可以通过反射添加其它类型元素</p>
<h4 id="6、反射原理以及使用场景"><a href="#6、反射原理以及使用场景" class="headerlink" title="6、反射原理以及使用场景"></a><strong>6、反射原理以及使用场景</strong></h4><p><strong>Java反射：</strong></p>
<p>​        是指在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法；并且都能够调用它的任意一个方法；</p>
<p><strong>反射原理：</strong></p>
<p>​        反射首先是能够获取到Java中的反射类的字节码，然后将字节码中的方法，变量，构造函数等映射成 相应的 Method、Filed、Constructor 等类</p>
<p>​    <strong>如何得到Class的实例:</strong></p>
<pre><code>     1.类名.class(就是一份字节码)
     2.Class.forName(String className);根据一个类的全限定名来构建Class对象
     3.每一个对象多有getClass()方法:obj.getClass();返回对象的真实类型
</code></pre>
<p><strong>使用场景：</strong></p>
<ul>
<li><p><strong>开发通用框架 -</strong> 反射最重要的用途就是开发各种通用框架。很多框架（比如 Spring）都是配置化的（比如通过 XML 文件配置 JavaBean、Filter 等），为了保证框架的通用性，需要根据配置文件运行时动态加载不同的对象或类，调用不同的方法。</p>
</li>
<li><p><strong>动态代理</strong> - 在切面编程（AOP）中，需要拦截特定的方法，通常，会选择动态代理方式。这时，就需要反射技术来实现了。</p>
<p>JDK：spring默认动态代理，需要实现接口</p>
<p>CGLIB：通过asm框架序列化字节流，可配置，性能差</p>
</li>
<li><p><strong>自定义注解</strong> - 注解本身仅仅是起到标记作用，它需要利用反射机制，根据注解标记去调用注解解释器，执行行为。</p>
</li>
</ul>
<h4 id="7、Java异常体系"><a href="#7、Java异常体系" class="headerlink" title="7、Java异常体系"></a><strong>7、Java异常体系</strong></h4><p>​                <img src="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=3137389296,1222888772&fm=26&gp=0.jpg" style="zoom:67%;" /></p>
<p>Throwable 是 Java 语言中所有错误或异常的超类。下一层分为 Error 和 Exception</p>
<p><strong>Error ：</strong></p>
<p>​        是指 java 运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象。如果出现了这样的错误，除了告知用户，剩下的就是尽力使程序安全的终止。</p>
<p><strong>Exception 包含：RuntimeException 、CheckedException</strong></p>
<p>编程错误可以分成三类：语法错误、逻辑错误和运行错误。</p>
<p><strong>语法错误</strong>（也称编译错误）是在编译过程中出现的错误，由编译器检查发现语法错误</p>
<p><strong>逻辑错误</strong>指程序的执行结果与预期不符，可以通过调试定位并发现错误的原因</p>
<p><strong>运行错误</strong>是引起程序非正常终端的错误，需要通过异常处理的方式处理运行错误</p>
<p><strong>RuntimeException：</strong> 运行时异常，程序应该从逻辑角度尽可能避免这类异常的发生。</p>
<p>​     如 NullPointerException 、 ClassCastException ； </p>
<p><strong>CheckedException：</strong>受检异常，程序使用trycatch进行捕捉处理</p>
<p>​        如IOException、SQLException、NotFoundException；</p>
<h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1goe17hajvzj316d0lhju3.jpg" alt="JavaCollection"></p>
<h4 id="1、ArrayList和LinkedList"><a href="#1、ArrayList和LinkedList" class="headerlink" title="1、ArrayList和LinkedList"></a><strong>1、ArrayList和LinkedList</strong></h4><p><strong>ArrayList：</strong></p>
<p>​        底层基于数组实现，支持对元素进行快速随机访问，适合随机查找和遍历，不适合插入和删除。（提一句实际上）<br>​        默认初始大小为10，当数组容量不够时，会触发扩容机制（扩大到当前的1.5倍），需要将原来数组的数据复制到新的数组中；当从 ArrayList 的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。</p>
<p><strong>LinkedList：</strong></p>
<p>​        底层基于双向链表实现，适合数据的动态插入和删除；<br>​        内部提供了 List 接口中没有定义的方法，用于操作表头和表尾元素，可以当作堆栈、队列和双向队列使用。（比如jdk官方推荐使用基于linkedList的Deque进行堆栈操作）</p>
<p><strong>ArrayList与LinkedList区别：</strong></p>
<p>​        都是线程不安全的，ArrayList 适用于查找的场景，LinkedList 适用于增加、删除多的场景</p>
<p><strong>实现线程安全：</strong></p>
<p>​        可以使用原生的Vector，或者是Collections.synchronizedList(List list)函数返回一个线程安全的ArrayList集合。<br>​        建议使用concurrent并发包下的<strong>CopyOnWriteArrayList</strong>的。</p>
<p>​            ①<strong>Vector:</strong> 底层通过synchronize修饰保证线程安全，效率较差</p>
<p>​            ②<strong>CopyOnWriteArrayList：</strong>写时加锁，使用了一种叫<strong>写时复制</strong>的方法；读操作是可以不用加锁的</p>
<p>​            </p>
<h4 id="2、List遍历快速和安全失败"><a href="#2、List遍历快速和安全失败" class="headerlink" title="2、List遍历快速和安全失败"></a><strong>2、List遍历快速和安全失败</strong></h4><p><strong>①普通for循环遍历List删除指定元素</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i &lt; list.size(); i++)&#123;</span><br><span class="line">   <span class="keyword">if</span>(list.get(i) == <span class="number">5</span>) </span><br><span class="line">       list.remove(i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>② 迭代遍历,用list.remove(i)方法删除元素</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Iterator&lt;Integer&gt; it = list.iterator();</span><br><span class="line"><span class="keyword">while</span>(it.hasNext())&#123;</span><br><span class="line">    <span class="type">Integer</span> <span class="variable">value</span> <span class="operator">=</span> it.next();</span><br><span class="line">    <span class="keyword">if</span>(value == <span class="number">5</span>)&#123;</span><br><span class="line">        list.remove(value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>③foreach遍历List删除元素</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(Integer i:list)&#123;</span><br><span class="line">    <span class="keyword">if</span>(i==<span class="number">3</span>) list.remove(i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>fail—fast：</strong>快速失败</p>
<p>​        当异常产生时，直接抛出异常，程序终止;</p>
<p>​        fail-fast主要是体现在当我们在遍历集合元素的时候，经常会使用迭代器，但在迭代器遍历元素的过程中，如果集合的结构（modCount）被改变的话，就会抛出异常ConcurrentModificationException，防止继续遍历。这就是所谓的快速失败机制。</p>
<p><strong>fail—safe：</strong>安全失败</p>
<p>    采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。由于在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发ConcurrentModificationException。</p>
<p>    缺点：基于拷贝内容的优点是避免了ConcurrentModificationException，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。</p>
<p>    场景：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。</p>
<h4 id="3、详细介绍HashMap"><a href="#3、详细介绍HashMap" class="headerlink" title="3、详细介绍HashMap"></a><strong>3、详细介绍HashMap</strong></h4><p>角度：数据结构+扩容情况+put查找的详细过程+哈希函数+容量为什么始终都是2^N，JDK1.7与1.8的区别。</p>
<p>参考：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/9fe4cb316c05">https://www.jianshu.com/p/9fe4cb316c05</a></p>
<p><strong>数据结构：</strong></p>
<p>​        HashMap在底层数据结构上采用了数组＋链表＋红黑树，通过散列映射来存储键值对数据</p>
<p><strong>扩容情况：</strong></p>
<p>​        默认的负载因子是0.75，如果数组中已经存储的元素个数大于数组长度的75%，将会引发扩容操作。</p>
<p>​        【1】创建一个长度为原来数组长度<strong>两倍的新数组</strong>。</p>
<p>​        【2】1.7采用Entry的重新hash运算，1.8采用高于与运算。</p>
<p><strong>put操作步骤：</strong></p>
<p>​                <img src="https://s0.lgstatic.com/i/image3/M01/73/D9/CgpOIF5rDYmATP43AAB3coc0R64799.png" alt="img" style="zoom:67%;" /></p>
<p>​    1、判断数组是否为空，为空进行初始化;</p>
<p>​    2、不为空，则计算 key 的 hash 值，通过(n - 1) &amp; hash计算应当存放在数组中的下标 index;</p>
<p>​    3、查看 table[index] 是否存在数据，没有数据就构造一个Node节点存放在 table[index] 中；</p>
<p>​    4、存在数据，说明发生了hash冲突(存在二个节点key的hash值一样), 继续判断key是否相等，相等，用新的value替换原数据；</p>
<p>​    5、若不相等，判断当前节点类型是不是树型节点，如果是树型节点，创造树型节点插入红黑树中；</p>
<p>​    6、若不是红黑树，创建普通Node加入链表中；判断链表长度是否大于 8，大于则将链表转换为红黑树；</p>
<p>​    7、插入完成之后判断当前节点数是否大于阈值，若大于，则扩容为原数组的二倍</p>
<p><strong>哈希函数：</strong></p>
<p>​     通过hash函数（优质因子31循环累加）先拿到 key 的hashcode，是一个32位的值，然后让hashcode的高16位和低16位进行<strong>异或</strong>操作。该函数也称为扰动函数，做到尽可能降低hash碰撞，通过尾插法进行插入。</p>
<p><strong>容量为什么始终都是2^N：</strong></p>
<p>​        先做对数组的⻓度取模运算，得到的余数才能⽤来要存放的位置也就是对应的数组下标。这个数组下标的计算⽅法是“  (n - 1) &amp; hash ”。（n代表数组⻓度）。方便数组的扩容和增删改时的取模。</p>
<p><strong>JDK1.7与1.8的区别：</strong></p>
<p><strong>JDK1.7 HashMap：</strong></p>
<p>​        底层是 <strong>数组和链表</strong> 结合在⼀起使⽤也就是链表散列。如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。扩容翻转时顺序不一致使用头插法会产生死循环，导致cpu100%</p>
<p><strong>JDK1.8 HashMap：</strong>    </p>
<p>​        底层数据结构上采用了<strong>数组＋链表＋红黑树</strong>；当链表⻓度⼤于阈值（默认为 8-泊松分布），数组的⻓度大于 64时，链表将转化为红⿊树，以减少搜索时间。（解决了tomcat臭名昭著的url参数dos攻击问题）</p>
<h4 id="4、ConcurrentHashMap"><a href="#4、ConcurrentHashMap" class="headerlink" title="**4、ConcurrentHashMap **"></a>**4、ConcurrentHashMap **</h4><p>​        可以通过<strong>ConcurrentHashMap</strong> 和 <strong>Hashtable</strong>来实现线程安全；Hashtable 是原始API类，通过synchronize同步修饰，效率低下；ConcurrentHashMap 通过分段锁实现，效率较比Hashtable要好；</p>
<p><strong>ConcurrentHashMap的底层实现：</strong></p>
<p>​        <strong>JDK1.7的 ConcurrentHashMap</strong> 底层采⽤ 分段的数组+链表 实现；采用 <strong>分段锁</strong>（Sagment） 对整个桶数组进⾏了分割分段(Segment默认16个)，每⼀把锁只锁容器其中⼀部分数据，多线程访问容器⾥不同数据段的数据，就不会存在锁竞争，提⾼并发访问率。</p>
<p><img src="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=1035283471,1167301443&fm=26&gp=0.jpg"></p>
<p>​        <strong>JDK1.8的 ConcurrentHashMap</strong> 采⽤的数据结构跟HashMap1.8的结构⼀样，数组+链表&#x2F;红⿊树；摒弃了Segment的概念，⽽是直接⽤ Node 数组+链表+红⿊树的数据结构来实现，通过并发控制 <strong>synchronized 和CAS</strong>来操作保证线程的安全。</p>
<h4 id="5、序列化和反序列化"><a href="#5、序列化和反序列化" class="headerlink" title="5、序列化和反序列化"></a><strong>5、序列化和反序列化</strong></h4><p>​        序列化的意思就是将对象的状态转化成字节流，以后可以通过这些值再生成相同状态的对象。对象序列化是对象持久化的一种实现方法，它是将对象的属性和方法转化为一种序列化的形式用于存储和传输。反序列化就是根据这些保存的信息重建对象的过程。</p>
<p><strong>序列化：</strong>将java对象转化为字节序列的过程。</p>
<p><strong>反序列化：</strong>将字节序列转化为java对象的过程。 </p>
<p><strong>优点：</strong></p>
<p>​    a、实现了数据的持久化，通过序列化可以把数据永久地保存到硬盘上（通常存放在文件里）Redis的RDB</p>
<p>​    b、利用序列化实现远程通信，即在网络上传送对象的字节序列。 Google的protoBuf</p>
<p><strong>反序列化失败的场景：</strong></p>
<p>​        序列化ID：serialVersionUID不一致的时候，导致反序列化失败</p>
<h4 id="6、String"><a href="#6、String" class="headerlink" title="6、String"></a><strong>6、String</strong></h4><p>String 使用<strong>数组</strong>存储内容，数组使用 <strong>final</strong> 修饰，因此 String 定义的字符串的值也是<strong>不可变的</strong></p>
<p>StringBuffer 对方法加了同步锁，线程安全，效率略低于 StringBuilder</p>
<h3 id="设计模式与原则"><a href="#设计模式与原则" class="headerlink" title="设计模式与原则"></a>设计模式与原则</h3><h4 id="1、单例模式"><a href="#1、单例模式" class="headerlink" title="1、单例模式"></a>1、单例模式</h4><p>​    某个类只能生成一个实例，该实例全局访问，例如Spring容器里一级缓存里的单例池。</p>
<p><strong>优点</strong>：</p>
<p>​    <strong>唯一访问</strong>：如生成唯一序列化的场景、或者spring默认的bean类型。</p>
<p>​    <strong>提高性能</strong>：频繁实例化创建销毁或者耗时耗资源的场景，如连接池、线程池。</p>
<p><strong>缺点</strong>：</p>
<p>​    不适合有状态且需变更的</p>
<p><strong>实现方式</strong>：</p>
<p>​    <strong>饿汉式</strong>：线程安全速度快</p>
<p>​    <strong>懒汉式</strong>：双重检测锁，第一次减少锁的开销、第二次防止重复、volatile防止重排序导致实例化未完成</p>
<p><strong>为什么要 double-check？</strong></p>
<p>我们先来看第二次的 check，这时你需要考虑这样一种情况，有两个线程同时调用 getInstance 方法，由于 singleton 是空的 ，因此两个线程都可以通过第一重的 if 判断；然后由于锁机制的存在，会有一个线程先进入同步语句，并进入第二重 if 判断 ，而另外的一个线程就会在外面等待。</p>
<p>不过，当第一个线程执行完 new Singleton() 语句后，就会退出 synchronized 保护的区域，这时如果没有第二重 if (singleton &#x3D;&#x3D; null) 判断的话，那么第二个线程也会创建一个实例，此时就破坏了单例，这肯定是不行的。</p>
<p>而对于第一个 check 而言，如果去掉它，那么所有线程都会串行执行，效率低下，所以两个 check 都是需要保留的。</p>
<p><strong>在双重检查锁模式中为什么需要使用 volatile 关键字?</strong></p>
<p>在java内存模型中，volatile 关键字作用可以是保证可见性或者禁止指令重排。这里是因为 singleton &#x3D; new Singleton() ，它并非是一个原子操作，事实上，在 JVM 中上述语句至少做了以下这 3 件事：</p>
<ul>
<li>第一步是给 singleton 分配内存空间；</li>
<li>第二步开始调用 Singleton 的构造函数等，来初始化 singleton；</li>
<li>第三步，将 singleton 对象指向分配的内存空间（执行完这步 singleton 就不是 null 了）。</li>
</ul>
<p>这里需要留意一下 1-2-3 的顺序，因为存在指令重排序的优化，也就是说第 2 步和第 3 步的顺序是不能保证的，最终的执行顺序，可能是 1-2-3，也有可能是 1-3-2。</p>
<p>如果是 1-3-2，那么在第 3 步执行完以后，singleton 就不是 null 了，可是这时第 2 步并没有执行，singleton 对象未完成初始化，它的属性的值可能不是我们所预期的值。假设此时线程 2 进入 getInstance 方法，由于 singleton 已经不是 null 了，所以会通过第一重检查并直接返回，但其实这时的 singleton 并没有完成初始化，所以使用这个实例的时候会报错，详细流程如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/EKNSfp_20210917165416.png"></p>
<p>线程 1 首先执行新建实例的第一步，也就是分配单例对象的内存空间，由于线程 1 被重排序，所以执行了新建实例的第三步，也就是把 singleton 指向之前分配出来的内存地址，在这第三步执行之后，singleton 对象便不再是 null。</p>
<p>这时线程 2 进入 getInstance 方法，判断 singleton 对象不是 null，紧接着线程 2 就返回 singleton 对象并使用，由于没有初始化，所以报错了。最后，线程 1 “姗姗来迟”，才开始执行新建实例的第二步——初始化对象，可是这时的初始化已经晚了，因为前面已经报错了。</p>
<p>使用了 volatile 之后，相当于是表明了该字段的更新可能是在其他线程中发生的，因此应确保在读取另一个线程写入的值时，可以顺利执行接下来所需的操作。在 JDK 5 以及后续版本所使用的 JMM 中，在使用了 volatile 后，会一定程度禁止相关语句的重排序，从而避免了上述由于重排序所导致的读取到不完整对象的问题的发生。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span>&#123;&#125;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton singleton;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(singleton == <span class="literal">null</span>)&#123;</span><br><span class="line">      <span class="keyword">synchronized</span>(Singleton.class)&#123;</span><br><span class="line">        <span class="keyword">if</span>(singleton == <span class="literal">null</span>)&#123;</span><br><span class="line">          singleton = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> singleton;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​    <strong>静态内部类</strong>：线程安全利用率高</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span>&#123;&#125;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SingletonHolder</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="type">Singleton</span> <span class="variable">INSTANCE</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> SingletonHolder.INSTANCE;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>​    <strong>枚举</strong>：effictiveJAVA推荐，反射也无法破坏</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span>&#123;&#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">enum</span> <span class="title class_">SingletonEnum</span> &#123;</span><br><span class="line">        SINGLETON;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Singleton</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">private</span> <span class="title function_">SingletonEnum</span><span class="params">()</span>&#123;</span><br><span class="line">            instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">public</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> instance;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="2、工厂模式"><a href="#2、工厂模式" class="headerlink" title="2、工厂模式"></a>2、工厂模式</h4><p>​    定义一个用于创建产品的接口，由子类决定生产何种产品。</p>
<p><strong>优点：</strong>解耦：提供参数即可获取产品，通过配置文件可以不修改代码增加具体产品。</p>
<p><strong>缺点：</strong>每增加一个产品就得新增一个产品类</p>
<h4 id="3、抽象工厂模式"><a href="#3、抽象工厂模式" class="headerlink" title="3、抽象工厂模式"></a>3、抽象工厂模式</h4><p>​    提供一个接口，用于创建相关或者依赖对象的家族，并由此进行约束。</p>
<p><strong>优点：</strong>可以在类的内部对产品族进行约束</p>
<p><strong>缺点</strong>：假如产品族中需要增加一个新的产品，则几乎所有的工厂类都需要进行修改。</p>
<h4 id="4、设计模式中工厂方法与抽象工厂之间的区别联系"><a href="#4、设计模式中工厂方法与抽象工厂之间的区别联系" class="headerlink" title="4、设计模式中工厂方法与抽象工厂之间的区别联系"></a>4、设计模式中工厂方法与抽象工厂之间的区别联系</h4><p>首先来看看两者的定义区别：</p>
<ul>
<li>工厂模式 定义一个用于创建对象的接口，让子类决定实例化哪一个类</li>
<li>抽象工厂模式 为创建一组相关或相互依赖的对象提供一个接口，而且无需指定他们的具体类</li>
</ul>
<p>个人觉得这个区别在于产品，如果产品单一，最合适用工厂模式，但是如果有多个业务品种、业务分类时，通过抽象工厂模式产生需要的对象是一种非常好的解决方式。 再通俗深化理解下：工厂模式针对的是一个产品等级结构 ，抽象工厂模式针对的是面向多个产品等级结构的。</p>
<p>再来看看工厂方法模式与抽象工厂模式对比：</p>
<table>
<thead>
<tr>
<th>工厂方法模式</th>
<th>抽象工厂模式</th>
</tr>
</thead>
<tbody><tr>
<td>针对的是单个产品等级结构</td>
<td>针对的是面向多个产品等级结构</td>
</tr>
<tr>
<td>一个抽象产品类</td>
<td>多个抽象产品类</td>
</tr>
<tr>
<td>可以派生出多个具体产品类</td>
<td>每个抽象产品类可以派生出多个具体产品类</td>
</tr>
<tr>
<td>一个抽象工厂类，可以派生出多个具体工厂类</td>
<td>一个抽象工厂类，可以派生出多个具体工厂类</td>
</tr>
<tr>
<td>每个具体工厂类只能创建一个具体产品类的实例</td>
<td>每个具体工厂类可以创建多个具体产品类的实例</td>
</tr>
</tbody></table>
<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><h3 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h3><p>构造方法可以被重载，只有当类中没有显性声明任何构造方法时，才会有默认构造方法。</p>
<p>构造方法没有返回值，构造方法的作用是创建新对象。</p>
<h3 id="初始化块"><a href="#初始化块" class="headerlink" title="初始化块"></a>初始化块</h3><p>静态初始化块的优先级最高，会最先执行，在非静态初始化块之前执行。</p>
<p>静态初始化块会在类第一次被加载时最先执行，因此在 main 方法之前。</p>
<h3 id="This"><a href="#This" class="headerlink" title="This"></a>This</h3><p>关键字 <code>this</code> 代表当前对象的引用。当前对象指的是调用类中的属性或方法的对象</p>
<p>关键字 <code>this</code> 不可以在静态方法中使用。静态方法不依赖于类的具体对象的引用</p>
<h3 id="重写和重载的区别"><a href="#重写和重载的区别" class="headerlink" title="重写和重载的区别"></a><strong>重写和重载的区别</strong></h3><p>重载指在同一个类中定义多个方法，这些方法名称相同，签名不同。</p>
<p>重写指在子类中的方法的名称和签名都和父类相同，使用override注解</p>
<h3 id="Object类方法"><a href="#Object类方法" class="headerlink" title="Object类方法"></a>Object类方法</h3><p><strong>toString</strong>     默认是个指针，一般需要重写</p>
<p><strong>equals</strong>        比较对象是否相同，默认和&#x3D;&#x3D;功能一致</p>
<p><strong>hashCode</strong>  散列码，equals则hashCode相同，所以重写equals必须重写hashCode</p>
<p>**finalize   **    用于垃圾回收之前做的遗嘱，默认空，子类需重写</p>
<p><strong>clone</strong>           深拷贝，类需实现cloneable的接口</p>
<p><strong>getClass</strong>     反射获取对象元数据，包括类名、方法、</p>
<p><strong>notify、wait</strong>   用于线程通知和唤醒</p>
<h3 id="基本数据类型和包装类"><a href="#基本数据类型和包装类" class="headerlink" title="基本数据类型和包装类"></a>基本数据类型和包装类</h3><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1goe1gq2yipj318s0ruwj4.jpg" alt="image-20210309224910999"></p>
<table>
<thead>
<tr>
<th>类型</th>
<th>缓存范围</th>
</tr>
</thead>
<tbody><tr>
<td>Byte,Short,Integer,Long</td>
<td>[-128, 127]</td>
</tr>
<tr>
<td>Character</td>
<td>[0, 127]</td>
</tr>
<tr>
<td>Boolean</td>
<td>[false, true]</td>
</tr>
</tbody></table>
<h1 id="二、JVM篇"><a href="#二、JVM篇" class="headerlink" title="二、JVM篇"></a>二、JVM篇</h1><h3 id="JVM内存划分"><a href="#JVM内存划分" class="headerlink" title="JVM内存划分"></a><strong>JVM内存划分</strong></h3><h4 id="1、JVM运行时数据区域"><a href="#1、JVM运行时数据区域" class="headerlink" title="1、JVM运行时数据区域"></a><strong>1、JVM运行时数据区域</strong></h4><p>​        堆、方法区（元空间）、虚拟机栈、本地方法栈、程序计数器</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gobgnw8m8uj30l10bejs4.jpg" alt="xxx"></p>
<p><strong>Heap(堆)：</strong></p>
<p>​        对象的实例以及数组的内存都是要在堆上进行分配的，堆是线程共享的一块区域，用来存放对象实例，也是垃圾回收（GC）的主要区域；开启逃逸分析后，某些未逃逸的对象可以通过标量替换的方式在栈中分配</p>
<p>​        堆细分：新生代、老年代，对于新生代又分为：<strong>Eden区</strong>和<strong>Surviver1</strong>和<strong>Surviver2</strong>区；</p>
<p><strong>方法区：</strong></p>
<p>​        对于JVM的方法区也可以称之为永久区，它储存的是已经被java虚拟机加载的类信息、常量、静态变量；Jdk1.8以后取消了方法区这个概念，称之为元空间（MetaSpace）；</p>
<p>​        当应用中的 Java 类过多时，比如 <strong>Spring 等一些使用动态代理的框架生成了很多类</strong>，如果占用空间超出了我们的设定值，就会发生<strong>元空间溢出</strong></p>
<p><strong>虚拟机栈：</strong></p>
<p>​        虚拟机栈<strong>是线程私有的</strong>，他的生命周期和线程的生命周期是一致的。里面装的是一个一个的<strong>栈帧</strong>，每一个方法在执行的时候都会创建一个栈帧，栈帧中用来存放（<strong>局部变量表</strong>、<strong>操作数栈</strong> 、<strong>动态链接</strong> 、<strong>返回地址</strong>）；在Java虚拟机规范中，对此区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将会抛出<strong>StackOverflowError</strong>异常；如果虚拟机栈动态扩展时无法申请到足够的内存，就会抛出<strong>OutOfMemoryError</strong>异常。</p>
<ul>
<li><p><strong>局部变量表：</strong>局部变量表是一组变量值存储空间，用来存放<strong>方法参数</strong>、方法内部定义的<strong>局部变量</strong>。底层是变量槽（variable slot）<strong>（注意：java分成员变量、局部变量）</strong></p>
</li>
<li><p><strong>操作数栈：</strong>是用来记录一个方法在执行的过程中，<strong>字节码指令向操作数栈中进行入栈和出栈的过程</strong>。大小在编译的时候已经确定了，当一个方法刚开始执行的时候，操作数栈中是空发的，在方法执行的过程中会有各种<strong>字节码指令</strong>往操作数栈中<strong>入栈和出栈</strong>。</p>
</li>
<li><p><strong>动态链接：</strong>因为字节码文件中有很多符号的引用，这些符号引用一部分会在<strong>类加载的解析阶段</strong>或<strong>第一次使用</strong>的时候转化成<strong>直接引用</strong>，这种称为<strong>静态解析</strong>；另一部分会<strong>在运行期间</strong>转化为直接引用，称为<strong>动态链接</strong>。</p>
</li>
<li><p><strong>返回地址（returnAddress）：</strong>类型（指向了一条字节码指令的地址）</p>
<p><strong>JIT即时编译器（Just In Time Compiler），简称 JIT 编译器</strong>: </p>
<p>为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化，比如锁粗化等</p>
</li>
</ul>
<p><strong>本地方法栈：</strong></p>
<p>​        本地方法栈和虚拟机栈类似，不同的是虚拟机栈服务的是Java方法，而<strong>本地方法栈服务的是Native方法</strong>。在HotSpot虚拟机实现中是把本地方法栈和虚拟机栈合二为一的，同理它也会抛出<strong>StackOverflowError</strong>和<strong>OOM</strong>异常。</p>
<p><strong>PC程序计数器：</strong></p>
<p>​        PC，指的是存放下一条指令的位置的一个指针。它是一块较小的内存空间，且是<strong>线程私有</strong>的。由于线程的切换，CPU在执行的过程中，需要记住原线程的下一条指令的位置，所以每一个线程都需要有自己的PC。</p>
<h4 id="2、堆内存分配策略"><a href="#2、堆内存分配策略" class="headerlink" title="2、堆内存分配策略"></a><strong>2、堆内存分配策略</strong></h4><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gobnjl5glvj30l10h9jrt.jpg" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/Hm2wXK_20210918154730.png"></p>
<ul>
<li><p>对象优先分配在Eden区，如果Eden区没有足够的空间进行分配时，虚拟机执行一次MinorGC。而那些无需回收的存活对象，将会进到 Survivor 的 From 区（From 区内存不足时，直接进入 Old 区）。</p>
</li>
<li><p>大对象直接进入老年代（<strong>需要大量连续内存空间的对象</strong>）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。</p>
</li>
<li><p>长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄（Age Count）计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，直到达到阀值（默认15次），对象进入老年区。</p>
<p>（<strong>动态对象年龄判定</strong>：程序从年龄最小的对象开始累加，如果累加的对象大小，大于幸存区的一半，则将当前的对象 age 作为新的阈值，年龄大于此阈值的对象则直接进入老年代）</p>
</li>
<li><p>每次进行Minor GC或者大对象直接进入老年区时，JVM会计算所需空间大小如小于老年区的剩余值大小，则进行一次<strong>Full GC</strong>。</p>
</li>
</ul>
<h4 id="3、创建一个对象的步骤"><a href="#3、创建一个对象的步骤" class="headerlink" title="3、创建一个对象的步骤"></a><strong>3、创建一个对象的步骤</strong></h4><p><strong>步骤：类加载检查、分配内存、初始化对象（包括：初始化零值、设置对象头、执行init方法）、将创建的对象指向分配的内存</strong></p>
<p><strong>①类加载检查：</strong> </p>
<p>​        虚拟机遇到 new 指令时，⾸先去检查是否能在常量池中定位到这个类的符号引⽤，并且检查这个符号引⽤代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执⾏相应的类加载过程。</p>
<p><strong>②分配内存：</strong></p>
<p>​         在类加载检查通过后，接下来虚拟机将为新⽣对象分配内存，分配⽅式有 <strong>“指针碰撞”</strong> 和 <strong>“空闲列表”</strong> 两种，选择那种分配⽅式由 Java 堆是否规整决定，⽽Java堆是否规整⼜由所采⽤的垃圾收集器是否带有压缩整理功能决定。</p>
<p><strong>③初始化对象</strong></p>
<ul>
<li><strong>初始化零值：</strong></li>
</ul>
<p>​         内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值，这⼀步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使⽤，程序能访问到这些字段的数据类型所对应的零值。</p>
<ul>
<li><strong>设置对象头：</strong></li>
</ul>
<p>​        初始化零值完成之后，虚拟机要对对象进⾏必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希吗、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运⾏状态的不同，如是否启⽤偏向锁等，对象头会有不同的设置⽅式。</p>
<ul>
<li><strong>执⾏ init ⽅法：</strong></li>
</ul>
<p>​        从虚拟机的视⻆来看，⼀个新的对象已经产⽣了，但从Java 程序的视⻆来看， <init> ⽅法还没有执⾏，所有的字段都还为零。所以⼀般来说（除循环依赖），执⾏ new 指令之后会接着执⾏  <init> ⽅法，这样⼀个真正可⽤的对象才算产⽣出来。</p>
<p><strong>④将创建的对象指向分配的内存</strong></p>
<h4 id="4、对象引用"><a href="#4、对象引用" class="headerlink" title="4、对象引用"></a>4、<strong>对象引用</strong></h4><p>普通的对象引用关系就是<strong>强引用</strong>。</p>
<p><strong>软引用</strong>用于维护一些可有可无的对象。只有在<strong>内存不足时，系统则会回收软引用对象</strong>，如果回收了软引用对象之后仍然没有足够的内存，才会抛出内存溢出异常。</p>
<p><strong>弱引用</strong>对象相比软引用来说，要更加无用一些，它拥有更短的生命周期，当 JVM 进行垃圾回收时，<strong>无论内存是否充足</strong>，都会回收被弱引用关联的对象。</p>
<p><strong>虚引用</strong>是一种形同虚设的引用，在现实场景中用的不是很多，它主要用来<strong>跟踪对象被垃圾回收</strong>的活动。</p>
<div style="page-break-after: always;"></div>

<h3 id="JVM类加载过程"><a href="#JVM类加载过程" class="headerlink" title="JVM类加载过程"></a><strong>JVM类加载过程</strong></h3><p><strong>过程：加载、验证、准备、解析、初始化</strong></p>
<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gobnnbem87j30eq0cogmj.jpg" alt="img" style="zoom:50%;" />

<p><strong>加载阶段：</strong></p>
<p>​        1.通过一个类的全限定名来获取定义此类的二进制字节流。</p>
<p>​        2.将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</p>
<p>​        3.在Java堆中生成一个代表这个类的java.lang.class对象，作为访问方法区这些数据的入口。</p>
<p><strong>验证阶段：</strong></p>
<p>​        1.文件格式验证（是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理）</p>
<p>​        2.元数据验证（对字节码描述的信息进行语意分析，以保证其描述的信息符合Java语言规范要求）</p>
<p>​        3.字节码验证（保证被校验类的方法在运行时不会做出危害虚拟机安全的行为）</p>
<p>​        4.符号引用验证（虚拟机将符号引用转化为直接引用时，解析阶段中发生）</p>
<p><strong>准备阶段：</strong></p>
<p>​        准备阶段是正式为类变量（成员变量）分配内存并设置类变量初始值的阶段。将对象初始化为“零”值。</p>
<p>这一步只会给那些静态变量设置一个初始的值，而那些实例变量是在实例化对象时进行分配的。</p>
<p><strong>解析阶段：</strong></p>
<p>​        解析阶段时虚拟机将常量池内的符号引用替换为直接引用的过程。</p>
<p>​        <strong>字符串常量池</strong>：堆上，默认class文件的静态常量池</p>
<p>​        <strong>运行时常量池</strong>：在方法区，属于元空间</p>
<p><strong>初始化阶段：</strong></p>
<p>​        初始化阶段时加载过程的最后一步，而这一阶段也是真正意义上开始执行类中定义的Java程序代码。</p>
<h4 id="1、双亲委派机制"><a href="#1、双亲委派机制" class="headerlink" title="1、双亲委派机制"></a><strong>1、双亲委派机制</strong></h4><p>​        每⼀个类都有⼀个对应它的类加载器。系统中的 ClassLoder 在协同⼯作的时候会默认使⽤ 双亲委派模型 。即在类加载的时候，系统会⾸先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载的时候，⾸先会把该请求委派该⽗类加载器的  loadClass() 处理，因此所有的请求最终都应该传送到顶层的启动类加载器  BootstrapClassLoader 中。当⽗类加载器⽆法处理时，才由⾃⼰来处理。当⽗类加载器为null时，会使⽤启动类加载器  BootstrapClassLoader 作为⽗类加载器。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gobn5lh4f6j30hk08rjso.jpg" alt="img"></p>
<p><strong>使用好处：</strong></p>
<p>​        此机制保证JDK核心类的优先加载；使得Java程序的稳定运⾏，可以避免类的重复加载，也保证了 Java 的核⼼ API 不被篡改。如果不⽤使⽤双亲委派模型，⽽是每个类加载器加载⾃⼰的话就会出现⼀些问题，⽐如我们编写⼀个称为  java.lang.Object 类的话，那么程序运⾏的时候，系统就会出现多个不同的Object 类。</p>
<p><strong>破坏双亲委派机制：</strong></p>
<ul>
<li><p>可以⾃⼰定义⼀个类加载器，重写loadClass方法；</p>
</li>
<li><p>Tomcat 可以加载自己目录下的 class 文件，并不会传递给父类的加载器；</p>
</li>
<li><p>Java 的 SPI，发起者 BootstrapClassLoader 已经是最上层了，它直接获取了 AppClassLoader 进行驱动加载，和双亲委派是相反的。</p>
</li>
</ul>
<h4 id="2、tomcat的类加载机制"><a href="#2、tomcat的类加载机制" class="headerlink" title="2、tomcat的类加载机制"></a><strong>2、tomcat的类加载机制</strong></h4><p><strong>步骤：</strong></p>
<ol>
<li>先在本地cache查找该类是否已经加载过，看看 Tomcat 有没有加载过这个类。</li>
<li>如果Tomcat 没有加载过这个类，则从系统类加载器的cache中查找是否加载过。</li>
<li>如果没有加载过这个类，尝试用ExtClassLoader类加载器类加载，重点来了，这里并没有首先使用 AppClassLoader 来加载类。这个Tomcat 的 WebAPPClassLoader 违背了双亲委派机制，直接使用了 ExtClassLoader来加载类。这里注意 ExtClassLoader 双亲委派依然有效，ExtClassLoader 就会使用 Bootstrap ClassLoader 来对类进行加载，保证了 Jre 里面的核心类不会被重复加载。 比如在 Web 中加载一个 Object 类。WebAppClassLoader → ExtClassLoader → Bootstrap ClassLoader，这个加载链，就保证了 Object 不会被重复加载。</li>
<li>如果 BoostrapClassLoader，没有加载成功，就会调用自己的 findClass 方法由自己来对类进行加载，findClass 加载类的地址是自己本 web 应用下的 class。</li>
<li>加载依然失败，才使用 AppClassLoader 继续加载。</li>
<li>都没有加载成功的话，抛出异常。</li>
</ol>
<p>总结一下以上步骤，WebAppClassLoader 加载类的时候，故意打破了JVM 双亲委派机制，绕开了 AppClassLoader，直接先使用 ExtClassLoader 来加载类。</p>
<div style="page-break-after: always;"></div>

<h3 id="JVM垃圾回收"><a href="#JVM垃圾回收" class="headerlink" title="JVM垃圾回收"></a>JVM垃圾回收</h3><h4 id="1、存活算法和两次标记过程"><a href="#1、存活算法和两次标记过程" class="headerlink" title="1、存活算法和两次标记过程"></a><strong>1、存活算法和两次标记过程</strong></h4><p><strong>引用计数法：</strong></p>
<p>​        给对象添加一个引用计数器，每当由一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。</p>
<p>​    优点：实现简单，判定效率也很高</p>
<p>​    缺点：他很难解决对象之间相互循环引用的问题，基本上被抛弃</p>
<p><strong>可达性分析法：</strong></p>
<p>​        通过一系列的成为“GC Roots”(活动线程相关的各种引用，虚拟机<strong>栈帧引用</strong>，<strong>静态变量引用</strong>，<strong>JNI引用</strong>)的对象作为起始点，从这些节点ReferenceChains开始向下搜索，搜索所走过的路径成为引用链，当一个对象到GC ROOTS没有任何引用链相连时，则证明此对象时不可用的；</p>
<p><strong>两次标记过程：</strong></p>
<p>​        对象被回收之前，该对象的finalize()方法会被调用；两次标记，即第一次标记不在“关系网”中的对象。第二次的话就要先判断该对象有没有实现finalize()方法了，如果没有实现就直接判断该对象可回收；如果实现了就会先放在一个队列中，并由虚拟机建立的一个低优先级的线程去执行它，随后就会进行第二次的小规模标记，在这次被标记的对象就会真正的被回收了。</p>
<h4 id="2、垃圾回收算法"><a href="#2、垃圾回收算法" class="headerlink" title="2、垃圾回收算法"></a><strong>2、垃圾回收算法</strong></h4><p><strong>垃圾回收算法</strong>：复制算法、标记清除、标记整理、分代收集</p>
<p><strong>复制算法：(young)</strong></p>
<p>​        将内存分为⼤⼩相同的两块，每次使⽤其中的⼀块。当这⼀块的内存使⽤完后，就将还存活的对象复制到另⼀块去，然后再把使⽤的空间⼀次清理掉。这样就使每次的内存回收都是对内存区间的⼀半进⾏回收；</p>
<p>​        优点：实现简单，内存效率高，不易产生碎片</p>
<p>​        缺点：内存压缩了一半，倘若存活对象多，Copying 算法的效率会大大降低</p>
<p><strong>标记清除：(cms)</strong></p>
<p>​        标记出所有需要回收的对象，在标记完成后统⼀回收所有被标记的对象</p>
<p>​        缺点：效率低，标记清除后会产⽣⼤量不连续的碎⽚，需要预留空间给分配阶段的浮动垃圾</p>
<p><strong>标记整理：(old)</strong></p>
<p>​        标记过程仍然与“标记-清除”算法⼀样，再让所有存活的对象向⼀端移动，然后直接清理掉端边界以外的内存；解决了产生大量不连续碎片问题</p>
<p><strong>分代收集：</strong></p>
<p>​        根据各个年代的特点选择合适的垃圾收集算法。</p>
<p>​        新生代采用复制算法，新生代每次垃圾回收都要回收大部分对象，存活对象较少，即要复制的操作比较少，一般将新生代划分为一块较大的 Eden 空间和两个较小的 Survivor 空间(From Space, To Space)，每次使用Eden 空间和其中的一块 Survivor 空间，当进行回收时，将该两块空间中还存活的对象复制到另一块 Survivor 空间中。</p>
<p>​        老年代的对象存活⼏率是⽐较⾼的，⽽且没有额外的空间对它进⾏分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进⾏垃圾收集。</p>
<p><strong>Safepoint</strong> 当发生 GC 时，用户线程必须全部停下来，才可以进行垃圾回收，这个状态我们可以认为 JVM 是安全的（safe），整个堆的状态是稳定的。如果在 GC 前，有线程迟迟进入不了 safepoint，那么整个 JVM 都在等待这个阻塞的线程，造成了整体 GC 的时间变长</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gobnmip32vj30l109q0t3.jpg" alt="img"></p>
<h5 id="MinorGC、MajorGC、FullGC"><a href="#MinorGC、MajorGC、FullGC" class="headerlink" title="MinorGC、MajorGC、FullGC"></a><strong>MinorGC、MajorGC、FullGC</strong></h5><p><strong>MinorGC</strong> 在年轻代空间不足的时候发生，</p>
<p><strong>MajorGC</strong> 指的是老年代的 GC，出现 MajorGC 一般经常伴有 MinorGC。</p>
<p><strong>FullGC</strong> 1、当老年代无法再分配内存的时候；2、元空间不足的时候；3、显示调用 System.gc 的时候。另外，像 CMS 一类的垃圾回收器，在 MinorGC 出现 promotion failure 的时候也会发生 FullGC。</p>
<p><strong>对象优先在 Eden 区分配</strong><br>    大多数情况下，对象在新生代 Eden 区分配，当 Eden 区空间不够时，发起 Minor GC。</p>
<p><strong>大对象直接进入老年代</strong><br>    大对象是指需要连续内存空间的对象，比如很长的字符串以及数组。老年代直接分配的<strong>目的是</strong>避免在 Eden 区和 Survivor 区之间出现大量内存复制。</p>
<p><strong>长期存活的对象进入老年代</strong><br>    虚拟机给每个对象定义了年龄计数器，对象在 Eden 区出生之后，如果经过一次 Minor GC 之后，将进入 Survivor 区，同时对象年龄变为 1，增加到一定阈值时则进入老年代（阈值默认为 15）</p>
<p><strong>动态对象年龄判定</strong><br>    为了能更好地适应不同程序的内存状况，虚拟机并不总是要求对象的年龄必须达到阈值才能进入老年代。如果在 Survivor 区中相同年龄的所有对象的空间总和大于 Survivor 区空间的一半，则年龄大于或等于该年龄的对象直接进入老年代。</p>
<p><strong>空间分配担保</strong><br>    在发生 Minor GC 之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象的空间总和，如果这个条件成立，那么 Minor GC 可以确保是安全的。如果不成立则进行 Full GC。</p>
<h4 id="3、垃圾收集器"><a href="#3、垃圾收集器" class="headerlink" title="3、垃圾收集器"></a><strong>3、垃圾收集器</strong></h4><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gobnjx3zcej30l10ctaat.jpg" alt="img"></p>
<p>​    <strong>JDK3：Serial Parnew 关注效率</strong></p>
<p><strong>Serial：</strong></p>
<p>​        Serial 是一个单线程的收集器，它不但只会使用一个 CPU 或一条线程去完成垃圾收集工作，并且在进行垃圾收集的同时，必须暂停其他所有的工作线程，直到垃圾收集结束。适合用于客户端垃圾收集器。</p>
<p><strong>Parnew：</strong></p>
<p>​        ParNew 垃圾收集器其实是 Serial 收集器的多线程版本，也使用复制算法，除了使用多线程进行垃圾收集之外，其余的行为和 Serial 收集器完全一样，ParNew 垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程。</p>
<p>​    <strong>JDK5：parallel Scavenge+（Serial old&#x2F;parallel old）关注吞吐量</strong></p>
<p><strong>parallel Scavenge：</strong>(关注吞吐量)</p>
<p>​        Parallel Scavenge收集器关注点是吞吐量（⾼效率的利⽤CPU）。CMS等垃圾收集器的关注点更多的是⽤户线程的停顿时间（提⾼⽤户体验）；高吞吐量可以最高效率地利用 CPU 时间，尽快地完成程序的运算任务，主要适用于在后台运算而不需要太多交互的任务。</p>
<p><strong>Serial old：</strong></p>
<p>Serial收集器的⽼年代版本，它同样是⼀个单线程收集器，使用标记-整理算法。主要有两个用途：</p>
<ul>
<li><p>在 JDK1.5 之前版本中与新生代的 Parallel Scavenge 收集器搭配使用。</p>
</li>
<li><p>作为年老代中使用 CMS 收集器的后备垃圾收集方案。</p>
</li>
</ul>
<p><strong>parallel old：</strong></p>
<p>​        Parallel Scavenge收集器的⽼年代版本。使⽤多线程和“标记-整理”算法。</p>
<p><strong>JDK8-CMS：（关注最短垃圾回收停顿时间）</strong></p>
<p>​        CMS收集器是一种年老代垃圾收集器，其最主要目标是获取<strong>最短垃圾回收停顿时间</strong>，和其他年老代使用标记-整理算法不同，它使用多线程的标记-清除算法。最短的垃圾收集停顿时间可以为交互比较高的程序提高用户体验。CMS 工作机制相比其他的垃圾收集器来说更复杂，整个过程分为以下 4 个阶段：</p>
<p>​        <strong>初始标记：</strong>只是标记一下 GC Roots 能直接关联的对象，速度很快，STW。</p>
<p>​        <strong>并发标记：</strong>进行 ReferenceChains跟踪的过程，和用户线程一起工作，不需要暂停工作线程。</p>
<p>​        <strong>重新标记：</strong>为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，STW。</p>
<p>​        <strong>并发清除：</strong>清除 GC Roots 不可达对象，和用户线程一起工作，不需要暂停工作线程。</p>
<p>​        由于耗时最长的并发标记和并发清除过程中，垃圾收集线程可以和用户现在一起并发工作，所以总体上来看CMS 收集器的内存回收和用户线程是一起并发地执行。</p>
<p>​        <strong>优点：</strong>并发收集、低停顿</p>
<p>​        <strong>缺点：</strong>对CPU资源敏感；⽆法处理浮动垃圾；使⽤“标记清除”算法，会导致⼤量空间碎⽚产⽣。</p>
<p><strong>JDK9-G1：（精准控制停顿时间，避免垃圾碎片）</strong></p>
<p>​        是⼀款⾯向服务器的垃圾收集器,主要针对配备多颗处理器及⼤容量内存的机器.以极⾼概率满⾜GC停顿时间要求的同时,还具备⾼吞吐量性能特征；相比与 CMS 收集器，G1 收集器两个最突出的改进是：</p>
<p>​        【1】基于标记-整理算法，不产生内存碎片。</p>
<p>​        【2】可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。</p>
<p>​        G1 收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间，优先回收垃圾最多的区域。<strong>区域划分</strong>和<strong>优先级区域</strong>回收机制，确保 G1 收集器可以在有限时间获得最高的垃圾收集效率。</p>
<ul>
<li><p><strong>初始标记</strong>：<strong>Stop The World，</strong>仅使用一条初始标记线程对GC Roots关联的对象进行标记</p>
</li>
<li><p><strong>并发标记</strong>：使用一条标记线程与用户线程并发执行。此过程进行<strong>可达性分析，速度很慢</strong></p>
</li>
<li><p><strong>最终标记</strong>：<strong>Stop The World</strong>，使用多条标记线程并发执行</p>
</li>
<li><p><strong>筛选回收</strong>：回收废弃对象，此时也要 <strong>Stop The World</strong>，并使用多条筛选回收线程并发执行</p>
</li>
</ul>
<p>**JDK11-ZGC:**（在不关注容量的情况获取最小停顿时间5TB&#x2F;10ms）</p>
<p>​    着色笔技术：加快标记过程</p>
<p>​    读屏障：解决GC和应用之间并发导致的STW问题</p>
<ul>
<li><p>支持 TB 级堆内存（最大 4T， JDK13 最大16TB）</p>
</li>
<li><p>最大 GC 停顿 10ms</p>
</li>
<li><p>对吞吐量影响最大，不超过 15%</p>
</li>
</ul>
<h4 id="4、配置垃圾收集器"><a href="#4、配置垃圾收集器" class="headerlink" title="4、配置垃圾收集器"></a><strong>4、配置垃圾收集器</strong></h4><ul>
<li>首先是内存大小问题，基本上每一个内存区域我都会设置一个上限，来避免溢出问题，比如元空间。</li>
<li>通常，堆空间我会设置成操作系统的 2&#x2F;3，超过 8GB 的堆，优先选用 G1</li>
<li>然后我会对 JVM 进行初步优化，比如根据老年代的对象提升速度，来调整年轻代和老年代之间的比例</li>
<li>依据系统容量、访问延迟、吞吐量等进行专项优化，我们的服务是高并发的，对 STW 的时间敏感</li>
<li>我会通过记录详细的 GC 日志，来找到这个瓶颈点，借用 GCeasy 这样的日志分析工具，定位问题</li>
</ul>
<h4 id="4、JVM性能调优"><a href="#4、JVM性能调优" class="headerlink" title="4、JVM性能调优"></a><strong>4、JVM性能调优</strong></h4><p>对应进程的JVM状态以定位问题和解决问题并作出相应的优化</p>
<p><strong>常用命令：</strong>jps、jinfo、jstat、jstack、jmap</p>
<p><strong>jps：查看java进程及相关信息</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">jps -l 输出jar包路径，类全名</span><br><span class="line">jps -m 输出main参数</span><br><span class="line">jps -v 输出JVM参数</span><br></pre></td></tr></table></figure>

<p><strong>jinfo：查看JVM参数</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">jinfo <span class="number">11666</span></span><br><span class="line">jinfo -flags <span class="number">11666</span></span><br><span class="line">Xmx、Xms、Xmn、MetaspaceSize</span><br></pre></td></tr></table></figure>

<p><strong>jstat：查看JVM运行时的状态信息，包括内存状态、垃圾回收</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">jstat [option] LVMID [interval] [count]</span><br><span class="line">其中LVMID是进程id，interval是打印间隔时间（毫秒），count是打印次数（默认一直打印）</span><br><span class="line">  </span><br><span class="line">option参数解释：</span><br><span class="line">-gc 垃圾回收堆的行为统计</span><br><span class="line">-gccapacity 各个垃圾回收代容量(young,old,perm)和他们相应的空间统计</span><br><span class="line">-gcutil 垃圾回收统计概述</span><br><span class="line">-gcnew 新生代行为统计</span><br><span class="line">-gcold 年老代和永生代行为统计</span><br></pre></td></tr></table></figure>

<p><strong>jstack：查看JVM线程快照，jstack命令可以定位线程出现长时间卡顿的原因，例如死锁，死循环</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">jstack [-l] &lt;pid&gt; (连接运行中的进程)</span><br><span class="line">  </span><br><span class="line">option参数解释：</span><br><span class="line">-F 当使用jstack &lt;pid&gt;无响应时，强制输出线程堆栈。</span><br><span class="line">-m 同时输出java和本地堆栈(混合模式)</span><br><span class="line">-l 额外显示锁信息</span><br></pre></td></tr></table></figure>

<p><strong>jmap：可以用来查看内存信息</strong>(配合jhat使用)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">jmap [option] &lt;pid&gt; (连接正在执行的进程)</span><br><span class="line"></span><br><span class="line">option参数解释：</span><br><span class="line">-heap 打印java heap摘要</span><br><span class="line">-dump:&lt;dump-options&gt; 生成java堆的dump文件</span><br></pre></td></tr></table></figure>



<h4 id="5、JDK新特性"><a href="#5、JDK新特性" class="headerlink" title="5、JDK新特性"></a>5、JDK新特性</h4><p>JDK8</p>
<p>支持 Lamda 表达式、集合的 stream 操作、提升HashMap性能</p>
<p><strong>JDK9</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Stream API中iterate方法的新重载方法，可以指定什么时候结束迭代</span></span><br><span class="line">IntStream.iterate(<span class="number">1</span>, i -&gt; i &lt; <span class="number">100</span>, i -&gt; i + <span class="number">1</span>).forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<p>默认G1垃圾回收器</p>
<p><strong>JDK10</strong> </p>
<p>其重点在于通过完全GC并行来改善G1最坏情况的等待时间。</p>
<p><strong>JDK11</strong></p>
<p>ZGC (并发回收的策略) 4TB</p>
<p>用于 Lambda 参数的局部变量语法</p>
<p><strong>JDK12</strong></p>
<p>Shenandoah GC (GC 算法)停顿时间和堆的大小没有任何关系，并行关注停顿响应时间。</p>
<p><strong>JDK13</strong></p>
<p>增加ZGC以将未使用的堆内存返回给操作系统，16TB</p>
<p><strong>JDK14</strong></p>
<p>删除cms垃圾回收器、弃用ParallelScavenge+SerialOldGC垃圾回收算法组合</p>
<p>将ZGC垃圾回收器应用到macOS和windows平台</p>
<div style="page-break-after: always;"></div>

<h3 id="线上故障排查"><a href="#线上故障排查" class="headerlink" title="线上故障排查"></a>线上故障排查</h3><h4 id="1、硬件故障排查"><a href="#1、硬件故障排查" class="headerlink" title="1、硬件故障排查"></a>1、硬件故障排查</h4><p>如果一个实例发生了问题，根据情况选择，要不要着急去重启。如果出现的CPU、内存飙高或者日志里出现了OOM异常</p>
<p><strong>第一步是隔离</strong>，第二步是<strong>保留现场</strong>，第三步才是<strong>问题排查</strong>。</p>
<p><strong>隔离</strong></p>
<p>就是把你的这台机器从请求列表里摘除，比如把 nginx 相关的权重设成零。</p>
<p><strong>现场保留</strong></p>
<p><strong>瞬时态和历史态</strong></p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gobnwy22d2j30l10cpt9d.jpg" alt="img"></p>
<p>查看比如 CPU、系统内存等，通过历史状态可以体现一个趋势性问题，而这些信息的获取一般依靠监控系统的协作。           </p>
<p><strong>保留信息</strong></p>
<p>（1）<strong>系统当前网络连接</strong></p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ss</span> -antp &gt; $DUMP_DIR/ss.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>


<p>使用 ss 命令而不是 netstat 的原因，是因为 netstat 在网络连接非常多的情况下，执行非常缓慢。</p>
<p>后续的处理，可通过查看各种网络连接状态的梳理，来排查 TIME_WAIT 或者 CLOSE_WAIT，或者其他连接过高的问题，非常有用。</p>
<p>（2）<strong>网络状态统计</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -s &gt; $DUMP_DIR/netstat-s.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>


<p>它能够按照各个协议进行统计输出，对把握当时整个网络状态，有非常大的作用。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sar -n DEV <span class="number">1</span> <span class="number">2</span> &gt; $DUMP_DIR/sar-traffic.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>


<p>在一些速度非常高的模块上，比如 Redis、Kafka，就经常发生跑满网卡的情况。表现形式就是网络通信非常缓慢。</p>
<p>（3）<strong>进程资源</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof -p $PID &gt; $DUMP_DIR/lsof-$PID.dump</span><br></pre></td></tr></table></figure>


<p>通过查看进程，能看到打开了哪些文件，可以以进程的维度来查看整个资源的使用情况，包括每条网络连接、每个打开的文件句柄。同时，也可以很容易的看到连接到了哪些服务器、使用了哪些资源。这个命令在资源非常多的情况下，输出稍慢，请耐心等待。</p>
<p>（4）<strong>CPU 资源</strong></p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">mpstat</span> &gt; $DUMP_DIR/mpstat.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br><span class="line"><span class="attribute">vmstat</span> <span class="number">1</span> <span class="number">3</span> &gt; $DUMP_DIR/vmstat.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br><span class="line"><span class="attribute">sar</span> -p <span class="literal">ALL</span>  &gt; $DUMP_DIR/sar-cpu.dump  <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br><span class="line"><span class="attribute">uptime</span> &gt; $DUMP_DIR/uptime.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>主要用于输出当前系统的 CPU 和负载，便于事后排查。</p>
<p>（5）<strong>I&#x2F;O 资源</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iostat -x &gt; $DUMP_DIR/iostat.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>


<p>一般，以计算为主的服务节点，I&#x2F;O 资源会比较正常，但有时也会发生问题，比如<strong>日志输出过多，或者磁盘问题</strong>等。此命令可以输出每块磁盘的基本性能信息，用来排查 I&#x2F;O 问题。在第 8 课时介绍的 GC 日志分磁盘问题，就可以使用这个命令去发现。</p>
<p>（6）<strong>内存问题</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">free -h &gt; $DUMP_DIR/free.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>


<p>free 命令能够大体展现操作系统的内存概况，这是故障排查中一个非常重要的点，比如 SWAP 影响了 GC，SLAB 区挤占了 JVM 的内存。</p>
<p>（7）<strong>其他全局</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ps -ef &gt; $DUMP_DIR/ps.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br><span class="line">dmesg &gt; $DUMP_DIR/dmesg.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br><span class="line">sysctl -a &gt; $DUMP_DIR/sysctl.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>


<p>dmesg 是许多静悄悄死掉的服务留下的最后一点线索。当然，ps 作为执行频率最高的一个命令，由于内核的配置参数，会对系统和 JVM 产生影响，所以我们也输出了一份。</p>
<p>（8）<strong>进程快照</strong>，最后的遗言（jinfo）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$&#123;JDK_BIN&#125;jinfo $PID &gt; $DUMP_DIR/jinfo.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>


<p>此命令将输出 Java 的基本进程信息，包括<strong>环境变量和参数配置</strong>，可以查看是否因为一些错误的配置造成了 JVM 问题。</p>
<p><strong>（9）dump 堆信息</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$&#123;JDK_BIN&#125;jstat -gcutil $PID &gt; $DUMP_DIR/jstat-gcutil.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br><span class="line">$&#123;JDK_BIN&#125;jstat -gccapacity $PID &gt; $DUMP_DIR/jstat-gccapacity.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>


<p>jstat 将输出当前的 gc 信息。一般，基本能大体看出一个端倪，如果不能，可将借助 jmap 来进行分析。</p>
<p><strong>（10）堆信息</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$&#123;JDK_BIN&#125;jmap $PID &gt; $DUMP_DIR/jmap.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br><span class="line">$&#123;JDK_BIN&#125;jmap -heap $PID &gt; $DUMP_DIR/jmap-heap.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br><span class="line">$&#123;JDK_BIN&#125;jmap -histo $PID &gt; $DUMP_DIR/jmap-histo.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br><span class="line">$&#123;JDK_BIN&#125;jmap -dump:format=b,file=$DUMP_DIR/heap.bin $PID &gt; /dev/<span class="literal">null</span>  <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>


<p>jmap 将会得到当前 Java 进程的 dump 信息。如上所示，其实最有用的就是第 4 个命令，但是前面三个能够让你初步对系统概况进行大体判断。因为，第 4 个命令产生的文件，一般都非常的大。而且，需要下载下来，导入 MAT 这样的工具进行深入分析，才能获取结果。这是分析内存泄漏一个必经的过程。</p>
<p><strong>（11）JVM 执行栈</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$&#123;JDK_BIN&#125;jstack $PID &gt; $DUMP_DIR/jstack.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>


<p>jstack 将会获取当时的执行栈。一般会多次取值，我们这里取一次即可。这些信息非常有用，能够还原 Java 进程中的线程情况。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top -Hp $PID -b -n <span class="number">1</span> -c &gt;  $DUMP_DIR/top-$PID.dump <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>


<p>为了能够得到更加精细的信息，我们使用 top 命令，来获取进程中所有线程的 CPU 信息，这样，就可以看到资源到底耗费在什么地方了。</p>
<p><strong>（12）高级替补</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill -<span class="number">3</span> $PID</span><br></pre></td></tr></table></figure>


<p>有时候，jstack 并不能够运行，有很多原因，比如 Java 进程几乎不响应了等之类的情况。我们会尝试向进程发送 kill -3 信号，这个信号将会打印 jstack 的 trace 信息到日志文件中，是 jstack 的一个替补方案。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcore -o $DUMP_DIR/core $PID</span><br></pre></td></tr></table></figure>


<p>对于 jmap 无法执行的问题，也有替补，那就是 GDB 组件中的 gcore，将会生成一个 core 文件。我们可以使用如下的命令去生成 dump：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$&#123;JDK_BIN&#125;jhsdb jmap --exe $&#123;JDK&#125;java  --core $DUMP_DIR/core --binaryheap</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><strong>内存泄漏的现象</strong></li>
</ol>
<p>稍微提一下 jmap 命令，它在 9 版本里被干掉了，取而代之的是 jhsdb，你可以像下面的命令一样使用。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">jhsdb jmap  --heap --pid  <span class="number">37340</span></span><br><span class="line">jhsdb jmap  --pid  <span class="number">37288</span></span><br><span class="line">jhsdb jmap  --histo --pid  <span class="number">37340</span></span><br><span class="line">jhsdb jmap  --binaryheap --pid  <span class="number">37340</span></span><br></pre></td></tr></table></figure>

<p>一般内存溢出，表现形式就是 Old 区的占用持续上升，即使经过了多轮 GC 也没有明显改善。比如ThreadLocal里面的GC Roots，内存泄漏的根本就是，这些对象并没有切断和 GC Roots 的关系，可通过一些工具，能够看到它们的联系。</p>
<h4 id="2、报表异常-JVM调优"><a href="#2、报表异常-JVM调优" class="headerlink" title="2、报表异常 | JVM调优"></a>2、报表异常 | JVM调优</h4><p>有一个报表系统，频繁发生内存溢出，在高峰期间使用时，还会频繁的发生拒绝服务，由于大多数使用者是管理员角色，所以很快就反馈到研发这里。</p>
<p>业务场景是由于有些结果集的字段不是太全，因此需要对结果集合进行循环，并通过 HttpClient 调用其他服务的接口进行数据填充。使用 Guava 做了 JVM 内缓存，但是响应时间依然很长。</p>
<p>初步排查，JVM 的资源太少。接口 A 每次进行报表计算时，都要涉及几百兆的内存，而且在内存里驻留很长时间，有些计算又非常耗 CPU，特别的“吃”资源。而我们分配给 JVM 的内存只有 3 GB，在多人访问这些接口的时候，内存就不够用了，进而发生了 OOM。在这种情况下，没办法，只有升级机器。把机器配置升级到 4C8G，给 JVM 分配 6GB 的内存，这样 OOM 问题就消失了。但随之而来的是频繁的 GC 问题和超长的 GC 时间，平均 GC 时间竟然有 5 秒多。</p>
<p>进一步，由于报表系统和高并发系统不太一样，它的对象，存活时长大得多，并不能仅仅通过增加年轻代来解决；而且，如果增加了年轻代，那么必然减少了老年代的大小，由于 CMS 的碎片和浮动垃圾问题，我们可用的空间就更少了。虽然服务能够满足目前的需求，但还有一些不太确定的风险。</p>
<p>第一，了解到程序中有很多缓存数据和静态统计数据，为了减少 MinorGC 的次数，通过分析 GC 日志打印的对象年龄分布，把 MaxTenuringThreshold 参数调整到了 3（特殊场景特殊的配置）。这个参数是让年轻代的这些对象，赶紧回到老年代去，不要老呆在年轻代里。</p>
<p>第二，我们的 GC 时间比较长，就一块开了参数 CMSScavengeBeforeRemark，使得在 CMS remark 前，先执行一次 Minor GC 将新生代清掉。同时配合上个参数，其效果还是比较好的，一方面，对象很快晋升到了老年代，另一方面，年轻代的对象在这种情况下是有限的，在整个 MajorGC 中占的时间也有限。</p>
<p>第三，由于缓存的使用，有大量的弱引用，拿一次长达 10 秒的 GC 来说。我们发现在 GC 日志里，处理 weak refs 的时间较长，达到了 4.5 秒。这里可以加入参数 ParallelRefProcEnabled 来并行处理Reference，以加快处理速度，缩短耗时。</p>
<p>优化之后，效果不错，但并不是特别明显。经过评估，针对高峰时期的情况进行调研，我们决定再次提升机器性能，改用 8core16g 的机器。但是，这带来另外一个问题。</p>
<p><strong>高性能的机器带来了非常大的服务吞吐量</strong>，通过 jstat 进行监控，能够看到年轻代的分配速率明显提高，但随之而来的 MinorGC 时长却变的不可控，有时候会超过 1 秒。累积的请求造成了更加严重的后果。</p>
<p>这是由于堆空间明显加大造成的回收时间加长。为了获取较小的停顿时间，我们在堆上<strong>改用了 G1 垃圾回收器</strong>，把它的目标设定在 200ms。G1 是一款非常优秀的垃圾收集器，不仅适合堆内存大的应用，同时也简化了调优的工作。通过主要的参数初始和最大堆空间、以及最大容忍的 GC 暂停目标，就能得到不错的性能。修改之后，虽然 GC 更加频繁了一些，但是停顿时间都比较小，应用的运行较为平滑。</p>
<p>到目前为止，也只是勉强顶住了已有的业务，但是，这时候领导层面又发力，<strong>要求报表系统可以支持未来两年业务10到100倍的增长</strong>，并保持其可用性，但是这个“千疮百孔”的报表系统，稍微一压测，就宕机，那如何应对十倍百倍的压力呢 ? 硬件即使可以做到动态扩容，但是毕竟也有极限。</p>
<p>使用 MAT 分析堆快照，发现很多地方可以通过代码优化，那些占用内存特别多的对象：</p>
<p>1、select * 全量排查，只允许获取必须的数据</p>
<p>2、报表系统中cache实际的命中率并不高，将Guava 的 Cache 引用级别改成弱引用（WeakKeys）</p>
<p>3、限制报表导入文件大小，同时拆分用户超大范围查询导出请求。</p>
<p>每一步操作都使得JVM使用变得更加可用，一系列优化以后，机器相同压测数据性能提升了数倍。</p>
<h4 id="3、大屏异常-JUC调优"><a href="#3、大屏异常-JUC调优" class="headerlink" title="3、大屏异常 | JUC调优"></a>3、大屏异常 | JUC调优</h4><p>有些数据需要使用 HttpClient 来获取进行补全。提供数据的服务提供商有的响应时间可能会很长，也有可能会造成服务整体的阻塞。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gobr4whjzwj30l1058dfx.jpg" alt="img"></p>
<p>接口 A 通过 HttpClient 访问服务 2，响应 100ms 后返回；接口 B 访问服务 3，耗时 2 秒。HttpClient 本身是有一个最大连接数限制的，如果服务 3 迟迟不返回，就会造成 HttpClient 的连接数达到上限，<strong>概括来讲，就是同一服务，由于一个耗时非常长的接口，进而引起了整体的服务不可用</strong></p>
<p>这个时候，通过 jstack 打印栈信息，会发现大多数竟然阻塞在了接口 A 上，而不是耗时更长的接口 B，这个现象起初十分具有迷惑性，不过经过分析后，我们猜想其实是因为接口 A 的速度比较快，在问题发生点进入了更多的请求，它们全部都阻塞住的同时被打印出来了。</p>
<p>为了验证这个问题，我搭建了一个demo 工程，模拟了两个使用同一个 HttpClient 的接口。fast 接口用来访问百度，很快就能返回；slow 接口访问谷歌，由于众所周知的原因，会阻塞直到超时，大约 10 s。 利用ab对两个接口进行压测，同时使用 jstack 工具 dump 堆栈。首先使用 jps 命令找到进程号，然后把结果重定向到文件（可以参考 10271.jstack 文件）。</p>
<p>过滤一下 nio 关键字，可以查看 tomcat 相关的线程，足足有 200 个，这和 Spring Boot 默认的 maxThreads 个数不谋而合。更要命的是，有大多数线程，都处于 BLOCKED 状态，说明线程等待资源超时。通过grep fast | wc -l 分析，确实200个中有150个都是blocked的fast的进程。</p>
<p>问题找到了，解决方式就顺利成章了。</p>
<p>1、fast和slow争抢连接资源，通过线程池限流或者熔断处理</p>
<p>2、有时候slow的线程也不是一直slow，所以就得加入监控</p>
<p>3、使用带countdownLaunch对线程的执行顺序逻辑进行控制</p>
<h4 id="4、接口延迟-SWAP调优"><a href="#4、接口延迟-SWAP调优" class="headerlink" title="4、接口延迟 | SWAP调优"></a><strong>4、接口延迟 | SWAP调优</strong></h4><p>有一个关于服务的某个实例，经常发生服务卡顿。由于服务的并发量是比较高的，每多停顿 1 秒钟，几万用户的请求就会感到延迟。</p>
<p>我们统计、类比了此服务其他实例的 CPU、内存、网络、I&#x2F;O 资源，区别并不是很大，所以一度怀疑是机器硬件的问题。</p>
<p>接下来我们对比了节点的 GC 日志，发现无论是 Minor GC，还是 Major GC，这个节点所花费的时间，都比其他实例长得多。</p>
<p>通过仔细观察，我们发现在 GC 发生的时候，vmstat 的 si、so 飙升的非常严重，这和其他实例有着明显的不同。</p>
<p>使用 free 命令再次确认，发现 SWAP 分区，使用的比例非常高，引起的具体原因是什么呢？</p>
<p>更详细的操作系统内存分布，从 &#x2F;proc&#x2F;meminfo 文件中可以看到具体的逻辑内存块大小，有多达 40 项的内存信息，这些信息都可以通过遍历 &#x2F;proc 目录的一些文件获取。我们注意到 slabtop 命令显示的有一些异常，dentry（目录高速缓冲）占用非常高。</p>
<p>问题最终定位到是由于某个运维工程师删除日志时，定时执行了一句命令：</p>
<p>find &#x2F; | grep “xxx.log”</p>
<p>他是想找一个叫做 要被删除 的日志文件，看看在哪台服务器上，结果，这些老服务器由于文件太多，扫描后这些文件信息都缓存到了 slab 区上。而服务器开了 swap，操作系统发现物理内存占满后，并没有立即释放 cache，导致每次 GC 都要和硬盘打一次交道。</p>
<p><strong>解决方式就是关闭 SWAP 分区。</strong></p>
<p>swap 是很多性能场景的万恶之源，建议禁用。在高并发 SWAP 绝对能让你体验到它魔鬼性的一面：进程倒是死不了了，但 GC 时间长的却让人无法忍受。</p>
<h4 id="5、内存溢出-Cache调优"><a href="#5、内存溢出-Cache调优" class="headerlink" title="5、内存溢出 | Cache调优"></a>5、<strong>内存溢出 | Cache调优</strong></h4><blockquote>
<p>有一次线上遇到故障，重新启动后，使用 jstat 命令，发现 Old 区一直在增长。我使用 jmap 命令，导出了一份线上堆栈，然后使用 MAT 进行分析，通过对 GC Roots 的分析，发现了一个非常大的 HashMap 对象，这个原本是其他同事做缓存用的，但是做了一个无界缓存，没有设置超时时间或者 LRU 策略，在使用上又没有重写key类对象的hashcode和equals方法，对象无法取出也直接造成了堆内存占用一直上升，后来，将这个缓存改成 guava 的 Cache，并设置了弱引用，故障就消失了。</p>
<p>关于文件处理器的应用，在读取或者写入一些文件之后，由于发生了一些异常，<strong>close 方法又没有放在 finally</strong> 块里面，造成了文件句柄的泄漏。由于文件处理十分频繁，产生了严重的内存泄漏问题。</p>
</blockquote>
<p>内存溢出是一个结果，而<strong>内存泄漏</strong>是一个原因。内存溢出的原因有<strong>内存空间不足、配置错误</strong>等因素。一些错误的编程方式，不再被使用的对象、没有被回收、没有及时切断与 GC Roots 的联系，这就是内存泄漏。</p>
<p>举个例子，有团队使用了 HashMap 做缓存，但是并没有设置超时时间或者 LRU 策略，造成了放入 Map 对象的数据越来越多，而产生了内存泄漏。</p>
<p>再来看一个经常发生的内存泄漏的例子，也是由于 HashMap 产生的。代码如下，由于没有重写 Key 类的 hashCode 和 equals 方法，造成了放入 HashMap 的所有对象都无法被取出来，它们和外界失联了。所以下面的代码结果是 null。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//leak example</span></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HashMapLeakDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Key</span> &#123;</span><br><span class="line">        String title;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Key</span><span class="params">(String title)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.title = title;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">    Map&lt;Key, Integer&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">    map.put(<span class="keyword">new</span> <span class="title class_">Key</span>(<span class="string">&quot;1&quot;</span>), <span class="number">1</span>);</span><br><span class="line">    map.put(<span class="keyword">new</span> <span class="title class_">Key</span>(<span class="string">&quot;2&quot;</span>), <span class="number">2</span>);</span><br><span class="line">    map.put(<span class="keyword">new</span> <span class="title class_">Key</span>(<span class="string">&quot;3&quot;</span>), <span class="number">2</span>);</span><br><span class="line">    <span class="type">Integer</span> <span class="variable">integer</span> <span class="operator">=</span> map.get(<span class="keyword">new</span> <span class="title class_">Key</span>(<span class="string">&quot;2&quot;</span>));</span><br><span class="line">    System.out.println(integer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>即使提供了 equals 方法和 hashCode 方法，也要非常小心，尽量避免使用自定义的对象作为 Key。</p>
<p>再看一个例子，关于文件处理器的应用，在读取或者写入一些文件之后，由于发生了一些异常，<strong>close 方法又没有放在 finally</strong> 块里面，造成了文件句柄的泄漏。由于文件处理十分频繁，产生了严重的内存泄漏问题。</p>
<h4 id="6：CPU飙高-死循环"><a href="#6：CPU飙高-死循环" class="headerlink" title="6：CPU飙高 | 死循环"></a>6：CPU飙高 | 死循环</h4><p>我们有个线上应用，单节点在运行一段时间后，CPU 的使用会飙升，一旦飙升，一般怀疑某个业务逻辑的计算量太大，或者是触发了死循环（比如著名的 HashMap 高并发引起的死循环），但排查到最后其实是 GC 的问题。        </p>
<p>（1）使用 top 命令，查找到使用 CPU 最多的某个进程，记录它的 pid。使用 Shift + P 快捷键可以按 CPU 的使用率进行排序。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top</span><br></pre></td></tr></table></figure>


<p>（2）再次使用 top 命令，加 -H 参数，查看某个进程中使用 CPU 最多的某个线程，记录线程的 ID。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top -Hp $pid</span><br></pre></td></tr></table></figure>


<p>（3）使用 printf 函数，将十进制的 tid 转化成十六进制。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">printf %x $tid</span><br></pre></td></tr></table></figure>


<p>（4）使用 jstack 命令，查看 Java 进程的线程栈。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jstack $pid &gt;$pid.log</span><br></pre></td></tr></table></figure>


<p>（5）使用 less 命令查看生成的文件，并查找刚才转化的十六进制 tid，找到发生问题的线程上下文。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">less $pid.log</span><br></pre></td></tr></table></figure>


<p>我们在 jstack 日志搜关键字DEAD，以及中找到了 CPU 使用最多的几个线程id。</p>
<p>可以看到问题发生的根源，是我们的堆已经满了，但是又没有发生 OOM，于是 GC 进程就一直在那里回收，回收的效果又非常一般，造成 CPU 升高应用假死。接下来的具体问题排查，就需要把内存 dump 一份下来，使用 MAT 等工具分析具体原因了。</p>
<h1 id="三、多线程篇"><a href="#三、多线程篇" class="headerlink" title="三、多线程篇"></a>三、多线程篇</h1><h3 id="线程调度"><a href="#线程调度" class="headerlink" title="线程调度"></a>线程调度</h3><h4 id="1、线程状态"><a href="#1、线程状态" class="headerlink" title="1、线程状态"></a><strong>1、线程状态</strong></h4><p>​        线程是cpu任务调度的最小执行单位，每个线程拥有自己独立的程序计数器、虚拟机栈、本地方法栈</p>
<p><strong>线程状态：创建、就绪、运行、阻塞、死亡</strong></p>
<img src="https://s0.lgstatic.com/i/image3/M01/77/29/Cgq2xl5xxGKAKBpeAAEw9Ifr07Y662.png" alt="img" style="zoom: 40%;" />



<h4 id="2、线程状态切换"><a href="#2、线程状态切换" class="headerlink" title="2、线程状态切换"></a><strong>2、线程状态切换</strong></h4><table>
<thead>
<tr>
<th>方法</th>
<th>作用</th>
<th>区别</th>
</tr>
</thead>
<tbody><tr>
<td>start</td>
<td>启动线程，由虚拟机自动调度执行run()方法</td>
<td>线程处于就绪状态</td>
</tr>
<tr>
<td>run</td>
<td>线程逻辑代码块处理，JVM调度执行</td>
<td>线程处于运行状态</td>
</tr>
<tr>
<td>sleep</td>
<td>让当前正在执行的线程休眠（暂停执行）</td>
<td>不释放锁</td>
</tr>
<tr>
<td>wait</td>
<td>使得当前线程等待</td>
<td>释放同步锁</td>
</tr>
<tr>
<td>notify</td>
<td>唤醒在此对象监视器上等待的单个线程</td>
<td>唤醒单个线程</td>
</tr>
<tr>
<td>notifyAll</td>
<td>唤醒在此对象监视器上等待的所有线程</td>
<td>唤醒多个线程</td>
</tr>
<tr>
<td>yiled</td>
<td>停止当前线程，让同等优先权的线程运行</td>
<td>用Thread类调用</td>
</tr>
<tr>
<td>join</td>
<td>使当前线程停下来等待，直至另一个调用join方法的线程终止</td>
<td>用线程对象调用</td>
</tr>
</tbody></table>
<img src="https://s0.lgstatic.com/i/image/M00/80/24/Ciqc1F_Qfy2ACkrLAAD2DLkc2qw212.png" alt="img" style="zoom:67%;" />

<h4 id="3、阻塞唤醒过程"><a href="#3、阻塞唤醒过程" class="headerlink" title="3、阻塞唤醒过程"></a><strong>3、阻塞唤醒过程</strong></h4><p><strong>阻塞：</strong></p>
<p>​        这三个方法的调用都会使当前线程阻塞。该线程将会被放置到对该Object的请求等待队列中，然后让出当前对Object所拥有的所有的同步请求。线程会一直暂停所有线程调度，直到下面其中一种情况发生：</p>
<p>　　　　① 其他线程调用了该Object的notify方法，而该线程刚好是那个被唤醒的线程；</p>
<p>　　　　② 其他线程调用了该Object的notifyAll方法；</p>
<p><strong>唤醒：</strong></p>
<p>​        线程将会从等待队列中移除，重新成为可调度线程。它会与其他线程以常规的方式竞争对象同步请求。<strong>一旦它重新获得对象的同步请求，所有之前的请求状态都会恢复，也就是线程调用wait的地方的状态。线程将会在之前调用wait的地方继续运行下去。</strong></p>
<p><strong>为什么要出现在同步代码块中：</strong></p>
<p>​        由于<code>wait()属于Object方法，调用之后会强制释放当前对象锁，所以在wait()</code> 调用时必须拿到当前对象的监视器monitor对象。因此，wait()方法在同步方法&#x2F;代码块中调用。</p>
<h4 id="4、wait和sleep区别"><a href="#4、wait和sleep区别" class="headerlink" title="4、wait和sleep区别"></a><strong>4、wait和sleep区别</strong></h4><ul>
<li><p>wait 方法必须在 synchronized 保护的代码中使用，而 sleep 方法并没有这个要求。</p>
</li>
<li><p>wait 方法会主动释放 monitor 锁，在同步代码中执行 sleep 方法时，并不会释放 monitor 锁。</p>
</li>
<li><p>wait 方法意味着永久等待，直到被中断或被唤醒才能恢复，不会主动恢复，sleep 方法中会定义一个时间，时间到期后会主动恢复。</p>
</li>
<li><p>wait&#x2F;notify 是 Object 类的方法，而 sleep 是 Thread 类的方法。</p>
</li>
</ul>
<h4 id="5、创建线程方式"><a href="#5、创建线程方式" class="headerlink" title="5、创建线程方式"></a>5、创建线程方式</h4><p><strong>实现 Runnable 接口</strong>（优先使用）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RunnableThread</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;System.out.println(<span class="string">&#x27;用实现Runnable接口实现线程&#x27;</span>);&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>实现Callable接口</strong>（有返回值可抛出异常）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CallableTask</span> <span class="keyword">implements</span> <span class="title class_">Callable</span>&lt;Integer&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Integer <span class="title function_">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123; <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Random</span>().nextInt();&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>继承Thread类</strong>（java不支持多继承）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ExtendsThread</span> <span class="keyword">extends</span> <span class="title class_">Thread</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;System.out.println(<span class="string">&#x27;用Thread类实现线程&#x27;</span>);&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>使用线程池</strong>（底层都是实现run方法）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">DefaultThreadFactory</span> <span class="keyword">implements</span> <span class="title class_">ThreadFactory</span> &#123;</span><br><span class="line">    DefaultThreadFactory() &#123;</span><br><span class="line">        <span class="type">SecurityManager</span> <span class="variable">s</span> <span class="operator">=</span> System.getSecurityManager();</span><br><span class="line">        group = (s != <span class="literal">null</span>) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup();</span><br><span class="line">        namePrefix = <span class="string">&quot;pool-&quot;</span> + poolNumber.getAndIncrement() +<span class="string">&quot;-thread-&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> Thread <span class="title function_">newThread</span><span class="params">(Runnable r)</span> &#123;</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(group, r,namePrefix + threadNumber.getAndIncrement(),<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (t.isDaemon()) t.setDaemon(<span class="literal">false</span>);  <span class="comment">//是否守护线程</span></span><br><span class="line">        <span class="keyword">if</span> (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); <span class="comment">//线程优先级</span></span><br><span class="line">        <span class="keyword">return</span> t;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<div style="page-break-after: always;"></div>

<h3 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h3><p>优点：通过复用已创建的线程，<strong>降低资源损耗</strong>、线程可以直接处理队列中的任务<strong>加快响应速度</strong>、同时便于<strong>统一监控和管理</strong>。</p>
<h4 id="1、线程池构造函数"><a href="#1、线程池构造函数" class="headerlink" title="1、线程池构造函数"></a><strong>1、线程池构造函数</strong></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 线程池构造函数7大参数</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">ThreadPoolExecutor</span><span class="params">(<span class="type">int</span> corePoolSize,<span class="type">int</span> maximumPoolSize,<span class="type">long</span> keepAliveTime,</span></span><br><span class="line"><span class="params">    TimeUnit unit,BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,</span></span><br><span class="line"><span class="params">    RejectedExecutionHandler handler)</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p><strong>参数介绍：</strong></p>
<table>
<thead>
<tr>
<th>参数</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>corePoolSize</td>
<td>核心线程池大小</td>
</tr>
<tr>
<td>maximumPoolSize</td>
<td>最大线程池大小</td>
</tr>
<tr>
<td>keepAliveTime</td>
<td>线程池中超过 corePoolSize 数目的空闲线程最大存活时间；</td>
</tr>
<tr>
<td>TimeUnit</td>
<td>keepAliveTime 时间单位</td>
</tr>
<tr>
<td>workQueue</td>
<td>阻塞任务队列</td>
</tr>
<tr>
<td>threadFactory</td>
<td>新建线程工厂</td>
</tr>
<tr>
<td>RejectedExecutionHandler</td>
<td>拒绝策略。当提交任务数超过 maxmumPoolSize+workQueue 之和时，任务会交给RejectedExecutionHandler 来处理</td>
</tr>
</tbody></table>
<h4 id="2、线程处理任务过程："><a href="#2、线程处理任务过程：" class="headerlink" title="2、线程处理任务过程："></a><strong>2、线程处理任务过程：</strong></h4><img src="https://s0.lgstatic.com/i/image3/M01/78/50/Cgq2xl5zjxGAXOA-AABF0Dv8GMI518.png" alt="img" style="zoom: 67%;" />

<ol>
<li>当线程池小于corePoolSize，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。</li>
<li>当线程池达到corePoolSize时，新提交任务将被放入 workQueue 中，等待线程池中任务调度执行。</li>
<li>当workQueue已满，且 maximumPoolSize 大于 corePoolSize 时，新提交任务会创建新线程执行任务。</li>
<li>当提交任务数超过 maximumPoolSize 时，新提交任务由 RejectedExecutionHandler 处理。</li>
<li>当线程池中超过corePoolSize 线程，空闲时间达到 keepAliveTime 时，关闭空闲线程 。</li>
</ol>
<h4 id="3、线程拒绝策略"><a href="#3、线程拒绝策略" class="headerlink" title="3、线程拒绝策略"></a><strong>3、线程拒绝策略</strong></h4><p>​        线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，再也塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。</p>
<p>JDK 内置的拒绝策略如下：</p>
<p>​        <strong>AbortPolicy：</strong>直接抛出异常，阻止系统正常运行。可以根据业务逻辑选择重试或者放弃提交等策略。</p>
<p>​        <strong>CallerRunsPolicy ：</strong>只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。</p>
<p>​                不会造成任务丢失，同时减缓提交任务的速度，给执行任务缓冲时间。</p>
<p>​        <strong>DiscardOldestPolicy ：</strong>丢弃最老的一个请求，也就是即将被执行的任务，并尝试再次提交当前任务。</p>
<p>​        <strong>DiscardPolicy ：</strong>该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。</p>
<h4 id="4、Execuors类实现线程池"><a href="#4、Execuors类实现线程池" class="headerlink" title="4、Execuors类实现线程池"></a><strong>4、Execuors类实现线程池</strong></h4><img src="https://s0.lgstatic.com/i/image3/M01/63/5A/CgpOIF4z1EiAFjNQAAAtVe5xjgQ999.png" alt="img" style="zoom: 50%;" />

<ul>
<li><strong>newSingleThreadExecutor()：</strong>只有一个线程的线程池，任务是顺序执行，适用于一个一个任务执行的场景</li>
<li><strong>newCachedThreadPool()：</strong>线程池里有很多线程需要同时执行，60s内复用，适用执行很多短期异步的小程序或者负载较轻的服务</li>
<li><strong>newFixedThreadPool()：</strong>拥有固定线程数的线程池，如果没有任务执行，那么线程会一直等待，适用执行长期的任务。</li>
<li><strong>newScheduledThreadPool()：</strong>用来调度即将执行的任务的线程池</li>
<li>**newWorkStealingPool()**：底层采用forkjoin的Deque，采用独立的任务队列可以减少竞争同时加快任务处理</li>
<li></li>
<li><img src="https://s0.lgstatic.com/i/image2/M01/AF/80/CgoB5l3kzomAckv5AAAxf6FCPco696.png" alt="img" style="zoom:50%;" /></li>
</ul>
<p><strong>因为以上方式都存在弊端：</strong></p>
<p>​        FixedThreadPool 和 SingleThreadExecutor ： 允许请求的<strong>队列⻓度</strong>为 Integer.MAX_VALUE，会导致OOM。<br>​        CachedThreadPool 和 ScheduledThreadPool ： 允许创建的<strong>线程数量</strong>为 Integer.MAX_VALUE，会导致OOM。</p>
<p>手动创建的线程池底层使用的是ArrayBlockingQueue可以防止OOM。</p>
<h4 id="5、线程池大小设置"><a href="#5、线程池大小设置" class="headerlink" title="5、线程池大小设置"></a><strong>5、线程池大小设置</strong></h4><ul>
<li>CPU 密集型（n+1）</li>
</ul>
<p>​    CPU 密集的意思是该任务需要大量的运算，而没有阻塞，CPU 一直全速运行。</p>
<p>​    CPU 密集型任务尽可能的少的线程数量，一般为 CPU 核数 + 1 个线程的线程池。</p>
<ul>
<li>IO 密集型（2*n）</li>
</ul>
<p>​    由于 IO 密集型任务线程并不是一直在执行任务，可以多分配一点线程数，如 CPU * 2 </p>
<p>​    也可以使用公式：CPU 核心数 *（1+平均等待时间&#x2F;平均工作时间）。</p>
<div style="page-break-after: always;"></div>

<h3 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h3><h4 id="1、乐观锁，CAS思想"><a href="#1、乐观锁，CAS思想" class="headerlink" title="1、乐观锁，CAS思想"></a><strong>1、乐观锁，CAS思想</strong></h4><p><strong>java乐观锁机制：</strong></p>
<p>​        乐观锁体现的是悲观锁的反面。它是一种积极的思想，它总是认为数据是不会被修改的，所以是不会对数据上锁的。但是乐观锁在更新的时候会去判断数据是否被更新过。乐观锁的实现方案一般有两种（版本号机制和CAS）。乐观锁适用于<strong>读多写少的场景，这样可以提高系统的并发量</strong>。在Java中 <strong>java.util.concurrent.atomic</strong>下的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。</p>
<p>　　乐观锁，大多是基于数据版本  (Version)记录机制实现。即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来 实现。 读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提 交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据 版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。</p>
<p><strong>CAS思想：</strong></p>
<p>​        CAS就是compare and swap（<strong>比较交换</strong>），是一种很出名的无锁的算法，就是可以不使用锁机制实现线程间的同步。使用CAS线程是不会被阻塞的，所以又称为非阻塞同步。CAS算法涉及到三个操作：</p>
<p>​        需要读写内存值V；进行比较的值A；准备写入的值B</p>
<p>​        当且仅当V的值等于A的值等于V的值的时候，才用B的值去更新V的值，否则不会执行任何操作（比较和替换是一个原子操作-A和V比较，V和B替换），一般情况下是一个<strong>自旋操作</strong>，即<strong>不断重试</strong></p>
<p><strong>缺点：</strong></p>
<p>​        <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/23281499/answer/854522984">ABA问题-知乎</a></p>
<p>​        高并发的情况下，很容易发生并发冲突，如果CAS一直失败，那么就会一直重试，浪费CPU资源</p>
<p><strong>原子性：</strong></p>
<p>​        功能限制CAS是能保证单个变量的操作是原子性的，在Java中要配合使用volatile关键字来保证线程的安全；当涉及到多个变量的时候CAS无能为力；除此之外CAS实现需要硬件层面的支持，在Java的普通用户中无法直接使用，只能<strong>借助atomic包下的原子类</strong>实现，灵活性受到了限制</p>
<h4 id="2、synchronized底层实现"><a href="#2、synchronized底层实现" class="headerlink" title="2、synchronized底层实现"></a><strong>2、synchronized底层实现</strong></h4><p><strong>使用方法：</strong>主要的三种使⽤⽅式</p>
<p>​        <strong>修饰实例⽅法:</strong> 作⽤于当前对象实例加锁，进⼊同步代码前要获得当前对象实例的锁</p>
<p>​        <strong>修饰静态⽅法:</strong> 也就是给当前类加锁，会作⽤于类的所有对象实例，因为静态成员不属于任何⼀个实例对象，是类成员。</p>
<p>​        <strong>修饰代码块:</strong> 指定加锁对象，对给定对象加锁，进⼊同步代码库前要获得给定对象的锁。</p>
<p>​        <strong>总结：</strong>synchronized锁住的资源只有两类：一个是<strong>对象</strong>，一个是<strong>类</strong>。</p>
<p><strong>底层实现：</strong></p>
<p>​        对象头是我们需要关注的重点，它是synchronized实现锁的基础，因为synchronized申请锁、上锁、释放锁都与对象头有关。对象头主要结构是由<code>Mark Word</code> 组成，<strong>其中<code>Mark Word</code>存储对象的hashCode、锁信息或分代年龄或GC标志等信息</strong>。</p>
<p>​        锁也分不同状态，JDK6之前只有两个状态：无锁、有锁（重量级锁），而在JDK6之后对synchronized进行了优化，新增了两种状态，总共就是四个状态：<strong>无锁状态、偏向锁、轻量级锁、重量级锁</strong>，其中无锁就是一种状态了。锁的类型和状态在对象头<code>Mark Word</code>中都有记录，在申请锁、锁升级等过程中JVM都需要读取对象的<code>Mark Word</code>数据。</p>
<p>​        同步代码块是利用 monitorenter 和 monitorexit 指令实现的，而同步方法则是利用 flags 实现的。</p>
<h4 id="3、ReenTrantLock底层实现"><a href="#3、ReenTrantLock底层实现" class="headerlink" title="3、ReenTrantLock底层实现"></a><strong>3、ReenTrantLock底层实现</strong></h4><p>​        由于ReentrantLock是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能</p>
<p><strong>使用方法：</strong></p>
<p>​        基于API层面的互斥锁，需要lock()和unlock()方法配合try&#x2F;finally语句块来完成</p>
<p><strong>底层实现：</strong></p>
<p>​        ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。</p>
<p><strong>和synchronized区别：</strong></p>
<p>​        1、<strong>底层实现</strong>：synchronized 是<strong>JVM</strong>层面的锁，是<strong>Java关键字</strong>，通过monitor对象来完成（monitorenter与monitorexit），ReentrantLock 是从jdk1.5以来（java.util.concurrent.locks.Lock）提供的<strong>API层面</strong>的锁。</p>
<p>​        2、<strong>实现原理****：synchronized 的实现涉及到</strong>锁的升级<strong>，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁；ReentrantLock实现则是通过利用</strong>CAS**（CompareAndSwap）自旋机制保证线程操作的原子性和volatile保证数据可见性以实现锁的功能。</p>
<p>​        3、<strong>是否可手动释放：</strong>synchronized 不需要用户去手动释放锁，synchronized 代码执行完后系统会自动让线程释放对锁的占用； ReentrantLock则需要用户去手动释放锁，如果没有手动释放锁，就可能导致<strong>死锁现象</strong>。</p>
<p>​        4、<strong>是否可中断</strong>synchronized是不可中断类型的锁，除非加锁的代码中出现异常或正常执行完成； ReentrantLock则可以中断，可通过trylock(long timeout,TimeUnit unit)设置超时方法或者将lockInterruptibly()放到代码块中，调用interrupt方法进行中断。</p>
<p>​        5、<strong>是否公平锁</strong>synchronized为非公平锁 ReentrantLock则即可以选公平锁也可以选非公平锁，通过构造方法new ReentrantLock时传入boolean值进行选择，为空默认false非公平锁，true为公平锁,公平锁性能非常低。</p>
<h4 id="4、公平锁和非公平锁区别"><a href="#4、公平锁和非公平锁区别" class="headerlink" title="4、公平锁和非公平锁区别"></a><strong>4、公平锁和非公平锁区别</strong></h4><p><strong>公平锁：</strong></p>
<p>​        公平锁自然是遵循<strong>FIFO</strong>（先进先出）原则的，先到的线程会优先获取资源，后到的会进行排队等待</p>
<p>​        <strong>优点：</strong>所有的线程都能得到资源，不会饿死在队列中。适合大任务</p>
<p>​        <strong>缺点：</strong>吞吐量会下降，队列里面除了第一个线程，其他的线程都会阻塞，cpu唤醒阻塞线程的开销大</p>
<p><strong>非公平锁：</strong></p>
<p>​        多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁。</p>
<p>​        <strong>优点：</strong>可以减少CPU唤醒线程的开销，整体的吞吐效率会高点，CPU也不必取唤醒所有线程，会减少唤起线程的数量。</p>
<p>​        <strong>缺点：</strong>你们可能也发现了，这样可能导致队列中间的线程一直获取不到锁或者长时间获取不到锁</p>
<img src="https://s0.lgstatic.com/i/image3/M01/02/7D/Ciqah157DAiAK_DJAAC0JawhGp4730.png" alt="img" style="zoom:67%;" />

<p><strong>公平锁效率低原因：</strong></p>
<p>​        公平锁要维护一个队列，后来的线程要加锁，即使锁空闲，也要先检查有没有其他线程在 wait，如果有自己要挂起，加到队列后面，然后唤醒队列最前面线程。这种情况下相比较非公平锁多了一次<strong>挂起和唤醒</strong>。</p>
<p>​        <strong>线程切换的开销</strong>，其实就是非公平锁效率高于公平锁的原因，因为<strong>非公平锁减少了线程挂起的几率</strong>，后来的线程有一定几率逃离被挂起的开销。</p>
<h4 id="5、使用层面锁优化"><a href="#5、使用层面锁优化" class="headerlink" title="5、使用层面锁优化"></a><strong>5、使用层面锁优化</strong></h4><p>​    【1】<strong>减少锁的时间：</strong><br>​        不需要同步执行的代码，能不放在同步快里面执行就不要放在同步快内，可以让锁尽快释放；</p>
<p>​    【2】<strong>减少锁的粒度：</strong><br>​        它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。它的思想也是用空间来换时间；java中很多数据结构都是采用这种方法提高并发操作的效率，比如：</p>
<p>​        <strong>ConcurrentHashMap：</strong></p>
<p>​        java中的ConcurrentHashMap在jdk1.8之前的版本，使用一个Segment 数组：Segment&lt; K,V &gt;[] segments</p>
<p>​        Segment继承自ReenTrantLock，所以每个Segment是个可重入锁，每个Segment 有一个HashEntry&lt; K,V &gt;数组用来存放数据，put操作时，先确定往哪个Segment放数据，只需要锁定这个Segment，执行put，其它的Segment不会被锁定；所以数组中有多少个Segment就允许同一时刻多少个线程存放数据，这样增加了并发能力。</p>
<p>​    【3】<strong>锁粗化：</strong><br>​        大部分情况下我们是要让锁的粒度最小化，锁的粗化则是要增大锁的粒度; </p>
<p>​        假如有一个循环，循环内的操作需要加锁，我们应该把锁放到循环外面，否则每次进出循环，都进出一次临界区，效率是非常差的；</p>
<p>​    【4】<strong>使用读写锁：</strong></p>
<p>​        ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可并发读，写操作使用写锁，只能单线程写；</p>
<p>​    【5】<strong>使用CAS：</strong></p>
<p>​        如果需要同步的操作执行速度非常快，并且线程竞争并不激烈，这时候使用cas效率会更高，因为加锁会导致线程的上下文切换，如果上下文切换的耗时比同步操作本身更耗时，且线程对资源的竞争不激烈，使用volatiled+cas操作会是非常高效的选择；</p>
<h4 id="6、系统层面锁优化"><a href="#6、系统层面锁优化" class="headerlink" title="6、系统层面锁优化"></a>6、系统层面锁优化</h4><p><strong>自适应自旋锁：</strong></p>
<p>​        自旋锁可以避免等待竞争锁进入阻塞挂起状态被唤醒造成的<strong>内核态和用户态之间的切换</strong>的损耗，它们只需要等一等（自旋），但是如果锁被其他线程长时间占用，一直不释放CPU，死等会带来更多的性能开销；自旋次数默认值是10</p>
<p>​        对上面自旋锁优化方式的进一步优化，它的自旋的次数不再固定，其自旋的次数由前一次在同一个锁上的<strong>自旋时间及锁的拥有者的状态</strong>来决定，这就解决了自旋锁带来的缺点</p>
<p><strong>锁消除：</strong></p>
<p>​        锁削除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行削除。Netty中无锁化设计pipeline中channelhandler会进行锁消除的优化。</p>
<p><strong>锁升级：</strong></p>
<p>​    <strong>偏向锁：</strong></p>
<p>​        如果线程已经占有这个锁，当他在次试图去获取这个锁的时候，他会已最快的方式去拿到这个锁，而不需要在进行一些monitor操作，因为在大部分情况下是没有竞争的，所以使用偏向锁是可以提高性能的；</p>
<p>​    <strong>轻量级锁：</strong></p>
<p>​        在竞争不激烈的情况下，通过CAS避免线程上下文切换，可以显著的提高性能。</p>
<p>​    <strong>重量级锁：</strong></p>
<p>​        重量级锁的加锁、解锁过程造成的损耗是固定的，重量级锁适合于竞争激烈、高并发、同步块执行时间长的情况。</p>
<h4 id="7、ThreadLocal原理"><a href="#7、ThreadLocal原理" class="headerlink" title="7、ThreadLocal原理"></a><strong>7、ThreadLocal原理</strong></h4><p><strong>ThreadLocal简介：</strong></p>
<p>​        通常情况下，我们创建的变量是可以被任何⼀个线程访问并修改的。如果想实现每⼀个线程都有⾃⼰的<br>专属本地变量该如何解决呢？ JDK中提供的 ThreadLocal 类正是为了解决这样的问题。类似操作系统中的TLAB</p>
<p><strong>原理：</strong></p>
<p>​        首先 ThreadLocal 是一个泛型类，保证可以接受任何类型的对象。因为一个线程内可以存在多个 ThreadLocal 对象，所以其实是 ThreadLocal 内部维护了一个 Map ，是 ThreadLocal 实现的一个叫做 ThreadLocalMap 的静态内部类。</p>
<p>​        最终的变量是放在了当前线程的 <code>ThreadLocalMap</code> 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。</p>
<p>​        我们使用的 get()、set() 方法其实都是调用了这个ThreadLocalMap类对应的 get()、set() 方法。例如下面的 </p>
<p><strong>如何使用：</strong></p>
<p>​        1）存储用户Session</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">ThreadLocal</span> <span class="variable">threadSession</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadLocal</span>();</span><br></pre></td></tr></table></figure>

<p>​        2）解决线程安全的问题</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> ThreadLocal&lt;SimpleDateFormat&gt; format1 = <span class="keyword">new</span> <span class="title class_">ThreadLocal</span>&lt;SimpleDateFormat&gt;()</span><br></pre></td></tr></table></figure>



<p><strong>ThreadLocal内存泄漏的场景</strong> </p>
<p>​        实际上 ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，⽽ value 是强引⽤。弱引用的特点是，如果这个对象持有弱引用，那么在下一次垃圾回收的时候必然会被清理掉。</p>
<p>​        所以如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候会被清理掉的，这样一来 ThreadLocalMap中使用这个 ThreadLocal 的 key 也会被清理掉。但是，value 是强引用，不会被清理，这样一来就会出现 key 为 null 的 value。 假如我们不做任何措施的话，value 永远⽆法被GC 回收，如果线程长时间不被销毁，可能会产⽣内存泄露。</p>
<img src="https://s0.lgstatic.com/i/image3/M01/68/C4/Cgq2xl5Pld-AHFhJAADLtGXmSxc833.png" alt="img" style="zoom:67%;" />

<p>​        ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。如果说会出现内存泄漏，那只有在出现了 key 为 null 的记录后，没有手动调用 remove() 方法，并且之后也不再调用 get()、set()、remove() 方法的情况下。因此使⽤完ThreadLocal ⽅法后，<strong>最好⼿动调⽤ remove() ⽅法</strong>。</p>
<h4 id="8、HashMap线程安全"><a href="#8、HashMap线程安全" class="headerlink" title="8、HashMap线程安全"></a><strong>8、HashMap线程安全</strong></h4><p>​    <strong>死循环造成 CPU 100%</strong></p>
<p>​        HashMap 有可能会发生死循环并且造成  CPU 100% ，这种情况发生最主要的原因就是在<strong>扩容</strong>的时候，也就是内部<strong>新建新的 HashMap</strong> 的时候，扩容的逻辑会<strong>反转散列桶中的节点顺序</strong>，当有多个线程同时进行扩容的时候，由于 HashMap 并非线程安全的，所以如果<strong>两个线程同时反转的话，便可能形成一个循环</strong>，并且这种循环是链表的循环，相当于 A 节点指向 B 节点，B 节点又指回到 A 节点，这样一来，在下一次想要获取该 key 所对应的 value 的时候，便会在遍历链表的时候发生永远无法遍历结束的情况，也就发生 CPU 100% 的情况。</p>
<p>​        所以综上所述，HashMap 是线程不安全的，在多线程使用场景中推荐使用线程安全同时性能比较好的 ConcurrentHashMap。</p>
<h4 id="9、String不可变原因"><a href="#9、String不可变原因" class="headerlink" title="9、String不可变原因"></a>9、String不可变原因</h4><ol>
<li><p>可以使用<strong>字符串常量池</strong>，多次创建同样的字符串会指向同一个内存地址</p>
</li>
<li><p>可以很方便地用作 <strong>HashMap 的 key</strong>。通常建议把不可变对象作为 HashMap的 key</p>
</li>
<li><p>hashCode生成后就不会改变，使用时无需重新计算</p>
</li>
<li><p>线程安全，因为具备不变性的对象一定是线程安全的</p>
</li>
</ol>
<div style="page-break-after: always;"></div>

<h3 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h3><p>​        Java 内存模型（Java Memory Model，JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了 Java 程序在各种平台下对内存的访问都能保证效果一致的机制及规范。</p>
<p><img src="https://s0.lgstatic.com/i/image3/M01/7A/05/Cgq2xl54fTKALhevAAB_l3axT_o532.png" alt="img"></p>
<p>​        JMM 是一种规范，是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。目的是保证并发编程场景中的原子性、可见性和有序性。</p>
<p><strong>原子性：</strong></p>
<p>​        在 Java 中，为了保证原子性，提供了两个高级的字节码指令 Monitorenter 和 Monitorexit。这两个字节码，在 Java 中对应的关键字就是 Synchronized。因此，在 Java 中可以使用 Synchronized 来保证方法和代码块内的操作是原子性的。</p>
<p><strong>可见性：</strong></p>
<p>​        Java 中的 Volatile 关键字修饰的变量在被修改后可以立即同步到主内存。被其修饰的变量在每次使用之前都从主内存刷新。因此，可以使用 Volatile 来保证多线程操作时变量的可见性。除了 Volatile，Java 中的 Synchronized 和 Final 两个关键字也可以实现可见性。只不过实现方式不同</p>
<p><strong>有序性</strong></p>
<p>​        在 Java 中，可以使用 Synchronized 和 Volatile 来保证多线程之间操作的有序性。区别：Volatile 禁止指令重排。Synchronized 保证同一时刻只允许一条线程操作。</p>
<h4 id="1、volatile底层实现"><a href="#1、volatile底层实现" class="headerlink" title="1、volatile底层实现"></a><strong>1、volatile底层实现</strong></h4><p><strong>作用：</strong></p>
<p>​        保证数据的“可见性”：被volatile修饰的变量能够保证每个线程能够获取该变量的最新值，从而避免出现数据脏读的现象。</p>
<p>​        禁止指令重排：在多线程操作情况下，指令重排会导致计算结果不一致</p>
<p><strong>底层实现：</strong></p>
<p>​        “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”</p>
<p>　　lock前缀指令实际上相当于一个<strong>内存屏障</strong>（也成内存栅栏），内存屏障会提供3个功能：</p>
<p>　　1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；</p>
<p>　　2）它会强制将对缓存的修改操作立即写入主存；</p>
<p>　　3）如果是写操作，它会导致其他CPU中对应的缓存行无效。</p>
<p><strong>单例模式中volatile的作用：</strong></p>
<p>防止代码读取到instance不为null时，instance引用的对象有可能还没有完成初始化。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> <span class="type">Singleton</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="literal">null</span>;   <span class="comment">//禁止指令重排</span></span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;</span><br><span class="line">         </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(instance==<span class="literal">null</span>) &#123; <span class="comment">//减少加锁的损耗</span></span><br><span class="line">            <span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line">                <span class="keyword">if</span>(instance==<span class="literal">null</span>) <span class="comment">//确认是否初始化完成</span></span><br><span class="line">                    instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="2、AQS思想"><a href="#2、AQS思想" class="headerlink" title="2、AQS思想"></a><strong>2、AQS思想</strong></h4><p>​        AQS的全称为（AbstractQueuedSynchronizer）抽象的队列式的同步器，是⼀个⽤来构建锁和同步器的框架，使⽤AQS能简单且⾼效地构造出应⽤⼴泛的⼤量的同步器，如：基于AQS实现的lock, CountDownLatch、CyclicBarrier、Semaphore需解决的问题：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">状态的原子性管理</span><br><span class="line">线程的阻塞与解除阻塞</span><br><span class="line">队列的管理</span><br></pre></td></tr></table></figure>

<p>​        AQS核⼼思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的⼯作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占⽤，那么就需要⼀套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是⽤<strong>CLH（虚拟的双向队列）</strong>队列锁实现的，即将暂时获取不到锁的线程加⼊到队列中。</p>
<p><strong>lock：</strong></p>
<p>​        是一种可重入锁，除了能完成 synchronized 所能完成的所有工作外，还提供了诸如可响应中断锁、可轮询锁请求、定时锁等避免多线程死锁的方法。默认为非公平锁，但可以初始化为公平锁； 通过方法 lock()与 unlock()来进行加锁与解锁操作；</p>
<p><strong>CountDownLatch：</strong></p>
<p>​        通过计数法（倒计时器），让一些线程堵塞直到另一个线程完成一系列操作后才被唤醒；该⼯具通常⽤来控制线程等待，它可以让某⼀个线程等待直到倒计时结束，再开始执⾏。具体可以使用countDownLatch.await()来等待结果。多用于多线程信息汇总。</p>
<p><strong>CompletableFuture：</strong></p>
<p>​        通过设置参数，可以完成CountDownLatch同样的多平台响应问题，但是可以针对其中部分返回结果做更加灵活的展示。</p>
<p><strong>CyclicBarrier：</strong></p>
<p>​        字面意思是可循环(Cyclic)使用的屏障（Barrier）。他要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活，线程进入屏障通过CyclicBarrier的await()方法。可以用于批量发送消息队列信息、异步限流。</p>
<p><strong>Semaphore：</strong></p>
<p>​        信号量主要用于两个目的，一个是用于多个共享资源的互斥作用，另一个用于并发线程数的控制。SpringHystrix限流的思想</p>
<h4 id="3、happens-before"><a href="#3、happens-before" class="headerlink" title="3、happens-before"></a>3、happens-before</h4><p>​        用来描述和可见性相关问题：如果第一个操作 happens-before 第二个操作，那么我们就说第一个操作对于第二个操作是可见的</p>
<p>​        常见的happens-before：volatile 、锁、线程生命周期。</p>
<h1 id="四、MySQL篇"><a href="#四、MySQL篇" class="headerlink" title="四、MySQL篇"></a>四、MySQL篇</h1><h3 id="WhyMysql？"><a href="#WhyMysql？" class="headerlink" title="WhyMysql？"></a>WhyMysql？</h3><p>NoSQL数据库四大家族 </p>
<ul>
<li>列存储 Hbase</li>
<li>K-V存储 Redis</li>
<li>图像存储 Neo4j</li>
<li>文档存储 MongoDB</li>
</ul>
<p>云存储OSS</p>
<h4 id="海量Aerospike"><a href="#海量Aerospike" class="headerlink" title="海量Aerospike"></a>海量Aerospike</h4><p>​    Aerospike（简称AS）是一个分布式，可扩展的键值存储的NoSQL<strong>数据库</strong>。T级别大数据高并发的结构化<strong>数据存储，</strong>采用混合架构，索引存储在内存中，而数据可存储在机械硬盘(HDD)或固态硬盘(SSD) 上，读写操作达微妙级，99%的响应可在1毫秒内实现。</p>
<table>
<thead>
<tr>
<th></th>
<th>Aerospike</th>
<th>Redis</th>
</tr>
</thead>
<tbody><tr>
<td>类型</td>
<td>Nosql数据库</td>
<td>缓存</td>
</tr>
<tr>
<td>线程数</td>
<td>多线程</td>
<td>单线程</td>
</tr>
<tr>
<td>数据分片</td>
<td>自动处理相当于分片</td>
<td>提供分片算法、平衡各分片数据</td>
</tr>
<tr>
<td>数据扩容</td>
<td>动态增加数据卷平衡流量</td>
<td>需停机</td>
</tr>
<tr>
<td>数据同步</td>
<td>设置复制因子后可以透明的完成故障转移</td>
<td>手动故障转移和数据同步</td>
</tr>
<tr>
<td>载体</td>
<td>内存存储索引+SSD存储数据</td>
<td>内存</td>
</tr>
</tbody></table>
<p>​    Aerospike作为一个大容量的NoSql解决方案，适合对<strong>容量要求比较大，QPS相对低</strong>一些的场景，主要用在广告行业，<strong>个性化推荐厂告</strong>是建立在了和掌握消费者独特的偏好和习性的基础之上，对消费者的购买需求做出准确的预测或引导，在合适的位置、合适的时间，以合适的形式向消费者呈现与其需求高度吻合的广告，以此来促进用户的消费行为。</p>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmam43b44bj30d90d4aa7.jpg" alt="image-20210103170039711" style="zoom:50%;" />

<p>​    （ETL数据仓库技术）抽取（extract）、转换（transform）、加载（load）</p>
<ul>
<li><p>用户行为日志收集系统收集日志之后推送到ETL做数据的清洗和转换</p>
</li>
<li><p>把ETL过后的数据发送到推荐引擎计算每个消费者的推荐结果，其中推荐逻辑包括规则和算法两部分</p>
</li>
<li><p>收集用户最近浏览、最长停留等特征，分析商品相似性、用户相似性、相似性等算法。</p>
</li>
<li><p>把推荐引擎的结果存入Aerospike集群中，并提供给广告投放引擎实时获取</p>
<p>分别通过HDFS和HBASE对日志进行离线和实时的分析，然后把用户画像的标签(tag : 程序猿、宅男…)结果存入高性能的Nosql数据库Aerospike中，同时把数据备份到异地数据中心。前端广告投放请求通过决策引擎（投放引擎）向用户画像数据库中读取相应的用户画像数据，然后根据竞价算法出价进行竞价。竞价成功之后就可以展现广告了。而在竞价成功之后，具体给用户展现什么样的广告，就是有上面说的个性化推荐广告来完成的。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>Aerospike</th>
<th>Mysql</th>
</tr>
</thead>
<tbody><tr>
<td>库名</td>
<td>Namespace</td>
<td>Database</td>
</tr>
<tr>
<td>表名</td>
<td>Set</td>
<td>Table</td>
</tr>
<tr>
<td>记录</td>
<td>Bin</td>
<td>Column</td>
</tr>
<tr>
<td>字段</td>
<td>Record</td>
<td>Row</td>
</tr>
<tr>
<td>索引</td>
<td>key 、 pk 、kv</td>
<td>pk</td>
</tr>
</tbody></table>
<h4 id="图谱Neo4j"><a href="#图谱Neo4j" class="headerlink" title="图谱Neo4j"></a>图谱Neo4j</h4><blockquote>
<p>Neo4j是一个开源基于java开发的图形noSql数据库，它将结构化数据存储在图中而不是表中。它是一个嵌入式的、基于磁盘的、具备完全的事务特性的Java持久化引擎。程序数据是在一个面向对象的、灵活的网络结构下，而不是严格的表中，但具备完全的事务特性、企业级的数据库的所有好处。</p>
</blockquote>
<p>一种基于图的数据结构，由节点(Node)和边(Edge)组成。其中节点即实体，由一个全局唯一的ID标示，边就是关系用于连接两个节点。通俗地讲，知识图谱就是把所有不同种类的信息，连接在一起而得到的一个关系网络。知识图谱提供了从“关系”的角度去分析问题的能力。</p>
<p>互联网、大数据的背景下，谷歌、百度、搜狗等搜索引擎纷纷基于该背景，创建自己的知识图<strong>Knowledge Graph（谷歌</strong>）、<strong>知心（百度）</strong>和<strong>知立方（搜狗）</strong>，主要用于改进搜索质量。</p>
<p>自己项目主要用作好友推荐，图数据库(Graph database)指的是以图数据结构的形式来存储和查询数据的数据库。关系图谱中，关系的组织形式采用的就是图结构，所以非常适合用图库进行存储。</p>
<ul>
<li><p><img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmaq0j9otdj30pz0en0vm.jpg" alt="image-20210103191540372"></p>
<p>优势总结:</p>
</li>
<li><p>性能上，使用cql查询，对长程关系的查询速度快</p>
</li>
<li><p>擅于发现隐藏的关系，例如通过判断图上两点之间有没有走的通的路径，就可以发现事物间的关联</p>
</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmaqc75y6bj30wc0d60u4.jpg" alt="image-20210103192653004"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 查询三层级关系节点如下：with可以将前面查询结果作为后面查询条件</span></span><br><span class="line">match (na:Person)-[re]-(nb:Person) where na.name=<span class="string">&quot;林婉儿&quot;</span> WITH na,re,nb <span class="title function_">match</span> <span class="params">(nb:Person)</span>- [re2:Friends]-&gt;(nc:Person) <span class="keyword">return</span> na,re,nb,re2,nc</span><br><span class="line"><span class="comment">// 直接拼接关系节点查询</span></span><br><span class="line">match data=(na:Person&#123;name:<span class="string">&quot;范闲&quot;</span>&#125;)-[re]-&gt;(nb:Person)-[re2]-&gt;(nc:Person) <span class="keyword">return</span> data</span><br><span class="line"><span class="comment">// 使用深度运算符</span></span><br><span class="line">显然使用以上方式比较繁琐,可变数量的关系-&gt;节点可以使用-[:TYPE*minHops..maxHops]-。</span><br><span class="line">match data=(na:Person&#123;name:<span class="string">&quot;范闲&quot;</span>&#125;)-[*<span class="number">1.</span><span class="number">.2</span>]-(nb:Person) <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>



<h4 id="文档MongoDB"><a href="#文档MongoDB" class="headerlink" title="文档MongoDB"></a><strong>文档MongoDB</strong></h4><blockquote>
<p>MongoDB 是一个基于分布式文件存储的数据库，是非关系数据库中功能最丰富、最像关系数据库的。在高负载的情况下，通过添加更多的节点，可以保证服务器性能。由 C++ 编写，可以为 WEB 应用提供可扩展、高性能、易部署的数据存储解决方案。</p>
</blockquote>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmaqyp75qsj312q0i8q5f.jpg" alt="image-20210103194830654" style="zoom:80%;" />

<p><strong>什么是BSON</strong></p>
<blockquote>
<p>{key:value,key2:value2}和Json类似，是一种二进制形式的存储格式，支持内嵌的文档对象和数组对象，但是BSON有JSON没有的一些数据类型，比如 value包括字符串,double,Array,DateBSON可以做为网络数据交换的一种存储形式,它的优点是灵活性高，但它的缺点是空间利用率不是很理想。</p>
</blockquote>
<p>BSON有三个特点：轻量性、可遍历性、高效性</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/* 查询 find() 方法可以传入多个键(key)，每个键(key)以逗号隔开*/</span><br><span class="line">db.collection.find(&#123;key1:value1, key2:value2&#125;).pretty()</span><br><span class="line">/* 更新 $set ：设置字段值 $unset :删除指定字段 $inc：对修改的值进行自增*/</span><br><span class="line">db.collection.update(&#123;where&#125;,&#123;$set:&#123;字段名:值&#125;&#125;,&#123;multi:true&#125;)</span><br><span class="line">/* 删除 justOne :如果设为true，只删除一个文档，默认false，删除所有匹配条件的文档*/</span><br><span class="line">db.collection.remove(&#123;where&#125;, &#123;justOne: &lt;boolean&gt;, writeConcern: &lt;回执&gt; &#125; )</span><br></pre></td></tr></table></figure>

<p><strong>优点：</strong></p>
<ul>
<li><p><strong>文档结构的存储方式，能够更便捷的获取数据。</strong></p>
<p>对于一个层级式的数据结构来说，使用扁平式的，表状的结构来查询保存数据非常的困难。</p>
</li>
<li><p><strong>内置GridFS，支持大容量的存储。</strong></p>
<p>GridFS是一个出色的分布式文件系统，支持海量的数据存储，满足对大数据集的快速范围查询。</p>
</li>
<li><p><strong>性能优越</strong></p>
<p>千万级别的文档对象，近10G的数据，对有索引的ID的查询 不会比mysql慢，而对非索引字段的查询，则是全面胜出。 mysql实际无法胜任大数据量下任意字段的查询，而mongodb的查询性能实在牛逼。写入性能同样很令人满意，同样写入百万级别的数据，mongodb基本10分钟以下可以解决。</p>
</li>
</ul>
<p>缺点：</p>
<ul>
<li>不支持事务</li>
<li>磁盘占用空间大</li>
</ul>
<p>MySQL 8.0 版本</p>
<p><strong>1. 性能</strong>：MySQL 8.0 的速度要比 MySQL 5.7 快 2 倍。</p>
<p><strong>2. NoSQL</strong>：MySQL 从 5.7 版本开始提供 NoSQL 存储功能，在 8.0 版本中nosql得到了更大的改进。</p>
<p><strong>3. 窗口函数</strong>：实现若干新的查询方式。窗口函数与 SUM()、COUNT() 这种集合函数类似，但它不会将多行查询结果合并为一行，而是将结果放回多行当中，即窗口函数不需要 GROUP BY。</p>
<p><strong>4. 隐藏索引</strong>：在 MySQL 8.0 中，索引可以被“隐藏”和“显示”。当对索引进行隐藏时，它不会被查询优化器所使用。我们可以使用这个特性用于性能调试，例如我们先隐藏一个索引，然后观察其对数据库的影响。如果数据库性能有所下降，说明这个索引是有用的，然后将其“恢复显示”即可；如果数据库性能看不出变化，说明这个索引是多余的，可以考虑删掉。</p>
<h4 id="云存储"><a href="#云存储" class="headerlink" title="云存储"></a><strong>云存储</strong></h4><table>
<thead>
<tr>
<th></th>
<th>OSS</th>
<th>自建</th>
</tr>
</thead>
<tbody><tr>
<td>可靠性</td>
<td>可用性不低于99.995%<br />数据设计持久性不低于99.9999999999%（12个9）</td>
<td>受限于硬件可靠性，易出问题，一旦出现磁盘坏道，容易出现不可逆转的数据丢失。人工数据恢复困难、耗时、耗力。</td>
</tr>
<tr>
<td>安全</td>
<td>服务端加密、客户端加密、防盗链、IP黑白名单等。多用户资源隔离机制，支持异地容灾机制。</td>
<td>需要另外购买清洗和黑洞设备。需要单独实现安全机制。</td>
</tr>
<tr>
<td>成本</td>
<td>多线BGP骨干网络，无带宽限制，上行流量免费。无需运维人员与托管费用，0成本运维。</td>
<td>单线或双线接入速度慢，有带宽限制，峰值时期需人工扩容。需专人运维，成本高。</td>
</tr>
</tbody></table>
<p><strong>使用步骤</strong></p>
<p>​    1、开通服务</p>
<p>​    2、创建存储空间</p>
<p>​    3、上传文件、下载文件、删除文件</p>
<p>​    4、域名绑定、日志记录</p>
<p>​    5、根据开放接口进行鉴权访问</p>
<p><strong>功能</strong></p>
<p>​    图片编辑（裁剪、模糊、水印）</p>
<p>​    视频截图</p>
<p>​    音频转码、视频修复</p>
<p><strong>CDN加速</strong></p>
<p>​    对象存储OSS与阿里云CDN服务结合，可优化静态热点文件下载加速的场景（即同一地区大量用户同时下载同一个静态文件的场景）。可以将OSS的存储空间（Bucket）作为源站，利用阿里云CDN将源内容发布到边缘节点。当大量终端用户重复访问同一文件时，可以直接从边缘节点获取已缓存的数据，提高访问的响应速度</p>
<h4 id="FastDFS"><a href="#FastDFS" class="headerlink" title="FastDFS"></a><strong>FastDFS</strong></h4><blockquote>
<p><strong>开源的轻量级分布式文件系统</strong>。它对文件进行管理，功能包括：<strong>文件存储、文件同步、文件访问</strong>（文件上传、文件下载）等，解决了<strong>大容量存储和负载均衡</strong>的问题。使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。如<strong>相册网站、视频网站</strong>等</p>
</blockquote>
<p><strong>扩展能力:</strong> 支持水平扩展，可以动态扩容；</p>
<p><strong>高可用性:</strong> 一是整个文件系统的可用性，二是数据的完整和一致性；</p>
<p><strong>弹性存储:</strong> 可以根据业务需要灵活地增删存储池中的资源，而不需要中断系统运行。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmfhjkvo59j30zu0b4dib.jpg" alt="image-20210107221022658"></p>
<p>特性</p>
<ul>
<li>和流行的web server无缝衔接，FastDFS已提供apache和nginx扩展模块</li>
<li>文件ID由FastDFS生成，作为文件访问凭证，FastDFS不需要传统的name server</li>
<li>分组存储，灵活简洁、对等结构，不存在单点</li>
<li>文件不分块存储，上传的文件和OS文件系统中的文件一一对应</li>
<li>中、小文件均可以很好支持，支持海量小文件存储</li>
<li>支持相同内容的文件只保存一份，节约磁盘空间</li>
<li>支持多块磁盘，支持单盘数据恢复</li>
<li>支持在线扩容 支持主从文件</li>
<li>下载文件支持多线程方式，支持断点续传</li>
</ul>
<p><strong>组成</strong></p>
<ul>
<li><p><strong>客户端（client）</strong></p>
<p>通过专有接口，使用TCP&#x2F;IP协议与跟踪器服务器或存储节点进行数据交互。</p>
</li>
<li><p><strong>跟踪器（tracker）</strong> </p>
<p>Trackerserver作用是负载均衡和调度，通过Tracker server在文件上传时可以根据策略找到文件上传的地址。Tracker在访问上起负载均衡的作用。</p>
</li>
<li><p><strong>存储节点（storage）</strong></p>
<p>Storageserver作用是文件存储，客户端上传的文件最终存储在Storage服务器上，Storage server<strong>没有实现自己的文件系统而是利用操作系统的文件系统来管理文件</strong>。存储节点中的服务器均可以<strong>随时增加或下线而不会影响线上服务</strong>。</p>
</li>
</ul>
<p><strong>上传</strong></p>
<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmfhvk0wwzj30ue0h4dlw.jpg" alt="image-20210107222155291" style="zoom:50%;" />

<p><strong>下载</strong></p>
<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmfhww8zmfj30uw0g6n37.jpg" alt="image-20210107222312338" style="zoom:50%;" />

<p><strong>断点续传</strong></p>
<p>​    续传涉及到的文件大小MD5不会改变。续传流程与文件上传类似，先<strong>定位到源storage</strong>，完成完整或部分上传，再<strong>通过binlog进行同group内server文件同步</strong>。</p>
<p><strong>配置优化</strong></p>
<p>配置文件：tracker.conf 和 storage.conf </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// FastDFS采用内存池的做法。 </span></span><br><span class="line"><span class="comment">// v5.04对预分配采用增量方式，tracker一次预分配 1024个，storage一次预分配256个。 </span></span><br><span class="line">max_connections = <span class="number">10240</span></span><br><span class="line"><span class="comment">// 根据实际需要将 max_connections 设置为一个较大的数值，比如 10240 甚至更大。</span></span><br><span class="line"><span class="comment">// 同时需要将一个进程允许打开的最大文件数调大</span></span><br><span class="line">vi /etc/security/limits.conf 重启系统生效 </span><br><span class="line">* soft nofile <span class="number">65535</span> </span><br><span class="line">* hard nofile <span class="number">65535</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">work_threads = <span class="number">4</span> </span><br><span class="line"><span class="comment">// 说明：为了避免CPU上下文切换的开销，以及不必要的资源消耗，不建议将本参数设置得过大。</span></span><br><span class="line"><span class="comment">// 公式为： work_threads + (reader_threads + writer_threads) = CPU数</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 对于单盘挂载方式，磁盘读写线程分 别设置为 1即可 </span></span><br><span class="line"><span class="comment">// 如果磁盘做了RAID，那么需要酌情加大读写线程数，这样才能最大程度地发挥磁盘性能</span></span><br><span class="line">disk_rw_separated：磁盘读写是否分离 </span><br><span class="line">disk_reader_threads：单个磁盘读线程数 </span><br><span class="line">disk_writer_threads：单个磁盘写线程数 </span><br></pre></td></tr></table></figure>

<p><strong>避免重复</strong></p>
<p>​    如何避免文件重复上传 解决方案 上传成功后计算文件对应的MD5然后<strong>存入MySQL</strong>,添加文件时把<strong>文件MD5和之前存入MYSQL中的存储的信息对比</strong> 。DigestUtils.md5DigestAsHex(bytes)。</p>
<div style="page-break-after: always;"></div>

<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><h4 id="1、事务4大特性"><a href="#1、事务4大特性" class="headerlink" title="1、事务4大特性"></a><strong>1、事务4大特性</strong></h4><p><strong>事务4大特性：</strong>原子性、一致性、隔离性、持久性</p>
<p>​    <strong>原⼦性：</strong> 事务是最⼩的执⾏单位，不允许分割。事务的原⼦性确保动作要么全部完成，要么全不执行</p>
<p>​    <strong>一致性：</strong> 执⾏事务前后，数据保持⼀致，多个事务对同⼀个数据读取的结果是相同的；</p>
<p>​    <strong>隔离性：</strong> 并发访问数据库时，⼀个⽤户的事务不被其他事务所⼲扰，各并发事务之间数据库是独⽴的；</p>
<p>​    <strong>持久性：</strong> ⼀个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发⽣故障也不应该对其有任何影响。</p>
<p><strong>实现保证：</strong></p>
<p>​        MySQL的存储引擎InnoDB使用重做日志保证一致性与持久性，回滚日志保证原子性，使用各种锁来保证隔离性。</p>
<h4 id="2、事务隔离级别"><a href="#2、事务隔离级别" class="headerlink" title="2、事务隔离级别"></a><strong>2、事务隔离级别</strong></h4><p><strong>读未提交：</strong>最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。</p>
<p><strong>读已提交：</strong>允许读取并发事务已经提交的数据，可以阻⽌脏读，但是幻读或不可重复读仍有可能发⽣。</p>
<p><strong>可重复读：</strong>同⼀字段的多次读取结果都是⼀致的，除⾮数据是被本身事务⾃⼰所修改，可以阻⽌脏读和不可重复读，会有幻读。</p>
<p><strong>串行化：</strong>最⾼的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执⾏，这样事务之间就完全不可能产⽣⼲扰。</p>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>并发问题</th>
</tr>
</thead>
<tbody><tr>
<td>读未提交</td>
<td>可能会导致脏读、幻读或不可重复读</td>
</tr>
<tr>
<td>读已提交</td>
<td>可能会导致幻读或不可重复读</td>
</tr>
<tr>
<td>可重复读</td>
<td>可能会导致幻读</td>
</tr>
<tr>
<td>可串行化</td>
<td>不会产⽣⼲扰</td>
</tr>
</tbody></table>
<h4 id="3、默认隔离级别-RR"><a href="#3、默认隔离级别-RR" class="headerlink" title="3、默认隔离级别-RR"></a><strong>3、默认隔离级别-RR</strong></h4><p><strong>默认隔离级别：</strong>可重复读；</p>
<p>​        同⼀字段的多次读取结果都是⼀致的，除⾮数据是被本身事务⾃⼰所修改；</p>
<p>​        可重复读是有可能出现幻读的，如果要保证绝对的安全只能把隔离级别设置成SERIALIZABLE；这样所有事务都只能顺序执行，自然不会因为并发有什么影响了，但是性能会下降许多。</p>
<p>​        第二种方式，使用MVCC解决<strong>快照读幻读问题</strong>（如简单select），读取的不是最新的数据。维护一个字段作为version，这样可以控制到每次只能有一个人更新一个版本。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select id from table_xx where id = ? and version = V</span><br><span class="line">update id from table_xx where id = ? and version = V+1</span><br></pre></td></tr></table></figure>

<p>​        第三种方式，如果需要读最新的数据，可以通过GapLock+Next-KeyLock可以解决<strong>当前读幻读问题</strong>，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select id from table_xx where id &gt; 100 for update;</span><br><span class="line">select id from table_xx where id &gt; 100 lock in share mode;</span><br></pre></td></tr></table></figure>



<h4 id="4、RR和RC使用场景"><a href="#4、RR和RC使用场景" class="headerlink" title="4、RR和RC使用场景"></a><strong>4、RR和RC使用场景</strong></h4><p>​        事务隔离级别RC(read commit)和RR（repeatable read）两种事务隔离级别基于多版本并发控制MVCC(multi-version concurrency control）来实现。</p>
<table>
<thead>
<tr>
<th></th>
<th>RC</th>
<th>RR</th>
</tr>
</thead>
<tbody><tr>
<td>实现</td>
<td>多条查询语句会创建多个不同的ReadView</td>
<td>仅需要一个版本的ReadView</td>
</tr>
<tr>
<td>粒度</td>
<td>语句级读一致性</td>
<td>事务级读一致性</td>
</tr>
<tr>
<td>准确性</td>
<td>每次语句执行时间点的数据</td>
<td>第一条语句执行时间点的数据</td>
</tr>
</tbody></table>
<h4 id="5、行锁，表锁，意向锁"><a href="#5、行锁，表锁，意向锁" class="headerlink" title="5、行锁，表锁，意向锁"></a><strong>5、行锁，表锁，意向锁</strong></h4><p><strong>InnoDB⽀持⾏级锁(row-level locking)和表级锁,默认为⾏级锁</strong>    </p>
<p>​    InnoDB按照不同的分类的锁：</p>
<p>​    共享&#x2F;排它锁(Shared and Exclusive Locks)：行级别锁，</p>
<p>​    意向锁(Intention Locks)，表级别锁</p>
<p>​    间隙锁(Gap Locks)，锁定一个区间</p>
<p>​    记录锁(Record Locks)，锁定一个行记录</p>
<p><strong>表级锁：（串行化）</strong></p>
<p>​        Mysql中锁定 粒度最大的一种锁，对当前操作的整张表加锁，实现简单 ，资源消耗也比较少，加锁快，不会出现死锁 。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。</p>
<p><strong>行级锁：（RR、RC）</strong></p>
<p>​        Mysql中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。 InnoDB支持的行级锁，包括如下几种：</p>
<p>​        <strong>记录锁（Record Lock）:</strong> 对索引项加锁，锁定<strong>符合条件的行</strong>。其他事务不能修改和删除加锁项；</p>
<p>​        <strong>间隙锁（Gap Lock）:</strong> 对索引项之间的“间隙”加锁，锁定<strong>记录的范围</strong>，不包含索引项本身，其他事务不能在锁范围内插入数据。</p>
<p>​        <strong>Next-key Lock：</strong> 锁定索引项本身和索引范围。即Record Lock和Gap Lock的结合。可解决幻读问题。</p>
<p>InnoDB 支持多粒度锁（multiple granularity locking），它允许行级锁与表级锁共存，而意向锁就是其中的一种表锁。</p>
<p><strong>共享锁</strong>（ shared lock, S ）锁允许持有锁读取行的事务。加锁时将自己和子节点全加S锁，父节点直到表头全加IS锁</p>
<p><strong>排他锁</strong>（ exclusive lock， X ）锁允许持有锁修改行的事务。 加锁时将自己和子节点全加X锁，父节点直到表头全加IX锁  </p>
<p><strong>意向共享锁</strong>（intention shared lock, IS）：事务有意向对表中的某些行加<strong>共享锁</strong>（S锁）</p>
<p><strong>意向排他锁</strong>（intention exclusive lock, IX）：事务有意向对表中的某些行加<strong>排他锁</strong>（X锁）</p>
<table>
<thead>
<tr>
<th>互斥性</th>
<th>共享锁（S）</th>
<th>排它锁（X）</th>
<th>意向共享锁IS</th>
<th>意向排他锁IX</th>
</tr>
</thead>
<tbody><tr>
<td>共享锁（S）</td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>排它锁（X）</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
</tr>
<tr>
<td>意向共享锁IS</td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>意向排他锁IX</td>
<td>❌</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
</tr>
</tbody></table>
<h4 id="6、MVCC多版本并发控制"><a href="#6、MVCC多版本并发控制" class="headerlink" title="6、MVCC多版本并发控制"></a><strong>6、MVCC多版本并发控制</strong></h4><p>​        MVCC是一种多版本并发控制机制，通过事务的可见性看到自己预期的数据，能降低其系统开销.（RC和RR级别工作）</p>
<p>​        InnoDB的MVCC,是通过在每行记录后面保存系统版本号(可以理解为事务的ID)，每开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的ID。这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的，防止幻读的产生。</p>
<p>​        1.MVCC手段只适用于Msyql隔离级别中的读已提交（Read committed）和可重复读（Repeatable Read）.</p>
<p>​        2.Read uncimmitted由于存在脏读，即能读到未提交事务的数据行，所以不适用MVCC.</p>
<p>​        3.简单的select快照度不会加锁，删改及select for update等需要当前读的场景会加锁</p>
<p>​        原因是MVCC的创建版本和删除版本只要在事务提交后才会产生。客观上，mysql使用的是乐观锁的一整实现方式，就是每行都有版本号，保存时根据版本号决定是否成功。Innodb的MVCC使用到的快照存储在Undo日志中，该日志通过回滚指针把一个数据行所有快照连接起来。</p>
<p><strong>版本链</strong></p>
<p>在InnoDB引擎表中，它的聚簇索引记录中有两个必要的隐藏列：</p>
<p><strong>trx_id</strong></p>
<p>这个id用来存储的每次对某条聚簇索引记录进行修改的时候的事务id。</p>
<p><strong>roll_pointer</strong></p>
<p>每次对哪条聚簇索引记录有修改的时候，都会把老版本写入undo日志中。这个roll_pointer就是存了一个指针，它指向这条聚簇索引记录的上一个版本的位置，通过它来获得上一个版本的记录信息。(注意插入操作的undo日志没有这个属性，因为它没有老版本)</p>
<p>每次修改都会在版本链中记录。<strong>SELECT可以去版本链中拿记录，这就实现了读-写，写-读的并发执行，</strong>提升了系统的性能。</p>
<div style="page-break-after: always;"></div>

<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><h4 id="1、Innodb和Myisam引擎"><a href="#1、Innodb和Myisam引擎" class="headerlink" title="1、Innodb和Myisam引擎"></a><strong>1、Innodb和Myisam引擎</strong></h4><p><strong>Myisam：</strong>支持表锁，适合读密集的场景，不支持外键，不支持事务，索引与数据在不同的文件</p>
<p><strong>Innodb：</strong>支持行、表锁，默认为行锁，适合并发场景，支持外键，支持事务，索引与数据同一文件</p>
<h4 id="2、哈希索引"><a href="#2、哈希索引" class="headerlink" title="2、哈希索引"></a><strong>2、哈希索引</strong></h4><p>​        哈希索引用索引列的值计算该值的hashCode，然后在hashCode相应的位置存执该值所在行数据的物理位置，因为使用散列算法，因此访问速度非常快，但是一个值只能对应一个hashCode，而且是散列的分布方式，因此哈希索引不支持范围查找和排序的功能</p>
<h4 id="3、B-树索引"><a href="#3、B-树索引" class="headerlink" title="3、B+树索引"></a><strong>3、B+树索引</strong></h4><p><strong>优点：</strong></p>
<p>​        B+树的磁盘读写代价低，更少的查询次数，查询效率更加稳定，有利于对数据库的扫描</p>
<p>​        B+树是B树的升级版，B+树只有叶节点存放数据，其余节点用来索引。索引节点可以全部加入内存，增加查询效率，叶子节点可以做双向链表，从而<strong>提高范围查找的效率，增加的索引的范围</strong></p>
<p>​        在大规模数据存储的时候，红黑树往往出现由于<strong>树的深度过大</strong>而造成磁盘IO读写过于频繁，进而导致效率低下的情况。所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B树与B+树可以有多个子女，从几十到上千，可以降低树的高度。</p>
<p>​        <strong>磁盘预读原理</strong>：将一个节点的大小设为等于一个页，这样每个节点只需要一次I&#x2F;O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证<strong>一个节点物理上也存储在一个页里</strong>，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I&#x2F;O。</p>
<h4 id="4、创建索引"><a href="#4、创建索引" class="headerlink" title="4、创建索引"></a>4、创建索引</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span>  [<span class="keyword">UNIQUE</span> <span class="operator">|</span> FULLTEXT]  INDEX  索引名 <span class="keyword">ON</span>  表名(字段名) [<span class="keyword">USING</span> 索引方法]；</span><br><span class="line"></span><br><span class="line">说明：</span><br><span class="line"><span class="keyword">UNIQUE</span>:可选。表示索引为唯一性索引。</span><br><span class="line">FULLTEXT:可选。表示索引为全文索引。</span><br><span class="line">INDEX和KEY:用于指定字段为索引，两者选择其中之一就可以了，作用是一样的。</span><br><span class="line">索引名:可选。给创建的索引取一个新名称。</span><br><span class="line">字段名<span class="number">1</span>:指定索引对应的字段的名称，该字段必须是前面定义好的字段。</span><br><span class="line">注：索引方法默认使用B<span class="operator">+</span>TREE。</span><br></pre></td></tr></table></figure>



<h4 id="5、聚簇索引和非聚簇索引"><a href="#5、聚簇索引和非聚簇索引" class="headerlink" title="5、聚簇索引和非聚簇索引"></a><strong>5、聚簇索引和非聚簇索引</strong></h4><p>​    <strong>聚簇索引：</strong>将数据存储与索引放到了一块，索引结构的叶子节点保存了行数据（<strong>主键索引</strong>）</p>
<p>​    <strong>非聚簇索引：</strong>将数据与索引分开存储，索引结构的叶子节点指向了数据对应的位置（<strong>辅助索引</strong>）</p>
<p>​    聚簇索引的叶子节点就是数据节点，而非聚簇索引的叶子节点仍然是索引节点，只不过有指向对应数据块的指针。</p>
<h4 id="6、最左前缀问题"><a href="#6、最左前缀问题" class="headerlink" title="6、最左前缀问题"></a>6、最左前缀问题</h4><p>​        最左前缀原则主要使用在联合索引中，联合索引的B+Tree是按照第一个关键字进行索引排列的。</p>
<p>​        联合索引的底层是一颗B+树，只不过联合索引的B+树节点中存储的是键值。由于构建一棵B+树只能根据一个值来确定索引关系，所以数据库依赖联合索引最左的字段来构建。</p>
<p>​        采用&gt;、&lt;等进行匹配都会导致后面的列无法走索引，因为通过以上方式匹配到的数据是不可知的。</p>
<div style="page-break-after: always;"></div>

<h3 id="SQL查询"><a href="#SQL查询" class="headerlink" title="SQL查询"></a>SQL查询</h3><h4 id="1、SQL语句的执行过程"><a href="#1、SQL语句的执行过程" class="headerlink" title="1、SQL语句的执行过程"></a><strong>1、SQL语句的执行过程</strong></h4><p><strong>查询语句：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from student  A where A.age=&#x27;18&#x27; and A.name=&#x27;张三&#x27;;</span><br></pre></td></tr></table></figure>

<img src="http://s0.lgstatic.com/i/image2/M01/8B/0F/CgotOV14ySKAMxohAAH2VHcAzkE612.png" alt="img" style="zoom: 67%;" />

<p>结合上面的说明，我们分析下这个语句的执行流程：</p>
<p>①通过客户端&#x2F;服务器通信协议与 MySQL 建立连接。并查询是否有权限</p>
<p>②Mysql8.0之前开看是否开启缓存，开启了 Query Cache 且命中完全相同的 SQL 语句，则将查询结果直接返回给客户端；</p>
<p>③由解析器进行语法语义解析，并生成解析树。如查询是select、表名tb_student、条件是id&#x3D;’1’</p>
<p>④查询优化器生成执行计划。根据索引看看是否可以优化</p>
<p>⑤查询执行引擎执行 SQL 语句，根据存储引擎类型，得到查询结果。若开启了 Query Cache，则缓存，否则直接返回。</p>
<h4 id="2、回表查询和覆盖索引"><a href="#2、回表查询和覆盖索引" class="headerlink" title="2、回表查询和覆盖索引"></a><strong>2、回表查询和覆盖索引</strong></h4><p><strong>普通索引</strong>（唯一索引+联合索引+全文索引）需要扫描两遍索引树</p>
<p>（1）先通过普通索引定位到主键值id&#x3D;5；</p>
<p>（2）在通过聚集索引定位到行记录；</p>
<p>这就是所谓的<strong>回表查询</strong>，先定位主键值，再定位行记录，它的性能较扫一遍索引树更低。</p>
<p><strong>覆盖索引</strong>：主键索引&#x3D;&#x3D;聚簇索引&#x3D;&#x3D;覆盖索引</p>
<p>​    覆盖索引（covering index ，或称为索引覆盖）就是把单列的非主键 索引 修改为多字段的联合索引,  在一棵索引数上 就找到了想要的数据, 不需要去主键索引树上,再检索一遍  这个现象,称之为 索引覆盖.</p>
<p>​    如果where条件的列和返回的数据在一个索引中，那么不需要回查表，那么就叫覆盖索引。</p>
<p><strong>实现覆盖索引</strong>：常见的方法是，将被查询的字段，建立到联合索引里去。</p>
<h4 id="3、Explain及优化"><a href="#3、Explain及优化" class="headerlink" title="3、Explain及优化"></a>3、Explain及优化</h4><p>参考：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8fab76bbf448">https://www.jianshu.com/p/8fab76bbf448</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; explain select * from staff;</span><br><span class="line">+----+-------------+-------+------+---------------+------+---------+------+------+-------+</span><br><span class="line">| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows | Extra |</span><br><span class="line">+----+-------------+-------+------+---------------+------+---------+------+------+-------+</span><br><span class="line">|  1 | SIMPLE      | staff | ALL  | NULL          | 索引  | NULL    | NULL |    2 | NULL  |</span><br><span class="line">+----+-------------+-------+------+---------------+------+---------+------+------+-------+</span><br><span class="line">1 row in set</span><br></pre></td></tr></table></figure>

<p><strong>索引优化：</strong></p>
<p>​    ①最左前缀索引：like只用于’string%’，语句中的&#x3D;和in会动态调整顺序</p>
<p>​    ②唯一索引：唯一键区分度在0.1以上</p>
<p>​        区分度的公式是count(distinct col)&#x2F;count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在<a target="_blank" rel="noopener" href="http://lib.csdn.net/base/hadoop">大数据</a>面前区分度就 是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条 记录</p>
<p>​    ③无法使用索引：!&#x3D;  、is null 、 or、&gt;&lt; 、（<strong>5.7以后根据数量自动判定）in 、not in</strong></p>
<p>​    ④联合索引：避免select * ，查询列使用覆盖索引</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT uid From user Where gid = 2 order by ctime asc limit 10</span><br><span class="line">ALTER TABLE user add index idx_gid_ctime_uid(gid,ctime,uid) #创建联合覆盖索引，避免回表查询</span><br></pre></td></tr></table></figure>



<p><strong>语句优化：</strong></p>
<p>​    ①char固定长度查询效率高，varchar第一个字节记录数据长度</p>
<p>​    ②应该针对Explain中Rows增加索引</p>
<p>​    ③group&#x2F;order by字段均会涉及索引</p>
<p>​    ④Limit中分页查询会随着start值增大而变缓慢，通过子查询+表连接解决</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mytbl <span class="keyword">order</span> <span class="keyword">by</span> id limit <span class="number">100000</span>,<span class="number">10</span>  改进后的<span class="keyword">SQL</span>语句如下：</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mytbl <span class="keyword">where</span> id <span class="operator">&gt;=</span> ( <span class="keyword">select</span> id <span class="keyword">from</span> mytbl <span class="keyword">order</span> <span class="keyword">by</span> id limit <span class="number">100000</span>,<span class="number">1</span> ) limit <span class="number">10</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mytbl <span class="keyword">inner</span> ori <span class="keyword">join</span> (<span class="keyword">select</span> id <span class="keyword">from</span> mytbl <span class="keyword">order</span> <span class="keyword">by</span> id limit <span class="number">100000</span>,<span class="number">10</span>) <span class="keyword">as</span> tmp <span class="keyword">on</span> tmp.id<span class="operator">=</span>ori.id;</span><br></pre></td></tr></table></figure>

<p>​    ⑤count会进行全表扫描，如果估算可以使用explain</p>
<p>​    ⑥delete删除表时会增加大量undo和redo日志， 确定删除可使用trancate</p>
<p><strong>表结构优化：</strong></p>
<p>​    ①单库不超过200张表</p>
<p>​    ②单表不超过500w数据</p>
<p>​    ③单表不超过40列</p>
<p>​    ④单表索引不超过5个</p>
<p><strong>数据库范式</strong> ：</p>
<p>​    ①第一范式（1NF）列不可分割</p>
<p>​    ②第二范式（2NF）属性完全依赖于主键 [ 消除部分子函数依赖 ]</p>
<p>​    ③第三范式（3NF）属性不依赖于其它非主属性 [ 消除传递依赖 ]</p>
<p><strong>配置优化：</strong></p>
<p>​    配置连接数、禁用Swap、增加内存、升级SSD硬盘</p>
<h4 id="4、JOIN查询"><a href="#4、JOIN查询" class="headerlink" title="4、JOIN查询"></a>4、JOIN查询</h4><img src="https://image-static.segmentfault.com/276/780/2767807589-5c122586a23c4_articlex" style="align:left;zoom: 60%;" />

<p><strong>left join(左联接)</strong> 返回包括左表中的所有记录和右表中关联字段相等的记录 </p>
<p><strong>right join(右联接)</strong> 返回包括右表中的所有记录和左表中关联字段相等的记录</p>
<p><strong>inner join(等值连接)</strong> 只返回两个表中关联字段相等的行</p>
<div style="page-break-after: always;"></div>

<h3 id="集群"><a href="#集群" class="headerlink" title="集群"></a><strong>集群</strong></h3><h4 id="1、主从复制过程"><a href="#1、主从复制过程" class="headerlink" title="1、主从复制过程"></a>1、主从复制过程</h4><p><strong>MySQl主从复制：</strong></p>
<ul>
<li><strong>原理</strong>：将主服务器的binlog日志复制到从服务器上执行一遍，达到主从数据的一致状态。</li>
<li><strong>过程</strong>：从库开启一个I&#x2F;O线程，向主库请求Binlog日志。主节点开启一个binlog dump线程，检查自己的二进制日志，并发送给从节点；从库将接收到的数据保存到中继日志（Relay log）中，另外开启一个SQL线程，把Relay中的操作在自身机器上执行一遍</li>
<li><strong>优点</strong>：<ul>
<li>作为备用数据库，并且不影响业务</li>
<li>可做读写分离，一个写库，一个或多个读库，在不同的服务器上，充分发挥服务器和数据库的性能，但要保证数据的一致性</li>
</ul>
</li>
</ul>
<p><strong>binlog记录格式：</strong>statement、row、mixed</p>
<p>​        基于语句statement的复制、基于行row的复制、基于语句和行（mix）的复制。其中基于row的复制方式更能保证主从库数据的一致性，但日志量较大，在设置时考虑磁盘的空间问题</p>
<h4 id="2、数据一致性问题"><a href="#2、数据一致性问题" class="headerlink" title="2、数据一致性问题"></a>2、数据一致性问题</h4><p>“主从复制有延时”，这个延时期间读取从库，可能读到不一致的数据。</p>
<p><strong>缓存记录写key法：</strong></p>
<p>​        在cache里记录哪些记录发生过的写请求，来路由读主库还是读从库</p>
<p><strong>异步复制：</strong></p>
<p>​        在异步复制中，主库执行完操作后，写入binlog日志后，就返回客户端，这一动作就结束了，并不会验证从库有没有收到，完不完整，所以这样可能<strong>会造成数据的不一致</strong>。</p>
<p><strong>半同步复制：</strong></p>
<p>​        当主库每提交一个事务后，不会立即返回，而是等待其中一个从库接收到Binlog并成功写入Relay-log中才返回客户端，通过一份在主库的Binlog，另一份在其中一个从库的Relay-log，可以保证了数据的安全性和一致性。</p>
<p><strong>全同步复制：</strong></p>
<p>​        指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的<strong>性能必然会收到严重的影响</strong>。</p>
<h4 id="3、集群架构"><a href="#3、集群架构" class="headerlink" title="3、集群架构"></a>3、集群架构</h4><p> <strong>Keepalived + VIP + MySQL 主从&#x2F;双主</strong></p>
<p>​        当写节点 Master db1 出现故障时，由 MMM Monitor 或 Keepalived 触发切换脚本，将 VIP 漂移到可用的 Master db2 上。当出现网络抖动或网络分区时，MMM Monitor 会误判，严重时来回切换写 VIP 导致集群双写，当数据复制延迟时，应用程序会出现数据错乱或数据冲突的故障。有效避免单点失效的架构就是采用共享存储，单点故障切换可以通过分布式哨兵系统监控。</p>
<img src="http://s0.lgstatic.com/i/image2/M01/89/48/CgoB5l12KuGALf-cAAGuHVmMkHs743.png" alt="img" style="zoom: 67%;" />

<p> <strong>架构选型：</strong>MMM 集群  -&gt; MHA集群 -&gt; MHA+Arksentinel。</p>
<img src="http://s0.lgstatic.com/i/image2/M01/89/68/CgotOV12KuKAe_HOAABl-wRATa0772.png" alt="img"  />



<h4 id="4、故障转移和恢复"><a href="#4、故障转移和恢复" class="headerlink" title="4、故障转移和恢复"></a>4、故障转移和恢复</h4><p><strong>转移方式及恢复方法</strong></p>
<pre><code>1. 虚拟IP或DNS服务 （Keepalived +VIP/DNS  和 MMM 架构）
</code></pre>
<p>​    问题：在虚拟 IP 运维过程中，刷新ARP过程中有时会出现一个 VIP 绑定在多台服务器同时提供连接的问题。这也是为什么要避免使用 Keepalived+VIP 和 MMM 架构的原因之一，因为它处理不了这类问题而导致集群多点写入。</p>
<pre><code>2. 提升备库为主库（MHA、QMHA）
</code></pre>
<p>​    尝试将原 Master 设置 read_only 为 on，避免集群多点写入。借助 binlog server 保留 Master 的 Binlog；当出现数据延迟时，再提升 Slave 为新 Master 之前需要进行数据补齐，否则会丢失数据。</p>
<div style="page-break-after: always;"></div>

<h3 id="面试题-1"><a href="#面试题-1" class="headerlink" title="面试题"></a>面试题</h3><h4 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h4><h5 id="如何进行分库分表"><a href="#如何进行分库分表" class="headerlink" title="如何进行分库分表"></a>如何进行分库分表</h5><blockquote>
<p><strong>分表</strong>用户id进行分表，每个表控制在300万数据。</p>
<p><strong>分库</strong>根据业务场景和地域分库，每个库并发不超过2000</p>
</blockquote>
<p><strong>Sharding-jdbc</strong> 这种 client 层方案的<strong>优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高</strong>，但是各个系统都需要<strong>耦合</strong> Sharding-jdbc 的依赖，升级比较麻烦</p>
<p><strong>Mycat</strong> 这种 proxy 层方案的<strong>缺点在于需要部署</strong>，自己运维一套中间件，运维成本高，但是<strong>好处在于对于各个项目是透明的</strong>，如果遇到升级之类的都是自己中间件那里搞就行了</p>
<p><strong>水平拆分</strong>：一个表放到多个库，分担高并发，加快查询速度</p>
<ul>
<li><strong>id</strong>保证业务在关联多张表时可以在同一库上操作</li>
<li><strong>range</strong>方便扩容和数据统计</li>
<li><strong>hash</strong>可以使得数据更加平均</li>
</ul>
<p><strong>垂直拆分</strong>：一个表拆成多个表，可以将一些冷数据拆分到冗余库中</p>
<blockquote>
<p>不是写瓶颈优先进行分表</p>
</blockquote>
<ul>
<li><p>分库数据间的数据无法再通过数据库直接查询了。会产生深分页的问题</p>
</li>
<li><p>分库越多，出现问题的可能性越大，维护成本也变得更高。</p>
</li>
<li><p>分库后无法保障跨库间事务，只能借助其他中间件实现最终一致性。</p>
</li>
</ul>
<p>分库首先需考虑满足业务最核心的场景：</p>
<p>1、订单数据按<strong>用户</strong>分库，可以<strong>提升用户的全流程体验</strong></p>
<p>2、超级客户导致<strong>数据倾斜</strong>可以使用最细粒度唯一标识进行hash拆分</p>
<p>3、按照最细粒度如订单号拆分以后，数据库就无法进行单库排重了</p>
<p>三个问题：</p>
<ul>
<li><p>富查询：采用分库分表之后，如何满足跨越分库的查询？<strong>使用ES</strong>的宽表</p>
<p>借助<strong>分库网关+分库业务</strong>虽然能够实现<strong>多维度查询的能力</strong>，但整体上性能不佳且对正常的写入请求有一定的影响。业界应对<strong>多维度实时查询</strong>的最常见方式便是借助 <strong>ElasticSearch</strong></p>
</li>
<li><p>数据倾斜：数据分库基础上再进行分表</p>
</li>
<li><p>分布式事务：跨多库的修改及多个微服务间的写操作导致的分布式事务问题？</p>
</li>
<li><p>深分页问题：按游标查询，或者叫每次查询都带上上一次查询经过排序后的最大 ID</p>
</li>
</ul>
<h4 id="如何将老数据进行迁移"><a href="#如何将老数据进行迁移" class="headerlink" title="如何将老数据进行迁移"></a>如何将老数据进行迁移</h4><p><strong>双写不中断迁移</strong></p>
<ul>
<li>线上系统里所有写库的地方，增删改操作，<strong>除了对老库增删改，都加上对新库的增删改</strong></li>
<li>系统部署以后，还需要跑程序读老库数据写新库，写的时候需要判断updateTime</li>
<li>循环执行，直至两个库的数据完全一致，最后重新部署分库分表的代码就行了</li>
</ul>
<h4 id="系统性能的评估及扩容"><a href="#系统性能的评估及扩容" class="headerlink" title="系统性能的评估及扩容"></a>系统性能的评估及扩容</h4><p>和家亲目前有1亿用户：场景 10万写并发，100万读并发，60亿数据量</p>
<p>设计时考虑极限情况，32库*32表~64个表，一共1000 ~ 2000张表</p>
<ul>
<li><p>支持<strong>3万</strong>的写并发，配合MQ实现每秒10万的写入速度</p>
</li>
<li><p>读写分离<strong>6万</strong>读并发，配合分布式缓存每秒100读并发</p>
</li>
<li><p>2000张表每张300万，可以最多写入60亿的数据</p>
</li>
<li><p>32张用户表，支撑亿级用户，后续最多也就扩容一次</p>
</li>
</ul>
<p><strong>动态扩容的步骤</strong></p>
<ol>
<li>推荐是 32 库 * 32 表，对于我们公司来说，可能几年都够了。</li>
<li>配置路由的规则，uid % 32 &#x3D; 库，uid &#x2F; 32 % 32 &#x3D; 表</li>
<li>扩容的时候，申请增加更多的数据库服务器，呈倍数扩容</li>
<li>由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去</li>
<li>修改一下配置，重新发布系统，上线，原先的路由规则变都不用变</li>
<li>直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。</li>
</ol>
<h4 id="如何生成自增的id主键"><a href="#如何生成自增的id主键" class="headerlink" title="如何生成自增的id主键"></a>如何生成自增的id主键</h4><ul>
<li>使用redis可以</li>
<li>并发不高可以单独起一个<strong>服务</strong>，生成自增id</li>
<li>设置数据库<strong>step</strong>自增步长可以支撑水平伸缩</li>
<li>UUID适合文件名、编号，但是<strong>不适合做主键</strong></li>
<li><strong>snowflake雪花算法</strong>，综合了<strong>41时间</strong>（ms）、<strong>10机器</strong>、<strong>12序列号</strong>（ms内自增）</li>
</ul>
<p>其中机器预留的10bit可以根据自己的业务场景配置</p>
<div style="page-break-after: always;"></div>

<h3 id="线上故障及优化"><a href="#线上故障及优化" class="headerlink" title="线上故障及优化"></a>线上故障及优化</h3><h4 id="更新失败-主从同步延时"><a href="#更新失败-主从同步延时" class="headerlink" title="更新失败 | 主从同步延时"></a>更新失败 | 主从同步延时</h4><p>以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。</p>
<p>是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了 2000&#x2F;s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。用户跟客服反馈，而客服就会反馈给我们。</p>
<p>我们通过 MySQL 命令：</p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">show</span> slave <span class="built_in">status</span></span><br></pre></td></tr></table></figure>

<p>查看 <code>Seconds_Behind_Master</code> ，可以看到从库复制主库的数据落后了几 ms。</p>
<p>一般来说，如果主从延迟较为严重，有以下解决方案：</p>
<ul>
<li>分库，拆分为多个主库，每个主库的写并发就减少了几倍，主从延迟可以忽略不计。</li>
<li>重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。</li>
<li>如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询<strong>设置直连主库</strong>或者<strong>延迟查询</strong>。主从复制延迟一般不会超过50ms</li>
</ul>
<h4 id="应用崩溃-分库分表优化"><a href="#应用崩溃-分库分表优化" class="headerlink" title="应用崩溃 | 分库分表优化"></a><strong>应用崩溃 | 分库分表优化</strong></h4><p>​    我们有一个线上通行记录的表，由于数据量过大，进行了分库分表，当时分库分表初期经常产生一些问题。典型的就是通行记录查询中使用了深分页，通过一些工具如MAT、Jstack追踪到是由于sharding-jdbc内部引用造成的。</p>
<p>​    通行记录数据被存放在两个库中。如果没有提供<strong>切分键</strong>，查询语句就会被分发到所有的数据库中，比如查询语句是 limit 10、offset 1000，最终结果只需要返回 10 条记录，但是数据库中间件要完成这种计算，则需要 (1000+10)*2&#x3D;2020 条记录来完成这个计算过程。如果 offset 的值过大，使用的内存就会暴涨。虽然 sharding-jdbc 使用归并算法进行了一些优化，但在实际场景中，深分页仍然引起了<strong>内存和性能</strong>问题。</p>
<p>​    这种在中间节点进行<strong>归并聚合</strong>的操作，在分布式框架中非常常见。比如在 ElasticSearch 中，就存在相似的数据获取逻辑，<strong>不加限制的深分页</strong>，同样会造成 ES 的内存问题。</p>
<p><strong>业界解决方案：</strong></p>
<p><strong>方法一：全局视野法</strong></p>
<p>（1）将order by time offset X limit Y，改写成order by time offset 0 limit X+Y</p>
<p>（2）服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录</p>
<p>这种方法随着翻页的进行，性能越来越低。</p>
<p><strong>方法二：业务折衷法-禁止跳页查询</strong></p>
<p>（1）用正常的方法取得第一页数据，并得到第一页记录的time_max</p>
<p>（2）每次翻页，将order by time offset X limit Y，改写成order by time where time&gt;$time_max limit Y</p>
<p>以保证每次只返回一页数据，性能为常量。</p>
<p><strong>方法三：业务折衷法-允许模糊数据</strong></p>
<p>（1）将order by time offset X limit Y，改写成order by time offset X&#x2F;N limit Y&#x2F;N</p>
<p><strong>方法四：二次查询法</strong></p>
<p>（1）将order by time offset X limit Y，改写成order by time offset X&#x2F;N limit Y</p>
<p>（2）找到最小值time_min</p>
<p>（3）between二次查询，order by time between $time_min and $time_i_max</p>
<p>（4）设置虚拟time_min，找到time_min在各个分库的offset，从而得到time_min在全局的offset</p>
<p>（5）得到了time_min在全局的offset，自然得到了全局的offset X limit Y</p>
<h4 id="查询异常-SQL-调优"><a href="#查询异常-SQL-调优" class="headerlink" title="查询异常 | SQL 调优"></a>查询异常 | SQL 调优</h4><p>分库分表前，有一段用用户名来查询某个用户的 SQL 语句：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * <span class="keyword">from</span> user where name = <span class="string">&quot;xxx&quot;</span> <span class="keyword">and</span> community=<span class="string">&quot;other&quot;</span>;</span><br></pre></td></tr></table></figure>

<p>为了达到动态拼接的效果，这句 SQL 语句被一位同事进行了如下修改。他的本意是，当 name 或者 community 传入为空的时候，动态去掉这些查询条件。这种写法，在 MyBaits 的配置文件中，也非常常见。大多数情况下，这种写法是没有问题的，因为结果集合是可以控制的。但随着系统的运行，用户表的记录越来越多，当传入的 name 和 community 全部为空时，悲剧的事情发生了:</p>
<figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> <span class="number">1</span>=<span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>数据库中的所有记录，都会被查询出来，载入到 JVM 的内存中。由于数据库记录实在太多，直接把内存给撑爆了。由于这种原因引起的内存溢出，发生的频率非常高，比如导入Excel文件时。</p>
<p>通常的解决方式是<strong>强行加入分页功能</strong>，或者对一些<strong>必填的参数进行校验</strong></p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gobovqjvijj30zd0lctbp.jpg" alt="img"></p>
<p><strong>Controller 层</strong></p>
<p>现在很多项目都采用前后端分离架构，所以 Controller 层的方法，一般使用 @ResponseBody 注解，把查询的结果，解析成 JSON 数据返回。这在数据集非常大的情况下，会占用很多内存资源。假如结果集在解析成 JSON 之前，占用的内存是 10MB，那么在解析过程中，有可能会使用 20M 或者更多的内存</p>
<p>因此，保持结果集的精简，是非常有必要的，这也是 DTO（Data Transfer Object）存在的必要。互联网环境不怕小结果集的高并发请求，却非常恐惧大结果集的耗时请求，这是其中一方面的原因。</p>
<p><strong>Service 层</strong></p>
<p>Service 层用于处理具体的业务，更加贴合业务的功能需求。一个 Service，可能会被多个 Controller 层所使用，也可能会使用多个 dao 结构的查询结果进行计算、拼装。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">getUserSize</span><span class="params">()</span> &#123;</span><br><span class="line">        List&lt;User&gt; users = dao.getAllUser();</span><br><span class="line">        <span class="type">return</span> <span class="variable">null</span> <span class="operator">=</span>= users ? <span class="number">0</span> : users.size();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>代码review中发现了定时炸弹，这种在数据量达到一定程度后，才会暴露问题。</p>
<p><strong>ORM 层</strong></p>
<p>比如使用Mybatis时，有一个批量导入服务，在 MyBatis 执行批量插入的时候，竟然产生了内存溢出，按道理这种插入操作是不会引起额外内存占用的，最后通过源码追踪到了问题。</p>
<p>这是因为 MyBatis 循环处理 batch 的时候，操作对象是数组，而我们在接口定义的时候，使用的是 List；当传入一个非常大的 List 时，它需要调用 List 的 toArray 方法将列表转换成数组（浅拷贝）；在最后的拼装阶段，又使用了 StringBuilder 来拼接最终的 SQL，所以实际使用的内存要比 List 多很多。</p>
<p>事实证明，不论是插入操作还是查询动作，只要涉及的数据集非常大，就容易出现问题。由于项目中众多框架的引入，想要分析这些具体的内存占用，就变得非常困难。所以保持小批量操作和结果集的干净，是一个非常好的习惯。</p>
<h1 id="五、Redis篇"><a href="#五、Redis篇" class="headerlink" title="五、Redis篇"></a><strong>五、Redis篇</strong></h1><h3 id="WhyRedis"><a href="#WhyRedis" class="headerlink" title="WhyRedis"></a>WhyRedis</h3><p>​        速度快，完全基于内存，使用C语言实现，网络层使用epoll解决高并发问题，单线程模型避免了不必要的上下文切换及竞争条件；</p>
<table>
<thead>
<tr>
<th></th>
<th>GuavaCache</th>
<th>Tair</th>
<th>EVCache</th>
<th>Aerospike</th>
</tr>
</thead>
<tbody><tr>
<td>类别</td>
<td>本地JVM缓存</td>
<td>分布式缓存</td>
<td>分布式缓存</td>
<td>分布式nosql数据库</td>
</tr>
<tr>
<td>应用</td>
<td>本地缓存</td>
<td>淘宝</td>
<td>Netflix、AWS</td>
<td>广告</td>
</tr>
<tr>
<td>性能</td>
<td>非常高</td>
<td>较高</td>
<td>很高</td>
<td>较高</td>
</tr>
<tr>
<td>持久化</td>
<td>无</td>
<td>有</td>
<td>有</td>
<td>有</td>
</tr>
<tr>
<td>集群</td>
<td>无</td>
<td>灵活配置</td>
<td>有</td>
<td>自动扩容</td>
</tr>
</tbody></table>
<p>​        与传统数据库不同的是 Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。另外，Redis 也经常用来做分布式锁。除此之外，Redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。</p>
<h4 id="1、简单高效"><a href="#1、简单高效" class="headerlink" title="1、简单高效"></a>1、简单高效</h4><p>​        1）完全基于内存，绝大部分请求是纯粹的内存操作。数据存在内存中，类似于 HashMap，查找和操作的时间复杂度都是O(1)；</p>
<p>​        2）数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；</p>
<p>​        3）采用单线程，避免了多线程不必要的上下文切换和竞争条件，不存在加锁释放锁操作，减少了因为锁竞争导致的性能消耗；（6.0以后多线程）</p>
<p>​        4）使用EPOLL多路 I&#x2F;O 复用模型，非阻塞 IO；</p>
<p>​        5）使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</p>
<h4 id="2、Memcache"><a href="#2、Memcache" class="headerlink" title="2、Memcache"></a>2、Memcache</h4><table>
<thead>
<tr>
<th>redis</th>
<th>Memcached</th>
</tr>
</thead>
<tbody><tr>
<td>内存高速数据库</td>
<td>高性能分布式内存缓存数据库</td>
</tr>
<tr>
<td>支持hash、list、set、zset、string结构</td>
<td>只支持key-value结构</td>
</tr>
<tr>
<td>将大部分数据放到内存</td>
<td>全部数据放到内存中</td>
</tr>
<tr>
<td>支持持久化、主从复制备份</td>
<td>不支持数据持久化及数据备份</td>
</tr>
<tr>
<td>数据丢失可通过AOF恢复</td>
<td>挂掉后，数据不可恢复</td>
</tr>
<tr>
<td>单线程（2~4万TPS）</td>
<td>多线程（20-40万TPS）</td>
</tr>
</tbody></table>
<p><strong>使用场景：</strong></p>
<p>​    1、如果有持久方面的需求或对数据类型和处理有要求的应该选择redis。<br>​    2、如果简单的key&#x2F;value 存储应该选择memcached。    </p>
<h4 id="3、Tair"><a href="#3、Tair" class="headerlink" title="3、Tair"></a>3、Tair</h4><p>​    Tair(Taobao Pair)是淘宝开发的分布式Key-Value存储引擎，既可以做缓存也可以做数据源（三种引擎切换）</p>
<ul>
<li>MDB（Memcache）属于内存型产品,支持kv和类hashMap结构,性能最优</li>
<li>RDB（Redis）支持List.Set.Zset等复杂的数据结构,性能次之,可提供缓存和持久化存储两种模式</li>
<li>LDB（levelDB）属于持久化产品,支持kv和类hashmap结构,性能较前两者稍低,但持久化可靠性最高</li>
</ul>
<p><strong>分布式缓存</strong></p>
<p>大访问少量临时数据的存储（kb左右）</p>
<p>用于缓存，降低对后端数据库的访问压力</p>
<p>session场景</p>
<p>高速访问某些数据结构的应用和计算（rdb）</p>
<p><strong>数据源存储</strong></p>
<p>快速读取数据（fdb）</p>
<p>持续大数据量的存入读取（ldb），交易快照</p>
<p>高频度的更新读取（ldb），库存</p>
<p><strong>痛点</strong>：redis集群中，想借用缓存资源必须得指明redis服务器地址去要。这就增加了程序的维护复杂度。因为redis服务器很可能是需要频繁变动的。所以人家淘宝就想啊，为什么不能像操作分布式数据库或者hadoop那样。增加一个中央节点，让他去代理所有事情。在tair中程序只要跟tair中心节点交互就OK了。同时tair里还有配置服务器概念。又免去了像操作hadoop那样，还得每台hadoop一套一模一样配置文件。改配置文件得整个集群都跟着改。</p>
<h4 id="4、Guava"><a href="#4、Guava" class="headerlink" title="4、Guava"></a>4、Guava</h4><p>​        分布式缓存一致性更好一点，用于集群环境下多节点使用同一份缓存的情况；有网络IO，吞吐率与缓存的数据大小有较大关系；</p>
<p>​        本地缓存非常高效，本地缓存会占用堆内存，影响垃圾回收、影响系统性能。</p>
<p><strong>本地缓存设计：</strong></p>
<p>​        以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况，每个实例都需要各自保存一份缓存，缓存不具有一致性。</p>
<p><strong>解决缓存过期：</strong></p>
<p>​    1、将缓存过期时间调为永久</p>
<p>​    2、将缓存失效时间分散开，不要将缓存时间长度都设置成一样；比如我们可以在原有的失效时间基础上增加一个随机值，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。</p>
<p><strong>解决内存溢出：</strong></p>
<p>​    <strong>第一步</strong>，修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。)</p>
<p>　<strong>第二步</strong>，检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。</p>
<p>　<strong>第三步</strong>，对代码进行走查和分析，找出可能发生内存溢出的位置。</p>
<p><strong>Google Guava Cache</strong> </p>
<p><strong>自己设计本地缓存痛点：</strong></p>
<ul>
<li>不能按照一定的规则淘汰数据，如 LRU，LFU，FIFO 等。</li>
<li>清除数据时的回调通知</li>
<li>并发处理能力差，针对并发可以使用CurrentHashMap，但缓存的其他功能需要自行实现</li>
<li>缓存过期处理，缓存数据加载刷新等都需要手工实现</li>
</ul>
<p><strong>Guava Cache 的场景：</strong></p>
<ul>
<li>对性能有非常高的要求</li>
<li>不经常变化，占用内存不大</li>
<li>有访问整个集合的需求</li>
<li>数据允许不实时一致</li>
</ul>
<p><strong>Guava Cache 的优势</strong>：</p>
<ul>
<li>缓存过期和淘汰机制</li>
</ul>
<p>在GuavaCache中可以设置Key的过期时间，包括访问过期和创建过期。GuavaCache在缓存容量达到指定大小时，采用LRU的方式，将不常使用的键值从Cache中删除</p>
<ul>
<li>并发处理能力</li>
</ul>
<p>GuavaCache类似CurrentHashMap，是线程安全的。提供了设置并发级别的api，使得缓存支持并发的写入和读取，采用分离锁机制，分离锁能够减小锁力度，提升并发能力，分离锁是分拆锁定，把一个集合看分成若干partition, 每个partiton一把锁。更新锁定</p>
<ul>
<li>防止缓存击穿</li>
</ul>
<p>一般情况下，在缓存中查询某个key，如果不存在，则查源数据，并回填缓存。（Cache Aside Pattern）在高并发下会出现，多次查源并重复回填缓存，可能会造成源的宕机（DB），性能下降 GuavaCache可以在CacheLoader的load方法中加以控制，对同一个key，只让一个请求去读源并回填缓存，其他请求阻塞等待。（相当于集成数据源，方便用户使用）</p>
<ul>
<li>监控缓存加载&#x2F;命中情况</li>
</ul>
<p>统计</p>
<p><strong>问题：</strong></p>
<p>​    OOM-&gt;设置过期时间、使用弱引用、配置过期策略</p>
<h4 id="5、EVCache"><a href="#5、EVCache" class="headerlink" title="5、EVCache"></a>5、EVCache</h4><p>EVCache是一个Netflflix（网飞）公司开源、快速的分布式缓存，是基于Memcached的内存存储实现的，用以构建超大容量、高性能、低延时、跨区域的全球可用的缓存数据层。</p>
<p>E：Ephemeral：数据存储是短暂的，有自身的存活时间</p>
<p>V：Volatile：数据可以在任何时候消失</p>
<p>EVCache典型地适合对强一致性没有必须要求的场合</p>
<p>典型用例：Netflflix向用户推荐用户感兴趣的电影</p>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmapdnh0yaj30ku0aigmc.jpg" alt="image-20210103185340548" style="zoom:50%;" />

<p><strong>EVCache集群</strong>在峰值每秒可以处理<strong>200kb</strong>的请求，</p>
<p>Netflflix生产系统中部署的EVCache经常要处理超过<strong>每秒3000万个</strong>请求，存储数十亿个对象，</p>
<p>跨数千台memcached服务器。整个EVCache集群<strong>每天处理近2万亿个</strong>请求。</p>
<p>EVCache集群响应平均延时大约是1-5毫秒，最多不会超过20毫秒。</p>
<p>EVCache集群的缓存命中率在99%左右。</p>
<p><strong>典型部署</strong></p>
<p>EVCache 是线性扩展的，可以在一分钟之内完成扩容，在几分钟之内完成负载均衡和缓存预热。</p>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmapg99q8lj30ix0f3jrw.jpg" alt="image-20210103185611516" style="zoom:50%;" />

<p>1、集群启动时，EVCache向服务注册中心（Zookeeper、Eureka）注册各个实例</p>
<p>2、在web应用启动时，查询命名服务中的EVCache服务器列表，并建立连接。</p>
<p>3、客户端通过key使用一致性hash算法，将数据分片到集群上。</p>
<h4 id="6、ETCD"><a href="#6、ETCD" class="headerlink" title="6、ETCD"></a>6、ETCD</h4><p>​    <strong>和Zookeeper一样，CP模型追求数据一致性，</strong>越来越多的系统开始用它保存关键数据。比如，秒杀系统经常用它<strong>保存各节点信</strong>息，以便控制消费 MQ 的服务数量。还有些业务系统的<strong>配置数据</strong>，也会通过 etcd 实时同步给业务系统的各节点，比如，秒杀管理后台会使用 etcd 将秒杀活动的<strong>配置数据实时同步给秒杀 API 服务各节点</strong>。</p>
<p>![image-20210418174251742](&#x2F;Users&#x2F;suhongliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20210418174251742.png)</p>
<div style="page-break-after: always;"></div>

<h3 id="Redis底层"><a href="#Redis底层" class="headerlink" title="Redis底层"></a>Redis底层</h3><h4 id="1、redis数据类型"><a href="#1、redis数据类型" class="headerlink" title="1、redis数据类型"></a>1、redis数据类型</h4><table>
<thead>
<tr>
<th>类型</th>
<th>底层</th>
<th>应用场景</th>
<th>编码类型</th>
</tr>
</thead>
<tbody><tr>
<td>String</td>
<td>SDS数组</td>
<td>帖子、评论、热点数据、输入缓冲</td>
<td>RAW &lt;&lt; EMBSTR &lt;&lt; INT</td>
</tr>
<tr>
<td>List</td>
<td>QuickList</td>
<td>评论列表、商品列表、发布与订阅、慢查询、监视器</td>
<td>LINKEDLIST &lt;&lt; ZIPLIST</td>
</tr>
<tr>
<td>Set</td>
<td>intSet</td>
<td>适合交集、并集、查集操作，例如朋友关系</td>
<td>HT &lt;&lt; INSET</td>
</tr>
<tr>
<td>Zset</td>
<td>跳跃表</td>
<td>去重后排序，适合排名场景</td>
<td>SKIPLIST &lt;&lt; ZIPLIST</td>
</tr>
<tr>
<td>Hash</td>
<td>哈希</td>
<td>结构化数据，比如存储对象</td>
<td>HT &lt;&lt; ZIPLIST</td>
</tr>
<tr>
<td>Stream</td>
<td>紧凑列表</td>
<td>消息队列</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2、相关API"><a href="#2、相关API" class="headerlink" title="2、相关API"></a><strong>2、相关API</strong></h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://redisdoc.com/">http://redisdoc.com</a></p>
</blockquote>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>String</td>
<td>SET</td>
<td>SETNX</td>
<td>SETEX</td>
<td>GET</td>
<td>GETSET</td>
<td>INCR</td>
<td>DECR</td>
<td>MSET</td>
<td>MGET</td>
</tr>
<tr>
<td>Hash</td>
<td>HSET</td>
<td>HSETNX</td>
<td>HGET</td>
<td>HDEL</td>
<td>HLEN</td>
<td>HMSET</td>
<td>HMGET</td>
<td>HKEYS</td>
<td>HGETALL</td>
</tr>
<tr>
<td>LIST</td>
<td>LPUSH</td>
<td>LPOP</td>
<td>RPUSH</td>
<td>RPOP</td>
<td>LINDEX</td>
<td>LREM</td>
<td>LRANGE</td>
<td>LLEN</td>
<td>RPOPLPUSH</td>
</tr>
<tr>
<td>ZSET</td>
<td>ZADD</td>
<td>ZREM</td>
<td>ZSCORE</td>
<td>ZCARD</td>
<td>ZRANGE</td>
<td>ZRANK</td>
<td>ZREVRANK</td>
<td></td>
<td>ZREVRANGE</td>
</tr>
<tr>
<td>SET</td>
<td>SADD</td>
<td>SREM</td>
<td>SISMEMBER</td>
<td>SCARD</td>
<td>SINTER</td>
<td>SUNION</td>
<td>SDIFF</td>
<td>SPOP</td>
<td>SMEMBERS</td>
</tr>
<tr>
<td>事务</td>
<td>MULTI</td>
<td>EXEC</td>
<td>DISCARD</td>
<td>WATCH</td>
<td>UNWATCH</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h4 id="3、redis底层结构"><a href="#3、redis底层结构" class="headerlink" title="3、redis底层结构"></a>3、redis底层结构</h4><p><strong>SDS数组结构</strong>，用于存储字符串和整型数据及输入缓冲。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">struct sdshdr&#123; </span><br><span class="line">  <span class="type">int</span> len;<span class="comment">//记录buf数组中已使用字节的数量 </span></span><br><span class="line">  <span class="type">int</span> free; <span class="comment">//记录 buf 数组中未使用字节的数量 </span></span><br><span class="line">  <span class="type">char</span> buf[];<span class="comment">//字符数组，用于保存字符串</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>跳跃表</strong>：将有序链表中的部分节点分层，每一层都是一个有序链表。</p>
<p>​    1、可以快速查找到需要的节点 O(logn) ，额外存储了一倍的空间</p>
<p>​    2、可以在O(1)的时间复杂度下，快速获得跳跃表的头节点、尾结点、长度和高度。            </p>
<p><strong>字典dict:</strong> 又称散列表(hash)，是用来存储键值对的一种数据结构。 </p>
<p>​    Redis整个数据库是用字典来存储的(K-V结构) —Hash+数组+链表</p>
<p>​    Redis字典实现包括:**字典(dict)、Hash表(dictht)、Hash表节点(dictEntry)**。</p>
<p>​    字典达到存储上限(阈值 0.75)，需要rehash(扩容)</p>
<p>​    1、初次申请默认容量为4个dictEntry，非初次申请为当前hash表容量的一倍。</p>
<p>​    2、rehashidx&#x3D;0表示要进行rehash操作。</p>
<p>​    3、新增加的数据在新的hash表h[1] 、修改、删除、查询在老hash表h[0]</p>
<p>​    4、将老的hash表h[0]的数据重新计算索引值后全部迁移到新的hash表h[1]中，这个过程称为 rehash。</p>
<p>​    <strong>渐进式rehash</strong></p>
<pre><code> 由于当数据量巨大时rehash的过程是非常缓慢的，所以需要进行优化。 可根据服务器空闲程度批量rehash部分节点
</code></pre>
<p><strong>压缩列表zipList</strong></p>
<p>​    压缩列表(ziplist)是由一系列特殊编码的连续内存块组成的顺序型数据结构，节省内容</p>
<p>​    <strong>sorted-set和hash元素个数少</strong>且是小整数或短字符串(直接使用) </p>
<p>​    list用快速链表(quicklist)数据结构存储，而<strong>快速链表是双向列表与压缩列表</strong>的组合。(间接使用)</p>
<p><strong>整数集合intSet</strong></p>
<p>​    整数集合(intset)是一个有序的(整数升序)、存储整数的连续存储结构。 </p>
<p>​    当Redis集合类型的元素都是整数并且都处在64位有符号整数范围内(2^64)，使用该结构体存储。</p>
<p><strong>快速列表quickList</strong></p>
<p>​    快速列表(quicklist)是Redis底层重要的数据结构。是Redis3.2列表的底层实现。</p>
<p>​    (在Redis3.2之前，Redis采 用双向链表(adlist)和压缩列表(ziplist)实现。)</p>
<p><strong>Redis Stream</strong>的底层主要使用了listpack(紧凑列表)和Rax树(基数树)。</p>
<p>​    <strong>listpack</strong>表示一个字符串列表的序列化，listpack可用于存储字符串或整数。用于存储stream的消息内 容。</p>
<p>​    <strong>Rax树</strong>是一个有序字典树 (基数树 Radix Tree)，按照 key 的字典序排列，支持快速地定位、插入和删除操 作。</p>
<h4 id="4、Zset底层实现"><a href="#4、Zset底层实现" class="headerlink" title="4、Zset底层实现"></a>4、Zset底层实现</h4><p>​        跳表(skip List)是一种随机化的数据结构，基于并联的链表，实现简单，插入、删除、查找的复杂度均为O(logN)。简单说来跳表也是链表的一种，只不过它在链表的基础上增加了跳跃功能，正是这个跳跃的功能，使得在查找元素时，跳表能够提供O(logN)的时间复杂度</p>
<p>​        Zset<strong>数据量少的时候使用压缩链表ziplist</strong>实现，有序集合使用紧挨在一起的压缩列表节点来保存，第一个节点保存member，第二个保存score。ziplist内的集合元素按score从小到大排序，score较小的排在表头位置。 <strong>数据量大的时候使用跳跃列表skiplist和哈希表hash_map</strong>结合实现，查找删除插入的时间复杂度都是O(longN)</p>
<p>​        Redis使用跳表而不使用红黑树，是因为跳表的索引结构序列化和反序列化更加快速，方便持久化。</p>
<p><strong>搜索</strong></p>
<p>​        跳跃表按 score 从小到大保存所有集合元素，查找时间复杂度为平均 <em>O(logN)，最坏 O(N) 。</em></p>
<p><strong>插入</strong></p>
<p>  选用链表作为底层结构支持，为了高效地动态增删。因为跳表底层的单链表是有序的，为了维护这种有序性，在插入前需要遍历链表，找到该插入的位置，单链表遍历查找的时间复杂度是O(n)，同理可得，跳表的遍历也是需要遍历索引数，所以是O(logn)。</p>
<p><strong>删除</strong></p>
<p>  如果该节点还在索引中，删除时不仅要删除单链表中的节点，还要删除索引中的节点；单链表在知道删除的节点是谁时，时间复杂度为O(1)，但针对单链表来说，删除时都需要拿到前驱节点O(logN)才可改变引用关系从而删除目标节点。</p>
<div style="page-break-after: always;"></div>

<h3 id="Redis可用性"><a href="#Redis可用性" class="headerlink" title="Redis可用性"></a><strong>Redis可用性</strong></h3><h4 id="1、redis持久化"><a href="#1、redis持久化" class="headerlink" title="1、redis持久化"></a>1、redis持久化</h4><p>持久化就是把内存中的数据持久化到本地磁盘，防止服务器宕机了内存数据丢失</p>
<p>Redis 提供两种持久化机制 <strong>RDB（默认）</strong> 和 <strong>AOF 机制</strong>，Redis4.0以后采用混合持久化，用 AOF 来<strong>保证数据不丢失</strong>，作为数据恢复的第一选择; 用 RDB 来做不同程度的<strong>冷备</strong></p>
<p><strong>RDB：</strong>是Redis DataBase缩写快照</p>
<p>​        RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。</p>
<p>​    <strong>优点：</strong></p>
<p>​    1）只有一个文件 dump.rdb，方便持久化；</p>
<p>​    2）容灾性好，一个文件可以保存到安全的磁盘。</p>
<p>​    3）性能最大化，fork 子进程来进行持久化写操作，让主进程继续处理命令，只存在毫秒级不响应请求。</p>
<p>​    4）相对于数据集大时，比 AOF 的启动效率更高。</p>
<p>​    <strong>缺点：</strong></p>
<p>​    数据安全性低，RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。</p>
<p><strong>AOF：持久化</strong></p>
<p>​        AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。</p>
<p>​    <strong>优点：</strong></p>
<p>​    1）数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录到 aof 文件中一次。</p>
<p>​    2）通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。</p>
<p><strong>缺点：</strong></p>
<p>​    1）AOF 文件比 RDB 文件大，且恢复速度慢。</p>
<p>​    2）数据集大的时候，比 rdb 启动效率低。</p>
<h4 id="2、redis事务"><a href="#2、redis事务" class="headerlink" title="2、redis事务"></a>2、redis事务</h4><p>​        事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。</p>
<p><strong>Redis事务的概念</strong></p>
<p>​        Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。</p>
<p>Redis的事务总是具有ACID中的<strong>一致性和隔离性</strong>，其他特性是不支持的。当服务器运行在AOF持久化模式下，并且appendfsync选项的值为always时，事务也具有耐久性。</p>
<p>Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的</p>
<p><strong>事务命令：</strong></p>
<p><strong>MULTI：</strong>用于开启一个事务，它总是返回OK。MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。</p>
<p><strong>EXEC：</strong>执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。当操作被打断时，返回空值 nil 。</p>
<p><strong>WATCH ：</strong>是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。（<strong>秒杀场景</strong>）</p>
<p><strong>DISCARD：</strong>调用该命令，客户端可以清空事务队列，并放弃执行事务，且客户端会从事务状态中退出。</p>
<p><strong>UNWATCH</strong>：命令可以取消watch对所有key的监控。</p>
<h4 id="3、redis失效策略"><a href="#3、redis失效策略" class="headerlink" title="3、redis失效策略"></a>3、redis失效策略</h4><p><strong>内存淘汰策略</strong></p>
<p>1）全局的键空间选择性移除</p>
<p>​    <strong>noeviction</strong>：当内存不足以容纳新写入数据时，新写入操作会报错。（字典库常用）</p>
<p>​    <strong>allkeys-lru</strong>：在键空间中，移除最近最少使用的key。（缓存常用）</p>
<p>​    <strong>allkeys-random</strong>：在键空间中，随机移除某个key。</p>
<p>2）设置过期时间的键空间选择性移除</p>
<p>​    <strong>volatile-lru</strong>：在设置了过期时间的键空间中，移除最近最少使用的key。</p>
<p>​    <strong>volatile-random</strong>：在设置了过期时间的键空间中，随机移除某个key。</p>
<p>​    <strong>volatile-ttl</strong>：在设置了过期时间的键空间中，有更早过期时间的key优先移除。</p>
<p><strong>缓存失效策略</strong></p>
<p>​    <strong>定时清除：</strong>针对每个设置过期时间的key都创建指定定时器</p>
<p>​    <strong>惰性清除：</strong>访问时判断，对内存不友好</p>
<p>​    <strong>定时扫描清除：</strong>定时100ms随机20个检查过期的字典，若存在25%以上则继续循环删除。</p>
<h4 id="4、redis读写模式"><a href="#4、redis读写模式" class="headerlink" title="4、redis读写模式"></a>4、redis读写模式</h4><p>​    <strong>CacheAside旁路缓存</strong></p>
<p>写请求更新数据库后删除缓存数据。读请求不命中查询数据库，查询完成写入缓存</p>
<img src="https://img-blog.csdnimg.cn/20200806194316539.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eF92aWN0b3J5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 15%;" />

<img src="https://img-blog.csdnimg.cn/20200806194300826.png" style="zoom: 15%;" />

<p>​    业务端处理所有数据访问细节，同时利用 <strong>Lazy 计算</strong>的思想，更新 DB 后，直接删除 cache 并通过 DB 更新，确保数据以 DB 结果为准，则可以大幅降低 cache 和 DB 中数据不一致的概率</p>
<p>​    如果没有专门的存储服务，同时是对<strong>数据一致性要求比较高的业务，或者是缓存数据更新比较复杂的业务</strong>，适合使用 Cache Aside 模式。如微博发展初期，不少业务采用这种模式</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 延迟双删，用以保证最终一致性,防止小概率旧数据读请求在第一次删除后更新数据库</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(String key,Object data)</span>&#123;</span><br><span class="line">	redis.delKey(key);</span><br><span class="line">	db.updateData(data);</span><br><span class="line">	Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">	redis.delKey(key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>高并发下保证绝对的一致，先删缓存再更新数据，需要用到<strong>内存队列做异步串行化</strong>。非高并发场景，先更新数据再删除缓存，<strong>延迟双删</strong>策略基本满足了</p>
<ul>
<li>先更新db后删除redis：删除redis失败则出现问题</li>
<li>先删redis后更新db：删除redis瞬间，旧数据被回填redis</li>
<li>先删redis后更新db休眠后删redis：同第二点，休眠后删除redis 可能宕机</li>
<li>java内部jvm队列：不适用分布式场景且降低并发</li>
</ul>
<p>​    <strong>Read&#x2F;Write Though</strong>（读写穿透）</p>
<p>​        <strong>先查询</strong>缓存中数据是否存在,如果存在则直接返回,如果<strong>不存在</strong>,则由<strong>缓存组件负责从数据库中同步加载数据.</strong></p>
<p>​    <img src="https://img-blog.csdnimg.cn/20200806194334623.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eF92aWN0b3J5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 50%;" /></p>
<p>​    先查询要<strong>写入的数据在缓存中</strong>是否已经存在,如果已经存在,则<strong>更新缓存中的数据</strong>，并且由<strong>缓存组件同步更新</strong>到数据库中。</p>
<p>​    <img src="https://img-blog.csdnimg.cn/20200806194346642.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eF92aWN0b3J5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 50%" /></p>
<p>​    用户<strong>读操作</strong>较多.相较于Cache aside而言更适合缓存一致的场景。使用简单屏蔽了<strong>底层数据库的操作</strong>,只是操作缓存.</p>
<p><strong>场景：</strong></p>
<p>微博 Feed 的 Outbox Vector（即用户最新微博列表）就采用这种模式。一些粉丝较少且不活跃的用户发表微博后，Vector 服务会首先查询 Vector Cache，如果 cache 中没有该用户的 Outbox 记录，则不写该用户的 cache 数据，直接更新 DB 后就返回，只有 cache 中存在才会通过 CAS 指令进行更新。</p>
<p>​    </p>
<p><strong>Write Behind Caching（异步缓存写入）</strong></p>
<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gorlsg74i6j31950e3dhs.jpg" alt="img" style="zoom:35%;" />

<p>比如对一些计数业务，一条 <strong>Feed 被点赞</strong> 1万 次，如果更新 1万 次 DB 代价很大，而合并成一次请求直接加 1万，则是一个非常轻量的操作。但这种模型有个显著的缺点，即数据的一致性变差，甚至在一些极端场景下可能会丢失数据。</p>
<h4 id="5、多级缓存"><a href="#5、多级缓存" class="headerlink" title="5、多级缓存"></a>5、多级缓存</h4><p><strong>浏览器本地内存缓存：</strong>专题活动，一旦上线，在活动期间是不会随意变更的。</p>
<p><strong>浏览器本地磁盘缓存：</strong>Logo缓存，大图片懒加载</p>
<p><strong>服务端本地内存缓存：</strong>由于没有持久化，重启时必定会被穿透</p>
<p><strong>服务端网络内存缓存</strong>：Redis等，针对穿透的情况下可以继续分层，必须保证数据库不被压垮</p>
<p><strong>为什么不是使用服务器本地磁盘做缓存？</strong></p>
<p>​    当系统处理大量磁盘 IO 操作的时候，由于 CPU 和内存的速度远高于磁盘，可能导致 CPU 耗费太多时间等待磁盘返回处理的结果。对于这部分 CPU 在 IO 上的开销，我们称为 <strong>iowait</strong></p>
<div style="page-break-after: always;"></div>

<h3 id="Redis七大经典问题"><a href="#Redis七大经典问题" class="headerlink" title="Redis七大经典问题"></a>Redis七大经典问题</h3><h4 id="1、缓存雪崩"><a href="#1、缓存雪崩" class="headerlink" title="1、缓存雪崩"></a>1、缓存雪崩</h4><p>​        指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p>
<p>​    <strong>解决方案：</strong></p>
<ul>
<li><p><strong>Redis 高可用</strong>，主从+哨兵，Redis cluster，避免全盘崩溃</p>
</li>
<li><p>本地 ehcache 缓存 + hystrix <strong>限流&amp;降级</strong>，避免 MySQL 被打死</p>
</li>
<li><p>缓存数据的<strong>过期时间设置随机</strong>，防止同一时间大量数据过期现象发生。</p>
</li>
<li><p><strong>逻辑上永不过期</strong>给每一个缓存数据增加相应的<strong>缓存标记</strong>，缓存标记失效则更新数据缓存</p>
</li>
<li><p><strong>多级缓存</strong>，失效时通过二级更新一级，由第三方插件更新二级缓存。</p>
</li>
</ul>
<h4 id="2、缓存穿透"><a href="#2、缓存穿透" class="headerlink" title="2、缓存穿透"></a><strong>2、缓存穿透</strong></h4><p>​        <a target="_blank" rel="noopener" href="https://blog.csdn.net/lin777lin/article/details/105666839">https://blog.csdn.net/lin777lin/article/details/105666839</a></p>
<p>​        缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p>
<p>​    <strong>解决方案：</strong></p>
<p>​    1）<strong>接口层增加校验</strong>，如用户鉴权校验，id做基础校验，id&lt;&#x3D;0的直接拦截；</p>
<p>​    2）从缓存取不到的数据，在数据库中也没有取到，这时也可以将<strong>key-value对写为key-null</strong>，缓存有效时间可以设置短点，如30秒。这样可以防止攻击用户反复用同一个id暴力攻击；</p>
<p>​    3）采用<strong>布隆过滤器</strong>，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力。（宁可错杀一千不可放过一人）</p>
<h4 id="3、缓存击穿"><a href="#3、缓存击穿" class="headerlink" title="3、缓存击穿"></a><strong>3、缓存击穿</strong></h4><p>​        这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库</p>
<p>​    <strong>解决方案：</strong></p>
<p>​    1）设置<strong>热点数据永远不过期</strong>，异步线程处理。</p>
<p>​    2）加<strong>写回操作加互斥锁</strong>，查询失败默认值快速返回。</p>
<p>​    3）缓存预热</p>
<p>​        系统上线后，将相关<strong>可预期（例如排行榜）</strong>热点数据直接加载到缓存。</p>
<p>​        写一个缓存刷新页面，手动操作热点数据<strong>（例如广告推广）</strong>上下线。</p>
<h4 id="4、数据不一致"><a href="#4、数据不一致" class="headerlink" title="4、数据不一致"></a>4、数据不一致</h4><p>​    在缓存机器的带宽被打满，或者机房网络出现波动时，缓存更新失败，新数据没有写入缓存，就会导致缓存和 DB 的数据不一致。缓存 rehash 时，某个缓存机器反复异常，多次上下线，更新请求多次 rehash。这样，一份数据存在多个节点，且每次 rehash 只更新某个节点，导致一些缓存节点产生脏数据。</p>
<ul>
<li><p>Cache 更新失败后，可以进行重试，则将重试失败的 key 写入mq，待缓存访问恢复后，将这些 key 从缓存删除。这些 key 在再次被查询时，重新从 DB 加载，从而保证数据的一致性</p>
</li>
<li><p>缓存时间适当调短，让缓存数据及早过期后，然后从 DB 重新加载，确保数据的最终一致性。</p>
</li>
<li><p>不采用 rehash 漂移策略，而采用缓存分层策略，尽量避免脏数据产生。</p>
</li>
</ul>
<h4 id="5、数据并发竞争"><a href="#5、数据并发竞争" class="headerlink" title="5、数据并发竞争"></a>5、数据并发竞争</h4><p>​    数据并发竞争在大流量系统也比较常见，比如车票系统，如果某个火车车次缓存信息过期，但仍然有大量用户在查询该车次信息。又比如微博系统中，如果某条微博正好被缓存淘汰，但这条微博仍然有大量的转发、评论、赞。上述情况都会造成并发竞争读取的问题。</p>
<ul>
<li>​    加<strong>写回操作加互斥锁</strong>，查询失败默认值快速返回。</li>
<li>​    对缓存数据保持多个备份，减少并发竞争的概率</li>
</ul>
<p>​    </p>
<h4 id="6、热点key问题"><a href="#6、热点key问题" class="headerlink" title="6、热点key问题"></a>6、热点key问题</h4><p>​    明星结婚、离婚、出轨这种特殊突发事件，比如奥运、春节这些重大活动或节日，还比如秒杀、双12、618 等线上促销活动，都很容易出现 Hot key 的情况。</p>
<p>如何提前发现HotKey？</p>
<ul>
<li>对于重要节假日、线上促销活动这些提前已知的事情，可以提前评估出可能的热 key 来。</li>
<li>而对于突发事件，无法提前评估，可以<strong>通过 Spark，对应流任务进行实时分析</strong>，及时发现新发布的热点 key。而对于之前已发出的事情，逐步发酵成为热 key 的，则可以通过 Hadoop 对批处理任务离线计算，找出最近历史数据中的高频热 key。</li>
</ul>
<p><strong>解决方案：</strong></p>
<ul>
<li><p>这 n 个 key 分散存在多个缓存节点，然后 client 端请求时，随机访问其中某个后缀的 hotkey，这样就可以把热 key 的请求打散，避免一个缓存节点过载</p>
</li>
<li><p>缓存集群可以单节点进行主从复制和垂直扩容</p>
</li>
<li><p>利用应用内的前置缓存，但是需注意需要设置上限</p>
</li>
<li><p>延迟不敏感，定时刷新，实时感知用主动刷新</p>
</li>
<li><p>和缓存穿透一样，限制逃逸流量，单请求进行数据回源并刷新前置</p>
</li>
<li><p>无论如何设计，最后都要写一个兜底逻辑，千万级流量说来就来</p>
</li>
</ul>
<h4 id="7、BigKey问题"><a href="#7、BigKey问题" class="headerlink" title="7、BigKey问题"></a>7、BigKey问题</h4><p>​    比如互联网系统中需要保存用户最新 1万 个粉丝的业务，比如一个用户个人信息缓存，包括基本资料、关系图谱计数、发 feed 统计等。微博的 feed 内容缓存也很容易出现，一般用户微博在 140 字以内，但很多用户也会发表 1千 字甚至更长的微博内容，这些长微博也就成了大 key</p>
<ul>
<li>首先Redis底层数据结构里，根据Value的不同，会进行数据结构的重新选择</li>
<li>可以扩展新的数据结构，进行序列化构建，然后通过 restore 一次性写入</li>
<li>将大 key 分拆为多个 key，设置较长的过期时间</li>
</ul>
<div style="page-break-after: always;"></div>

<h3 id="Redis分区容错"><a href="#Redis分区容错" class="headerlink" title="Redis分区容错"></a>Redis分区容错</h3><h4 id="1、redis数据分区"><a href="#1、redis数据分区" class="headerlink" title="1、redis数据分区"></a><strong>1、redis数据分区</strong></h4><p><strong>Hash：（不稳定）</strong></p>
<p>​        客户端分片：哈希+取余</p>
<p>​        节点伸缩：数据节点关系变化，导致数据迁移</p>
<p>​        迁移数量和添加节点数量有关：建议翻倍扩容</p>
<p>​        一个简单直观的想法是直接用Hash来计算，以Key做哈希后对节点数取模。可以看出，在key足够分散的情况下，均匀性可以获得，但一旦有节点加入或退出，所有的原有节点都会受到影响，稳定性无从谈起。</p>
<p><strong>一致性Hash：（不均衡）</strong></p>
<p>​        客户端分片：哈希+顺时针（优化取余）</p>
<p>​        节点伸缩：只影响邻近节点，但是还是有数据迁移</p>
<p>​        翻倍伸缩：保证最小迁移数据和负载均衡</p>
<p>​        一致性Hash可以很好的解决稳定问题，可以将所有的存储节点排列在收尾相接的Hash环上，每个key在计算Hash后会顺时针找到先遇到的一组存储节点存放。而当有节点加入或退出时，仅影响该节点在Hash环上顺时针相邻的后续节点，将数据从该节点接收或者给予。但这又带来均匀性的问题，即使可以将存储节点等距排列，也会在<strong>存储节点个数变化时带来数据的不均匀</strong>。</p>
<p><strong>Codis的Hash槽</strong></p>
<p>​        Codis 将所有的 key 默认划分为 1024 个槽位(slot)，它首先对客户端传过来的 key 进行 crc32 运算计算 哈希值，再将 hash 后的整数值对 1024 这个整数进行取模得到一个余数，这个余数就是对应 key 的槽位。</p>
<p><strong>RedisCluster</strong></p>
<p>​        Redis-cluster把所有的物理节点映射到[0-16383]个<strong>slot</strong>上,对key采用crc16算法得到hash值后对16384取模，基本上采用平均分配和连续分配的方式。</p>
<h4 id="2、主从模式-x3D-简单"><a href="#2、主从模式-x3D-简单" class="headerlink" title="2、主从模式&#x3D;简单"></a><strong>2、主从模式&#x3D;简单</strong></h4><p>​    主从模式最大的优点是<strong>部署简单</strong>，最少<strong>两个节点便可以构成主从模式</strong>，并且可以通过<strong>读写分离避免读和写同时不可用</strong>。不过，一旦 Master 节点出现故障，主从节点就<strong>无法自动切换</strong>，直接导致 SLA 下降。所以，主从模式一般<strong>适合业务发展初期，并发量低，运维成本低</strong>的情况</p>
<img src="https://s0.lgstatic.com/i/image/M00/80/25/Ciqc1F_QgPOAaL8TAAC5EiNlvo4795.png" alt="Drawing 1.png" style="zoom:50%;" />



<p><strong>主从复制原理：</strong></p>
<p>​    ①通过从服务器发送到PSYNC命令给主服务器</p>
<p>​    ②如果是首次连接，触发一次<strong>全量复制</strong>。此时主节点会启动一个后台线程，生成 RDB 快照文件</p>
<p>​    ③主节点会将这个 RDB 发送给从节点，slave 会先写入本地磁盘，再从本地磁盘加载到内存中</p>
<p>​    ④master会将此过程中的写命令写入缓存，从节点<strong>实时同步</strong>这些数据</p>
<p>​    ⑤如果网络断开了连接，自动重连后主节点通过命令传播<strong>增量复制</strong>给从节点部分缺少的数据</p>
<p><strong>缺点</strong></p>
<p>​    所有的slave节点数据的复制和同步都由master节点来处理，会照成master节点压力太大，使用主从从结构来解决，redis4.0中引入psync2 解决了slave重启后仍然可以增量同步。</p>
<h4 id="3、哨兵模式-x3D-读多"><a href="#3、哨兵模式-x3D-读多" class="headerlink" title="3、哨兵模式&#x3D;读多"></a>3、<strong>哨兵模式</strong>&#x3D;读多</h4><p>​    由一个或多个sentinel实例组成sentinel集群可以监视一个或多个主服务器和多个从服务器。<strong>哨兵模式适合读请求远多于写请求的业务场景，比如在秒杀系统</strong>中用来缓存活动信息。 如果写请求较多，当集群 Slave 节点数量多了后，Master 节点同步数据的压力会非常大。</p>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gluq6vlvglj30nw0e076f.jpg" alt="image-20201220231241725" style="zoom:50%;" />

<p>当主服务器进入下线状态时，sentinel可以将该主服务器下的某一从服务器升级为主服务器继续提供服务，从而保证redis的高可用性。</p>
<p><strong>检测主观下线状态</strong></p>
<p>​    Sentinel每秒一次向所有与它建立了命令连接的实例(主服务器、从服务器和其他Sentinel)发送PING命 令</p>
<p>​    实例在down-after-milliseconds毫秒内返回无效回复Sentinel就会认为该实例主观下线(<strong>SDown</strong>)</p>
<p><strong>检查客观下线状态</strong></p>
<p>​    当一个Sentinel将一个主服务器判断为主观下线后 ，Sentinel会向监控这个主服务器的所有其他Sentinel发送查询主机状态的命令</p>
<p>​    如果达到Sentinel配置中的quorum数量的Sentinel实例都判断主服务器为主观下线，则该主服务器就会被判定为客观下线(<strong>ODown</strong>)。</p>
<p><strong>选举Leader Sentinel</strong> </p>
<p>​    当一个主服务器被判定为客观下线后，监视这个主服务器的所有Sentinel会通过选举算法(raft)，选出一个Leader Sentinel去执行**failover(故障转移)**操作。</p>
<p>​    <strong>Raft算法</strong></p>
<p>​    Raft协议是用来解决分布式系统一致性问题的协议。 Raft协议描述的节点共有三种状态:Leader, Follower, Candidate。 Raft协议将时间切分为一个个的Term(任期)，可以认为是一种“逻辑时间”。 选举流程:<br>     ①Raft采用心跳机制触发Leader选举系统启动后，全部节点初始化为Follower，term为0</p>
<p>​     ②节点如果收到了RequestVote或者AppendEntries，就会保持自己的Follower身份 </p>
<p>​     ③节点如果一段时间内没收到AppendEntries消息，在该节点的超时时间内还没发现Leader，Follower就会转换成Candidate，自己开始竞选Leader。 一旦转化为Candidate，该节点立即开始下面几件事情:<br>​        –增加自己的term，启动一个新的定时器<br>​        –给自己投一票，向所有其他节点发送RequestVote，并等待其他节点的回复。</p>
<p>​     ④如果在计时器超时前，节点收到多数节点的同意投票，就转换成Leader。同时通过 AppendEntries，向其他节点发送通知。</p>
<p>​     ⑤每个节点在一个term内只能投一票，采取先到先得的策略，Candidate投自己， Follower会投给第一个收到RequestVote的节点。</p>
<p>​     ⑥Raft协议的定时器采取随机超时时间（选举的关键），先转为Candidate的节点会先发起投票，从而获得多数票。</p>
<p><strong>主服务器的选择</strong></p>
<p>​    当选举出Leader Sentinel后，Leader Sentinel会根据以下规则去从服务器中选择出新的主服务器。</p>
<ol>
<li>过滤掉主观、客观下线的节点</li>
<li>选择配置slave-priority最高的节点，如果有则返回没有就继续选择</li>
<li>选择出复制偏移量最大的系节点，因为复制偏移量越大则数据复制的越完整</li>
<li>选择run_id最小的节点，因为run_id越小说明重启次数越少</li>
</ol>
<p><strong>故障转移</strong></p>
<p>​    当Leader Sentinel完成新的主服务器选择后，Leader Sentinel会对下线的主服务器执行故障转移操作，主要有三个步骤:</p>
<p>​    1、它会将失效 Master 的其中一个 Slave 升级为新的 Master , 并让失效 Master 的其他 Slave 改为复制新的 Master ;</p>
<p>​    2、当客户端试图连接失效的 Master 时，集群会向客户端返回新 Master 的地址，使得集群当前状态只有一个Master。</p>
<p>​    3、Master 和 Slave 服务器切换后， Master 的 redis.conf 、 Slave 的 redis.conf 和 sentinel.conf 的配置文件的内容都会发生相应的改变，即 Master 主服务器的 redis.conf配置文件中会多一行 replicaof 的配置， sentinel.conf 的监控目标会随之调换。</p>
<h4 id="4、集群模式-x3D-写多"><a href="#4、集群模式-x3D-写多" class="headerlink" title="4、集群模式&#x3D;写多"></a>4、集群模式&#x3D;写多</h4><p>​    为了避免单一节点负载过高导致不稳定，集群模式采用<strong>一致性哈希算法或者哈希槽的方法</strong>将 Key 分布到各个节点上。其中，每个 Master 节点后跟若干个 Slave 节点，用于<strong>出现故障时做主备切换</strong>，客户端可以<strong>连接任意 Master 节点</strong>，集群内部会按照<strong>不同 key 将请求转发到不同的 Master</strong> 节点</p>
<p>​    集群模式是如何实现高可用的呢？集群内部节点之间会<strong>互相定时探测</strong>对方是否存活，如果多数节点判断某个节点挂了，则会将其踢出集群，然后从 <strong>Slave</strong> 节点中选举出一个节点<strong>替补</strong>挂掉的 Master 节点。<strong>整个原理基本和哨兵模式一致</strong></p>
<p>​    虽然集群模式避免了 Master 单节点的问题，但<strong>集群内同步数据时会占用一定的带宽</strong>。所以，只有在<strong>写操作比较多的情况下人们才使用集群模式</strong>，其他大多数情况，使用<strong>哨兵模式</strong>都能满足需求</p>
<h4 id="5、分布式锁"><a href="#5、分布式锁" class="headerlink" title="5、分布式锁"></a>5、分布式锁</h4><p><strong>利用Watch实现Redis乐观锁</strong></p>
<p>​    乐观锁基于CAS(Compare And Swap)比较并替换思想，不会产生锁等待而消耗资源，但是需要反复的重试，但也是因为重试的机制，能比较快的响应。因此我们可以利用redis来实现乐观锁<strong>（秒杀）</strong>。具体思路如下:</p>
<p>1、利用redis的watch功能，监控这个redisKey的状态值<br>2、获取redisKey的值，创建redis事务，给这个key的值+1<br>3、执行这个事务，如果key的值被修改过则回滚，key不加1</p>
<p><strong>利用setnx防止库存超卖</strong><br>    分布式锁是控制分布式系统之间同步访问共享资源的一种方式。 利用Redis的单线程特性对共享资源进行串行化处理</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取锁推荐使用set的方式</span></span><br><span class="line"><span class="type">String</span> <span class="variable">result</span> <span class="operator">=</span> jedis.set(lockKey, requestId, <span class="string">&quot;NX&quot;</span>, <span class="string">&quot;EX&quot;</span>, expireTime);</span><br><span class="line"><span class="type">String</span> <span class="variable">result</span> <span class="operator">=</span> jedis.setnx(lockKey, requestId); <span class="comment">//如线程死掉，其他线程无法获取到锁</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 释放锁，非原子操作，可能会释放其他线程刚加上的锁</span></span><br><span class="line"><span class="keyword">if</span> (requestId.equals(jedis.get(lockKey))) &#123; </span><br><span class="line">  jedis.del(lockKey);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 推荐使用redis+lua脚本</span></span><br><span class="line"><span class="type">String</span> <span class="variable">lua</span> <span class="operator">=</span> <span class="string">&quot;if redis.call(&#x27;get&#x27;,KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;,KEYS[1]) else return 0 end&quot;</span>;</span><br><span class="line"><span class="type">Object</span> <span class="variable">result</span> <span class="operator">=</span> jedis.eval(lua, Collections.singletonList(lockKey),</span><br></pre></td></tr></table></figure>



<p><strong>分布式锁存在的问题</strong>：</p>
<ul>
<li><strong>客户端长时间阻塞导致锁失效问题</strong></li>
</ul>
<p>​    计算时间内异步启动另外一个线程去检查的问题，这个key是否超时，当锁超时时间快到期且逻辑未执行完，延长锁超时时间。</p>
<ul>
<li><p>**Redis服务器时钟漂移问题导致同时加锁<br>redis的过期时间是依赖系统时钟的，如果时钟漂移过大时 理论上是可能出现的 **会影响到过期时间的计算。</p>
</li>
<li><p><strong>单点实例故障，锁未及时同步导致丢失</strong></p>
<p><strong>RedLock算法</strong></p>
</li>
</ul>
<ol>
<li><p>获取当前时间戳T0，配置时钟漂移误差T1</p>
</li>
<li><p>短时间内逐个获取全部N&#x2F;2+1个锁，结束时间点T2</p>
</li>
<li><p>实际锁能使用的处理时长变为：TTL - （T2 - T0）- T1</p>
<p>该方案通过多节点来<strong>防止Redis的单点故障</strong>，效果一般，也无法防止：</p>
</li>
</ol>
<ul>
<li><p><strong>主从切换导致的两个客户端同时持有锁</strong></p>
<p>大部分情况下<strong>持续时间极短</strong>，而且使用<strong>Redlock在切换的瞬间</strong>获取到节点的锁，也存在问题。已经是极低概率的时间，无法避免。<strong>Redis分布式锁适合幂等性事务</strong>，如果一定要<strong>保证安全</strong>，应该<strong>使用Zookeeper或者DB</strong>，但是，<strong>性能会急剧下降</strong>。</p>
</li>
</ul>
<p><strong>与zookeeper分布式锁对比</strong></p>
<ul>
<li>redis 分布式锁，其实<strong>需要自己不断去尝试获取锁</strong>，比较消耗性能。</li>
<li>zk 分布式锁，注册个监听器即可，不需要不断主动尝试获取锁，ZK获取锁会按照加锁的顺序，所以是公平锁，性能和mysql差不多，和redis差别大</li>
</ul>
<p><strong>Redission生产环境的分布式锁</strong></p>
<p>​    Redisson是基于NIO的Netty框架上的一个Java驻内存数据网格(In-Memory Data Grid)分布式锁开源组件。 </p>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1glurlfrrp4j30qk0g876c.jpg" alt="image-20201221000119586" style="zoom:67%;" />

<p>但当业务必须要数据的强一致性，即不允许重复获得锁，比如金融场景(重复下单，重复转账)，<strong>请不要使用redis分布式锁</strong>。可以使用CP模型实现，比如:<strong>zookeeper和etcd。</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>Redis</th>
<th>zookeeper</th>
<th>etcd</th>
</tr>
</thead>
<tbody><tr>
<td>一致性算法</td>
<td>无</td>
<td>paxos(ZAB)</td>
<td>raft</td>
</tr>
<tr>
<td>CAP</td>
<td>AP</td>
<td>CP</td>
<td>CP</td>
</tr>
<tr>
<td>高可用</td>
<td>主从集群</td>
<td>n+1</td>
<td>n+1</td>
</tr>
<tr>
<td>实现</td>
<td>setNX</td>
<td>createNode</td>
<td>restfulAPI</td>
</tr>
</tbody></table>
<h4 id="6、redis心跳检测"><a href="#6、redis心跳检测" class="headerlink" title="6、redis心跳检测"></a>6、redis心跳检测</h4><p>在命令传播阶段，从服务器默认会以每秒一次的频率向主服务器发送ACK命令:</p>
<p>​    1、检测主从的连接状态 检测主从服务器的网络连接状态</p>
<p>​            lag的值应该在0或1之间跳动，如果超过1则说明主从之间的连接有 故障。</p>
<p>​    2、辅助实现min-slaves,Redis可以通过配置防止主服务器在不安全的情况下执行写命令</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">min-slaves-to-write</span> <span class="number">3</span> <span class="string">(min-replicas-to-write</span> <span class="number">3</span> <span class="string">)</span></span><br><span class="line"></span><br><span class="line"><span class="string">min-slaves-max-lag</span> <span class="number">10</span> <span class="string">(min-replicas-max-lag</span> <span class="number">10</span><span class="string">)</span></span><br></pre></td></tr></table></figure>

<p>​        上面的配置表示:从服务器的数量少于3个，或者三个从服务器的延迟(lag)值都大于或等于10 秒时，主服务器将拒绝执行写命令。</p>
<p>​    3、检测命令丢失，增加重传机制</p>
<p>​        如果因为网络故障，主服务器传播给从服务器的写命令在半路丢失，那么当从服务器向主服务器发 送REPLCONF ACK命令时，主服务器将发觉从服务器当前的复制偏移量少于自己的复制偏移量， 然后主服务器就会根据从服务器提交的复制偏移量，在复制积压缓冲区里面找到从服务器缺少的数据，并将这些数据重新发送给从服务器。</p>
<div style="page-break-after: always;"></div>

<h3 id="Redis实战"><a href="#Redis实战" class="headerlink" title="Redis实战"></a>Redis实战</h3><h4 id="1、Redis优化"><a href="#1、Redis优化" class="headerlink" title="1、Redis优化"></a>1、Redis优化</h4><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gorm5m7b4gj30uy0hjwfp.jpg" alt="img"></p>
<p><strong>读写方式</strong><br>    简单来说就是不用<strong>keys</strong>等，用<strong>range、contains</strong>之类。比如，用户粉丝数，大 V 的粉丝更是高达几千万甚至过亿，因此，获取粉丝列表只能部分获取。另外在判断某用户是否关注了另外一个用户时，也只需要关注列表上进行检查判断，然后返回 True&#x2F;False 或 0&#x2F;1 的方式更为高效。</p>
<p><strong>KV size</strong><br>    如果单个业务的 KV size 过大，需要分拆成多个 KV 来缓存。拆分时应<strong>考虑访问频率</strong></p>
<p><strong>key 的数量</strong><br>    如果数据量巨大，则在缓存中尽可能只保留频繁访问的热数据，对于冷数据直接访问 DB。</p>
<p><strong>读写峰值</strong><br>    如果小于 10万 级别，简单分拆到独立 Cache 池即可<br>    如果达到 100万 级的QPS，则需要对 Cache 进行分层处理，可以同时使用 Local-Cache 配合远程 cache，甚至远程缓存内部继续分层叠加分池进行处理。<strong>（多级缓存）</strong></p>
<p><strong>命中率</strong><br>    缓存的命中率对整个服务体系的性能影响甚大。对于核心高并发访问的业务，需要预留足够的容量，确保核心业务缓存维持较高的命中率。比如微博中的 Feed Vector Cache（<strong>热点资讯</strong>），常年的命中率高达 99.5% 以上。为了持续保持缓存的命中率，缓存体系需要持续监控，及时进行故障处理或故障转移。同时在部分缓存节点异常、命中率下降时，故障转移方案，需要考虑是采用一致性 Hash 分布的访问漂移策略，还是采用数据多层备份策略。</p>
<p><strong>过期策略</strong></p>
<p>​    可以设置较短的过期时间，让冷 key 自动过期；也可以让 key 带上时间戳，同时设置较长的过期时间，比如很多业务系统内部有这样一些 key：key_20190801。</p>
<p><strong>缓存穿透时间</strong><br>    平均缓存穿透加载时间在某些业务场景下也很重要，对于一些缓存穿透后，加载时间特别长或者需要复杂计算的数据，而且访问量还比较大的业务数据，要配置更多容量，维持更高的命中率，从而减少穿透到 DB 的概率，来确保整个系统的访问性能。</p>
<p><strong>缓存可运维性</strong><br>    对于缓存的可运维性考虑，则需要考虑缓存体系的集群管理，如何进行一键扩缩容，如何进行缓存组件的升级和变更，如何快速发现并定位问题，如何持续监控报警，最好有一个完善的运维平台，将各种运维工具进行集成。</p>
<p><strong>缓存安全性</strong><br>    对于缓存的安全性考虑，一方面可以限制来源 IP，只允许内网访问，同时加密鉴权访问。</p>
<h4 id="2、Redis热升级"><a href="#2、Redis热升级" class="headerlink" title="2、Redis热升级"></a>2、Redis热升级</h4><blockquote>
<p>在 Redis 需要升级版本或修复 bug 时，如果直接重启变更，由于需要数据恢复，这个过程需要近 10 分钟的时间，时间过长，会严重影响系统的可用性。面对这种问题，可以对 Redis 扩展热升级功能，从而在毫秒级完成升级操作，完全不影响业务访问。</p>
</blockquote>
<p>热升级方案如下，首先构建一个 Redis 壳程序，将 redisServer 的所有属性（包括redisDb、client等）保存为全局变量。然后将 Redis 的处理逻辑代码全部封装到动态连接库 so 文件中。Redis 第一次启动，从磁盘加载恢复数据，在后续升级时，通过指令，壳程序重新加载 Redis 新的 redis-4.so 到 redis-5.so 文件，即可完成功能升级，毫秒级完成 Redis 的版本升级。而且整个过程中，所有 Client 连接仍然保留，在升级成功后，原有 Client 可以继续进行读写操作，整个过程对业务完全透明。</p>
<h1 id="六、Kafka篇"><a href="#六、Kafka篇" class="headerlink" title="六、Kafka篇"></a>六、Kafka篇</h1><h3 id="Why-kafka"><a href="#Why-kafka" class="headerlink" title="Why kafka"></a>Why kafka</h3><p>消息队列的作用：<strong>异步、削峰填谷、解耦</strong></p>
<p><strong>中小型公司</strong>，技术实力较为一般，技术挑战不是特别高，用 <strong>RabbitMQ</strong> （开源、社区活跃）是不错的选择；<strong>大型公司</strong>，基础架构研发实力较强，用 <strong>RocketMQ</strong>（Java二次开发） 是很好的选择。</p>
<p>如果是<strong>大数据领域</strong>的实时计算、日志采集等场景，用 <strong>Kafka</strong> 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。</p>
<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmfiyienm0j30zu0hago7.jpg" alt="image-20210107225921930" style="zoom:50%;" />



<p><strong>RabbitMQ</strong></p>
<p>RabbitMQ开始是用在电信业务的可靠通信的，也是少有的几款<strong>支持AMQP</strong>协议的产品之一。</p>
<p><strong>优点：</strong></p>
<ul>
<li>轻量级，快速，部署使用方便</li>
<li>支持灵活的路由配置。RabbitMQ中，在生产者和队列之间有一个交换器模块。根据配置的路由规则，生产者发送的消息可以发送到不同的队列中。路由规则很灵活，还可以自己实现。</li>
<li>RabbitMQ的客户端支持大多数的编程语言，支持<strong>AMQP</strong>协议。</li>
</ul>
<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmfjicxzb2j30u80hx0uw.jpg" alt="image-20210107231826261" style="zoom:40%;" />

<p><strong>缺点：</strong></p>
<ul>
<li>如果有大量消息堆积在队列中，性能会急剧下降</li>
<li>每秒处理几万到几十万的消息。如果应用要求高的性能，不要选择RabbitMQ。 </li>
<li>RabbitMQ是Erlang开发的，功能扩展和二次开发代价很高。</li>
</ul>
<p><strong>RocketMQ</strong></p>
<p>借鉴了Kafka的设计并做了很多改进，<strong>几乎具备了消息队列应该具备的所有特性和功能</strong>。</p>
<ul>
<li>RocketMQ主要用于有序，事务，流计算，消息推送，日志流处理，binlog分发等场景。</li>
<li>经过了历次的双11考验，性能，稳定性可靠性没的说。</li>
<li>java开发，阅读源代码、扩展、二次开发很方便。</li>
<li>对电商领域的响应延迟做了很多优化。</li>
<li>每秒处理几十万的消息，同时响应在毫秒级。如果应用很关注响应时间，可以使用RocketMQ。</li>
<li>性能比RabbitMQ高一个数量级，。</li>
<li>支持死信队列，DLX 是一个非常有用的特性。它可以处理<strong>异常情况下，消息不能够被消费者正确消费而被置入死信队列中</strong>的情况，后续分析程序可以通过消费这个死信队列中的内容来分析当时所遇到的异常情况，进而可以<strong>改善和优化系统</strong>。</li>
</ul>
<p><strong>缺点</strong>：</p>
<p>​    跟周边系统的整合和兼容不是很好。</p>
<p><strong>Kafka</strong></p>
<p><strong>高可用</strong>，几乎所有相关的开源软件都支持，满足大多数的应用场景，尤其是<strong>大数据和流计算</strong>领域，</p>
<ul>
<li>Kafka高效，可伸缩，消息持久化。支持分区、副本和容错。</li>
<li>对批处理和异步处理做了大量的设计，因此Kafka可以得到非常高的性能。</li>
<li>每秒处理几十万异步消息消息，如果开启了压缩，最终可以达到每秒处理2000w消息的级别。</li>
<li>但是由于是异步的和批处理的，延迟也会高，不适合电商场景。</li>
</ul>
<h3 id="What-Kafka"><a href="#What-Kafka" class="headerlink" title="What Kafka"></a>What Kafka</h3><ul>
<li>Producer API：允许应用程序将记录流发布到一个或多个Kafka主题。</li>
<li>Consumer API：允许应用程序订阅一个或多个主题并处理为其生成的记录流。</li>
<li>Streams API：允许应用程序充当流处理器，将输入流转换为输出流。</li>
</ul>
<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gme95cirjfj31000kb41j.jpg" alt="image-20210106203420526" style="zoom: 40%;" />



<p><strong>消息Message</strong></p>
<p>​    Kafka的数据单元称为消息。可以把消息看成是数据库里的一个“数据行”或一条“记录”。</p>
<p><strong>批次</strong></p>
<p>​    为了提高效率，消息被分批写入Kafka。提高吞吐量却加大了响应时间</p>
<p><strong>主题Topic</strong></p>
<p>​    通过主题进行分类，类似数据库中的表，</p>
<p><strong>分区Partition</strong></p>
<p>​    Topic可以被分成若干分区分布于kafka集群中，方便扩容</p>
<p>​    单个分区内是有序的，partition设置为一才能保证全局有序</p>
<p><strong>副本Replicas</strong></p>
<p>​    每个主题被分为若干个分区，每个分区有多个副本。</p>
<p><strong>生产者Producer</strong></p>
<p>​    生产者在默认情况下把<strong>消息均衡地分布</strong>到主题的所有分区上：</p>
<ul>
<li>直接指定消息的分区</li>
<li>根据消息的key散列取模得出分区</li>
<li>轮询指定分区。</li>
</ul>
<p><strong>消费者Comsumer</strong></p>
<p>​    消费者通过<strong>偏移量</strong>来区分已经读过的消息，从而消费消息。把每个分区最后读取的消息偏移量保存在Zookeeper 或Kafka上，如果消费者关闭或重启，它的<strong>读取状态不会丢失</strong>。</p>
<p><strong>消费组ComsumerGroup</strong></p>
<p>​    消费组保证<strong>每个分区只能被一个消费者</strong>使用，避免重复消费。如果群组内一个<strong>消费者失效</strong>，消费组里的其他消费者可以<strong>接管失效消费者的工作再平衡</strong>，重新分区</p>
<p><strong>节点Broker</strong></p>
<p>​    连接生产者和消费者，<strong>单个</strong>broker<strong>可以轻松处理</strong>数千个分区<strong>以及</strong>每秒百万级的消息量。</p>
<ul>
<li>broker接收来自生产者的消息，为消息设置偏移量，并提交<strong>消息到磁盘保存</strong>。</li>
<li>broker为消费者提供服务，响应读取分区的请求，<strong>返回已经提交到磁盘上的消息</strong>。</li>
</ul>
<p><strong>集群</strong></p>
<p>​    每隔分区都有一个<strong>首领</strong>，当分区被分配给多个broker时，会通过首领进行<strong>分区复制</strong>。    </p>
<p><strong>生产者Offset</strong></p>
<p>​    消息写入的时候，每一个分区都有一个offset，即每个分区的最新最大的offset。</p>
<p><strong>消费者Offset</strong></p>
<p>​    不同消费组中的消费者可以针对一个分区存储不同的Offset，互不影响</p>
<p><strong>LogSegment</strong></p>
<ul>
<li>一个分区由多个LogSegment组成，</li>
<li>一个LogSegment由<code>.log .index .timeindex</code>组成</li>
<li><code>.log</code>追加是顺序写入的，文件名是以文件中第一条message的offset来命名的</li>
<li><code>.Index</code>进行日志删除的时候和数据查找的时候可以快速定位。</li>
<li><code>.timeStamp</code>则根据<strong>时间戳查找对应的偏移量</strong>。</li>
</ul>
<h3 id="How-Kafka"><a href="#How-Kafka" class="headerlink" title="How Kafka"></a>How Kafka</h3><p><strong>优点</strong></p>
<ul>
<li><strong>高吞吐量</strong>：单机每秒处理几十上百万的消息量。即使存储了TB及消息，也保持稳定的性能。<ul>
<li><strong>零拷贝</strong> 减少内核态到用户态的拷贝，磁盘通过sendfile实现<strong>DMA</strong> 拷贝Socket buffer</li>
<li><strong>顺序读写</strong> 充分利用磁盘顺序读写的超高性能</li>
<li><strong>页缓存mmap</strong>，将磁盘文件<strong>映射</strong>到内存, 用户通过修改内存就能修改磁盘文件。</li>
</ul>
</li>
<li><strong>高性能</strong>：单节点支持上千个客户端，并保证零停机和零数据丢失。</li>
<li><strong>持久化</strong>：将消息持久化到磁盘。通过将数据持久化到硬盘以及replication防止数据丢失。</li>
<li><strong>分布式系统</strong>，易扩展。所有的组件均为分布式的，无需停机即可扩展机器。</li>
<li><strong>可靠性</strong> - Kafka是分布式，分区，复制和容错的。</li>
<li><strong>客户端状态维护</strong>：消息被处理的状态是在Consumer端维护，当失败时能自动平衡。</li>
</ul>
<p><strong>应用场景</strong></p>
<ul>
<li><strong>日志收集：</strong>用Kafka可以收集各种服务的Log，通过大数据平台进行处理；</li>
<li><strong>消息系统：</strong>解耦生产者和消费者、缓存消息等；</li>
<li><strong>用户活动跟踪：</strong>Kafka经常被用来记录Web用户或者App用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到Kafka的Topic中，然后消费者通过订阅这些Topic来做<strong>运营数据</strong>的实时的监控分析，也可保存到数据库；</li>
</ul>
<h3 id="生产消费基本流程"><a href="#生产消费基本流程" class="headerlink" title="生产消费基本流程"></a><strong>生产消费基本流程</strong></h3><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmeb1cw09gj313m0kgwgb.jpg" alt="image-20210106213944461" style="zoom:40%;" />

<ol>
<li><p>Producer创建时，会创建一个Sender线程并设置为守护线程。</p>
</li>
<li><p>生产的消息先经过拦截器-&gt;序列化器-&gt;分区器，然后将消息缓存在缓冲区。</p>
</li>
<li><p>批次发送的条件为：缓冲区数据大小达到<strong>batch.size</strong>或者<strong>linger.ms</strong>达到上限。</p>
</li>
<li><p>批次发送后，发往指定分区，然后落盘到broker；</p>
<ul>
<li><p><strong>acks&#x3D;0</strong>只要将消息放到缓冲区，就认为消息已经发送完成。</p>
</li>
<li><p><strong>acks&#x3D;1</strong>表示消息<strong>只需要写到主分区</strong>即可。在该情形下，如果主分区收到消息确认之后就宕机了，而副本分区还没来得及同步该消息，则该消息丢失。</p>
</li>
<li><p><strong>acks&#x3D;all （默认）</strong>首领分区会等待<strong>所有的ISR副本分区确认记录</strong>。该处理保证了只要有一个ISR副本分区存活，消息就不会丢失。</p>
</li>
</ul>
</li>
<li><p>如果生产者配置了<strong>retrires参数大于0并且未收到确认</strong>，那么客户端会对该消息进行重试。</p>
</li>
<li><p>落盘到broker成功，返回生产元数据给生产者。</p>
</li>
</ol>
<p><strong>Leader选举</strong></p>
<ul>
<li><p>Kafka会在Zookeeper上针对每个Topic维护一个称为ISR（in-sync replica）的集合</p>
</li>
<li><p>当集合中副本都跟Leader中的副本同步了之后，kafka才会认为消息已提交</p>
</li>
<li><p>只有这些跟Leader保持同步的Follower才应该被选作新的Leader</p>
</li>
<li><p>假设某个topic有N+1个副本，kafka可以容忍N个服务器不可用，冗余度较低</p>
<p>如果ISR中的副本都丢失了，则：</p>
<ul>
<li>可以等待ISR中的副本任何一个恢复，接着对外提供服务，需要时间等待</li>
<li>从OSR中选出一个副本做Leader副本，此时会造成数据丢失</li>
</ul>
</li>
</ul>
<p><strong>副本消息同步</strong></p>
<p>​    首先，Follower 发送 FETCH 请求给 Leader。接着，Leader 会读取底层日志文件中的消 息数据，再更新它内存中的 Follower 副本的 LEO 值，更新为 FETCH 请求中的 fetchOffset 值。最后，尝试更新分区高水位值。Follower 接收到 FETCH 响应之后，会把消息写入到底层日志，接着更新 LEO 和 HW 值。</p>
<p><strong>相关概念</strong>：<strong>LEO</strong>和<strong>HW</strong>。</p>
<ul>
<li>LEO：即日志末端位移(log end offset)，记录了该副本日志中下一条消息的位移值。如果LEO&#x3D;10，那么表示该副本保存了10条消息，位移值范围是[0, 9]</li>
<li>HW：水位值HW（high watermark）即已备份位移。对于同一个副本对象而言，其HW值不会大于LEO值。小于等于HW值的所有消息都被认为是“已备份”的（replicated）</li>
</ul>
<p><strong>Rebalance</strong></p>
<ul>
<li>组成员数量发生变化</li>
<li>订阅主题数量发生变化</li>
<li>订阅主题的分区数发生变化</li>
</ul>
<p>leader选举完成后，当以上三种情况发生时，Leader根据配置的<strong>RangeAssignor</strong>开始分配消费方案，即哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案封装进<strong>SyncGroup</strong>请求中发给coordinator，非leader也会发SyncGroup请求，只是内容为空。coordinator接收到分配方案之后会把方案塞进SyncGroup的response中发给各个consumer。这样组内的所有成员就都知道自己应该消费哪些分区了。</p>
<p><strong>分区分配算法RangeAssignor</strong></p>
<ul>
<li><p>原理是按照消费者总数和分区总数进行整除运算平均分配给所有的消费者。</p>
</li>
<li><p>订阅Topic的消费者按照名称的字典序排序，分均分配，剩下的字典序从前往后分配</p>
</li>
</ul>
<p><strong>增删改查</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper localhost:2181/myKafka --create --topic topic_x </span><br><span class="line">								--partitions 1 --replication-factor 1</span><br><span class="line">kafka-topics.sh --zookeeper localhost:2181/myKafka --delete --topic topic_x</span><br><span class="line">kafka-topics.sh --zookeeper localhost:2181/myKafka --alter --topic topic_x</span><br><span class="line">								--config max.message.bytes=1048576</span><br><span class="line">kafka-topics.sh --zookeeper localhost:2181/myKafka --describe --topic topic_x</span><br></pre></td></tr></table></figure>

<p><strong>如何查看偏移量为23的消息？</strong></p>
<p>通过查询跳跃表<code>ConcurrentSkipListMap</code>，定位到在00000000000000000000.index ，通过二分法在偏移量索引文件中找到不大于 23 的<strong>最大索引项</strong>，即offset 20 那栏，然后从日志分段文件中的物理位置为320 开始顺序查找偏移量为 23 的消息。</p>
<img src="https://img-blog.csdnimg.cn/20191230225447849.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjMzNzA2,size_16,color_FFFFFF,t_70" alt="img" style="zoom:50%;" />





<p><strong>切分文件</strong></p>
<ul>
<li><strong>大小分片</strong> 当前日志分段文件的大小超过了 broker 端参数 <code>log.segment.bytes</code> 配置的值</li>
<li><strong>时间分片</strong> 当前日志分段中消息的最大时间戳与系统的时间戳的差值大于<code>log.roll.ms</code>配置的值</li>
<li><strong>索引分片</strong> 偏移量或时间戳索引文件大小达到broker端 <code>log.index.size.max.bytes</code>配置的值</li>
<li><strong>偏移分片</strong> 追加的消息的偏移量与当前日志分段的偏移量之间的差值大于 Integer.MAX_VALUE</li>
</ul>
<h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p><strong>幂等性</strong></p>
<p>保证在消息重发的时候，消费者不会重复处理。即使在<strong>消费者收到重复消息的时候，重复处理</strong>，也</p>
<p>要<strong>保证最终结果的一致性</strong>。所谓幂等性，数学概念就是： f(f(x)) &#x3D; f(x) </p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmefdeas1vj315i0bgmya.jpg" alt="image-20210107000942286"></p>
<p><strong>如何实现？</strong></p>
<p>​    添加唯一ID，类似于数据库的主键，用于唯一标记一个消息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ProducerID：<span class="comment">#在每个新的Producer初始化时，会被分配一个唯一的PID</span></span><br><span class="line">SequenceNumber：<span class="comment">#对于每个PID发送数据的每个Topic都对应一个从0开始单调递增的SN值</span></span><br></pre></td></tr></table></figure>

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmefjpeet8j317e0cgmyp.jpg" alt="image-20210107001546404" style="zoom:80%;" />

<p><strong>如何选举</strong></p>
<ol>
<li>使用 Zookeeper 的<strong>分布式锁选举控制器</strong>，并在节点加入集群或退出集群时通知控制器。</li>
<li>控制器负责在节点加入或离开集群时进行分区Leader选举。</li>
<li>控制器使用epoch<code>忽略小的纪元</code>来避免<strong>脑裂</strong>：两个节点同时认为自己是当前的控制器。</li>
</ol>
<h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><ul>
<li>创建Topic的时候可以指定 –replication-factor 3 ，表示不超过broker的副本数</li>
<li>只有Leader是负责读写的节点，Follower定期地到Leader上Pull数据。</li>
<li>ISR是Leader负责维护的与其保持同步的Replica列表，即当前活跃的副本列表。如果一个Follow落后太多，Leader会将它从ISR中移除。选举时优先从ISR中挑选Follower。 </li>
<li>设置 acks&#x3D;all 。Leader收到了ISR中所有Replica的ACK，才向Producer发送ACK。</li>
</ul>
<div style="page-break-after: always;"></div>

<h3 id="面试题-2"><a href="#面试题-2" class="headerlink" title="面试题"></a>面试题</h3><h4 id="线上问题rebalance"><a href="#线上问题rebalance" class="headerlink" title="线上问题rebalance"></a><strong>线上问题rebalance</strong></h4><blockquote>
<p>因集群架构变动导致的消费组内重平衡，如果kafka集内节点较多，比如数百个，那重平衡可能会耗时导致<strong>数分钟到数小时</strong>，此时kafka基本处于不可用状态，对kafka的TPS影响极大</p>
</blockquote>
<p>产生的原因：</p>
<ul>
<li><p>组成员数量发生变化</p>
</li>
<li><p>订阅主题数量发生变化</p>
</li>
<li><p>订阅主题的分区数发生变化</p>
<p><strong>组成员崩溃和组成员主动离开是两个不同的场景。</strong>因为在崩溃时成员并不会主动地告知coordinator此事，coordinator有可能需要一个完整的session.timeout周期(心跳周期)才能检测到这种崩溃，这必然会造成consumer的滞后。可以说离开组是主动地发起rebalance；而崩溃则是被动地发起rebalance。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gooe9o07fvj30p00btju1.jpg" alt="img"></p>
</li>
</ul>
<p>解决方案：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">加大超时时间</span> <span class="string">session.timout.ms=6s</span></span><br><span class="line"><span class="attr">加大心跳频率</span> <span class="string">heartbeat.interval.ms=2s</span></span><br><span class="line"><span class="attr">增长推送间隔</span> <span class="string">max.poll.interval.ms=t+1 minutes</span></span><br></pre></td></tr></table></figure>



<h4 id="ZooKeeper-的作用"><a href="#ZooKeeper-的作用" class="headerlink" title="ZooKeeper 的作用"></a>ZooKeeper 的作用</h4><p>目前，Kafka 使用 ZooKeeper 存放集群元数据、成员管理、Controller 选举，以及其他一些管理类任务。之后，等 KIP-500 提案完成后，Kafka 将完全不再依赖于 ZooKeeper。</p>
<ul>
<li><strong>存放元数据</strong>是指主题分区的所有数据都保存在 ZooKeeper 中，其他“人”都要与它保持对齐。</li>
<li><strong>成员管理</strong>是指 Broker 节点的注册、注销以及属性变更等 。</li>
<li><strong>Controller 选举</strong>是指选举集群 Controller，包括但不限于主题删除、参数配置等。</li>
</ul>
<p>一言以蔽之:<strong>KIP-500 ，是使用社区自研的基于 Raft 的共识算法，实现 Controller 自选举</strong>。</p>
<p>同样是存储元数据，这几年<strong>基于Raft算法的etcd</strong>认可度越来越高</p>
<p>​    越来越多的系统开始用它保存关键数据。比如，<strong>秒杀系统经常用它保存各节点信息</strong>，以便控制消费 MQ 的服务数量。还有些<strong>业务系统的配置数据</strong>，也会通过 etcd 实时<strong>同步给业务系统的各节点</strong>，比如，秒杀管理后台会使用 etcd 将<strong>秒杀活动的配置数据实时同步给秒杀 API 服务各节点</strong>。</p>
<h4 id="Replica副本的作用"><a href="#Replica副本的作用" class="headerlink" title="Replica副本的作用"></a>Replica副本的作用</h4><p><strong>Kafka 只有 Leader 副本才能 对外提供读写服务，响应 Clients 端的请求。Follower 副本只是采用拉(PULL)的方 式，被动地同步 Leader 副本中的数据，并且在 Leader 副本所在的 Broker 宕机后，随时准备应聘 Leader 副本。</strong></p>
<ul>
<li><strong>自 Kafka 2.4 版本开始</strong>，社区可以通过配置参数，允许 Follower 副本有限度地提供读服务。</li>
<li>之前确保一致性的主要手段是高水位机制， 但高水位值无法保证 Leader 连续变更场景下的数据一致性，因此，社区引入了 <strong>Leader Epoch</strong> 机制，来修复高水位值的弊端。</li>
</ul>
<h4 id="为什么不支持读写分离"><a href="#为什么不支持读写分离" class="headerlink" title="为什么不支持读写分离?"></a>为什么不支持读写分离?</h4><ul>
<li><p><strong>自 Kafka 2.4 之后</strong>，Kafka 提供了有限度的读写分离。</p>
</li>
<li><p><strong>场景不适用</strong>。读写分离适用于那种读负载很大，而写操作相对不频繁的场景。</p>
</li>
<li><p><strong>同步机制</strong>。Kafka 采用 PULL 方式实现 Follower 的同步，同时复制延迟较大。</p>
</li>
</ul>
<h4 id="如何防止重复消费"><a href="#如何防止重复消费" class="headerlink" title="如何防止重复消费"></a>如何防止重复消费</h4><ul>
<li>代码层面每次消费需提交offset</li>
<li>通过Mysql的<strong>唯一键约束</strong>，结合Redis查看<strong>id是否被消费</strong>，存Redis可以直接使用set方法</li>
<li>量大且允许误判的情况下，使用布隆过滤器也可以</li>
</ul>
<h4 id="如何保证数据不会丢失"><a href="#如何保证数据不会丢失" class="headerlink" title="如何保证数据不会丢失"></a><strong>如何保证数据不会丢失</strong></h4><ul>
<li><strong>生产者</strong>生产消息可以通过comfirm配置<strong>ack&#x3D;all</strong>解决</li>
<li><strong>Broker</strong>同步过程中leader宕机可以通过配置<strong>ISR副本+重试</strong>解决</li>
<li><strong>消费者</strong>丢失可以<strong>关闭自动提交</strong>offset功能，系统处理完成时提交offset</li>
</ul>
<h4 id="如何保证顺序消费"><a href="#如何保证顺序消费" class="headerlink" title="如何保证顺序消费"></a><strong>如何保证顺序消费</strong></h4><ul>
<li>单 topic，单partition，单 consumer，单线程消费，吞吐量低，不推荐</li>
<li><strong>如只需保证单key有序</strong>，为每个key申请单独内存 queue，每个线程分别消费一个内存 queue 即可，这样就能保证单key（例如用户id、活动id）顺序性。</li>
</ul>
<h4 id="【线上】如何解决积压消费"><a href="#【线上】如何解决积压消费" class="headerlink" title="【线上】如何解决积压消费"></a>【线上】如何解决积压消费</h4><ul>
<li><strong>修复consumer</strong>，使其具备消费能力，并且扩容N台</li>
<li>写一个<strong>分发的程序</strong>，将Topic均匀分发到临时Topic中</li>
<li>同时<strong>起N台consumer</strong>，消费不同的<strong>临时Topic</strong></li>
</ul>
<h4 id="如何避免消息积压"><a href="#如何避免消息积压" class="headerlink" title="如何避免消息积压"></a>如何避免消息积压</h4><ul>
<li>提高消费并行度</li>
<li>批量消费</li>
<li>减少组件IO的交互次数</li>
<li>优先级消费</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (maxOffset - curOffset &gt; <span class="number">100000</span>) &#123;</span><br><span class="line">  <span class="comment">// TODO 消息堆积情况的优先处理逻辑</span></span><br><span class="line">  <span class="comment">// 未处理的消息可以选择丢弃或者打日志</span></span><br><span class="line">  <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// TODO 正常消费过程</span></span><br><span class="line"><span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br></pre></td></tr></table></figure>



<h4 id="如何设计消息队列"><a href="#如何设计消息队列" class="headerlink" title="如何设计消息队列"></a>如何设计消息队列</h4><p>需要支持快速水平扩容，broker+partition，partition放不同的机器上，增加机器时将数据根据topic做迁移，分布式需要考虑一致性、可用性、分区容错性</p>
<ul>
<li><strong>一致性：</strong>生产者的消息确认、消费者的幂等性、Broker的数据同步</li>
<li><strong>可用性：</strong>数据如何保证不丢不重、数据如何持久化、持久化时如何读写</li>
<li><strong>分区容错：</strong>采用何种选举机制、如何进行多副本同步</li>
<li><strong>海量数据：</strong>如何解决消息积压、海量Topic性能下降</li>
</ul>
<p>性能上，可以借鉴<strong>时间轮、零拷贝、IO多路复用、顺序读写、压缩批处理</strong></p>
<h1 id="七、Spring篇"><a href="#七、Spring篇" class="headerlink" title="七、Spring篇"></a>七、Spring篇</h1><h3 id="设计思想-amp-Beans"><a href="#设计思想-amp-Beans" class="headerlink" title="设计思想&amp;Beans"></a>设计思想&amp;Beans</h3><h4 id="1、IOC-控制反转"><a href="#1、IOC-控制反转" class="headerlink" title="1、IOC 控制反转"></a><strong>1、IOC 控制反转</strong></h4><p>​        IoC（Inverse of Control:控制反转）是⼀种设计思想，就是将原本在程序中⼿动创建对象的控制权，交由Spring框架来管理。 IoC 在其他语⾔中也有应⽤，并⾮ Spring 特有。 </p>
<p>​        IoC 容器是 Spring⽤来实现 IoC 的载体， IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象。将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注⼊。这样可以很⼤程度上简化应⽤的开发，把应⽤从复杂的依赖关系中解放出来。 IoC 容器就像是⼀个⼯⼚⼀样，当我们需要创建⼀个对象的时候，只需要配置好配置⽂件&#x2F;注解即可，完全不⽤考虑对象是如何被创建出来的。</p>
<p><strong>DI 依赖注入</strong></p>
<p>​    DI:（Dependancy Injection：依赖注入)站在容器的角度，将对象创建依赖的其他对象注入到对象中。</p>
<h4 id="2、AOP-动态代理"><a href="#2、AOP-动态代理" class="headerlink" title="2、AOP 动态代理"></a><strong>2、AOP 动态代理</strong></h4><p>​        AOP(Aspect-Oriented Programming:⾯向切⾯编程)能够将那些与业务⽆关，却为业务模块所共同调⽤的逻辑或责任（例如事务处理、⽇志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。</p>
<p>​        Spring AOP就是基于动态代理的，如果要代理的对象，实现了某个接⼝，那么Spring AOP会使⽤JDKProxy，去创建代理对象，⽽对于没有实现接⼝的对象，就⽆法使⽤ JDK Proxy 去进⾏代理了，这时候Spring AOP会使⽤基于asm框架字节流的Cglib动态代理 ，这时候Spring AOP会使⽤ Cglib ⽣成⼀个被代理对象的⼦类来作为代理。</p>
<h4 id="3、Bean生命周期"><a href="#3、Bean生命周期" class="headerlink" title="3、Bean生命周期"></a><strong>3、Bean生命周期</strong></h4><p><strong>单例对象：</strong> singleton                    </p>
<p>总结：单例对象的生命周期和容器相同        </p>
<p><strong>多例对象：</strong> prototype           </p>
<p>出生：使用对象时spring框架为我们创建            </p>
<p>活着：对象只要是在使用过程中就一直活着            </p>
<p>死亡：当对象长时间不用且没有其它对象引用时，由java的垃圾回收机制回收</p>
<img src="https://s0.lgstatic.com/i/image3/M01/89/0C/Cgq2xl6WvHqAdmt4AABGAn2eSiI631.png" alt="img" style="zoom:67%;" />

<p>IOC容器初始化加载Bean流程：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">refresh</span><span class="params">()</span> <span class="keyword">throws</span> BeansException, IllegalStateException &#123; <span class="keyword">synchronized</span> (<span class="built_in">this</span>.startupShutdownMonitor) &#123;</span><br><span class="line">  <span class="comment">// 第一步:刷新前的预处理 </span></span><br><span class="line">  prepareRefresh();</span><br><span class="line">  <span class="comment">//第二步: 获取BeanFactory并注册到 BeanDefitionRegistry</span></span><br><span class="line">  <span class="type">ConfigurableListableBeanFactory</span> <span class="variable">beanFactory</span> <span class="operator">=</span> obtainFreshBeanFactory();</span><br><span class="line">  <span class="comment">// 第三步:加载BeanFactory的预准备工作(BeanFactory进行一些设置，比如context的类加载器等)</span></span><br><span class="line">  prepareBeanFactory(beanFactory);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 第四步:完成BeanFactory准备工作后的前置处理工作 </span></span><br><span class="line">    postProcessBeanFactory(beanFactory);</span><br><span class="line">    <span class="comment">// 第五步:实例化BeanFactoryPostProcessor接口的Bean </span></span><br><span class="line">    invokeBeanFactoryPostProcessors(beanFactory);</span><br><span class="line">    <span class="comment">// 第六步:注册BeanPostProcessor后置处理器，在创建bean的后执行 </span></span><br><span class="line">    registerBeanPostProcessors(beanFactory);</span><br><span class="line">    <span class="comment">// 第七步:初始化MessageSource组件(做国际化功能;消息绑定，消息解析); </span></span><br><span class="line">    initMessageSource();</span><br><span class="line">    <span class="comment">// 第八步:注册初始化事件派发器 </span></span><br><span class="line">    initApplicationEventMulticaster();</span><br><span class="line">    <span class="comment">// 第九步:子类重写这个方法，在容器刷新的时候可以自定义逻辑 </span></span><br><span class="line">    onRefresh();</span><br><span class="line">    <span class="comment">// 第十步:注册应用的监听器。就是注册实现了ApplicationListener接口的监听器</span></span><br><span class="line">    registerListeners();</span><br><span class="line">    <span class="comment">//第十一步:初始化所有剩下的非懒加载的单例bean 初始化创建非懒加载方式的单例Bean实例(未设置属性)</span></span><br><span class="line">    finishBeanFactoryInitialization(beanFactory);</span><br><span class="line">    <span class="comment">//第十二步: 完成context的刷新。主要是调用LifecycleProcessor的onRefresh()方法，完成创建</span></span><br><span class="line">    finishRefresh();</span><br><span class="line">	&#125;</span><br><span class="line">  ……</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<p>总结：</p>
<p><strong>四个阶段</strong></p>
<ul>
<li>实例化 Instantiation</li>
<li>属性赋值 Populate</li>
<li>初始化 Initialization</li>
<li>销毁 Destruction</li>
</ul>
<p><strong>多个扩展点</strong></p>
<ul>
<li>影响多个Bean<ul>
<li>BeanPostProcessor</li>
<li>InstantiationAwareBeanPostProcessor</li>
</ul>
</li>
<li>影响单个Bean<ul>
<li>Aware</li>
</ul>
</li>
</ul>
<p><strong>完整流程</strong>  </p>
<ol>
<li>实例化一个Bean－－也就是我们常说的<strong>new</strong>；</li>
<li>按照Spring上下文对实例化的Bean进行配置－－<strong>也就是IOC注入</strong>；</li>
<li>如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String)方法，也就是根据就是Spring配置文件中<strong>Bean的id和name进行传递</strong></li>
<li>如果这个Bean已经实现了BeanFactoryAware接口，会调用它实现setBeanFactory(BeanFactory)也就是Spring配置文件配置的<strong>Spring工厂自身进行传递</strong>；</li>
<li>如果这个Bean已经实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，和4传递的信息一样但是因为ApplicationContext是BeanFactory的子接口，所以<strong>更加灵活</strong></li>
<li>如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessBeforeInitialization()方法，BeanPostProcessor经常被用作是Bean内容的更改，由于这个是在Bean初始化结束时调用那个的方法，也可以被应用于<strong>内存或缓存技</strong>术</li>
<li>如果Bean在Spring配置文件中配置了init-method属性会自动调用其配置的初始化方法。</li>
<li>如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessAfterInitialization()，<strong>打印日志或者三级缓存技术里面的bean升级</strong></li>
<li>以上工作完成以后就可以应用这个Bean了，那这个Bean是一个Singleton的，所以一般情况下我们调用同一个id的Bean会是在内容地址相同的实例，当然在Spring配置文件中也可以配置非Singleton，这里我们不做赘述。</li>
<li>当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，或者根据spring配置的destroy-method属性，调用实现的destroy()方法</li>
</ol>
<h4 id="4、Bean作用域"><a href="#4、Bean作用域" class="headerlink" title="4、Bean作用域"></a><strong>4</strong>、Bean作用域</h4><table>
<thead>
<tr>
<th>名称</th>
<th>作用域</th>
</tr>
</thead>
<tbody><tr>
<td><strong>singleton</strong></td>
<td><strong>单例对象，默认值的作用域</strong></td>
</tr>
<tr>
<td><strong>prototype</strong></td>
<td><strong>每次获取都会创建⼀个新的 bean 实例</strong></td>
</tr>
<tr>
<td>request</td>
<td>每⼀次HTTP请求都会产⽣⼀个新的bean，该bean仅在当前HTTP request内有效。</td>
</tr>
<tr>
<td>session</td>
<td>在一次 HTTP session 中，容器将返回同一个实例</td>
</tr>
<tr>
<td>global-session</td>
<td>将对象存入到web项目集群的session域中,若不存在集群,则global session相当于session</td>
</tr>
</tbody></table>
<p>默认作用域是singleton，多个线程访问同一个bean时会存在线程不安全问题</p>
<p><strong>保障线程安全方法：</strong></p>
<ol>
<li><p>在Bean对象中尽量避免定义可变的成员变量（不太现实）。</p>
</li>
<li><p>在类中定义⼀个ThreadLocal成员变量，将需要的可变成员变量保存在 ThreadLocal 中</p>
</li>
</ol>
<p>  <strong>ThreadLocal</strong>：</p>
<p>  ​        每个线程中都有一个自己的ThreadLocalMap类对象，可以将线程自己的对象保持到其中，各管各的，线程可以正确的访问到自己的对象。</p>
<p>  ​        将一个共用的ThreadLocal静态实例作为key，将不同对象的引用保存到不同线程的ThreadLocalMap中，然后<strong>在线程执行的各处通过这个静态ThreadLocal实例的get()方法取得自己线程保存的那个对象</strong>，避免了将这个对象作为参数传递的麻烦。</p>
<h4 id="5、循环依赖"><a href="#5、循环依赖" class="headerlink" title="5、循环依赖"></a>5、循环依赖</h4><p>​    循环依赖其实就是循环引用，也就是两个或者两个以上的 Bean 互相持有对方，最终形成闭环。比如A 依赖于B，B又依赖于A</p>
<p>Spring中循环依赖场景有: </p>
<ul>
<li><p>prototype 原型 bean循环依赖</p>
</li>
<li><p>构造器的循环依赖（构造器注入）</p>
</li>
<li><p>Field 属性的循环依赖（set注入）</p>
<p>其中，构造器的循环依赖问题无法解决，在解决属性循环依赖时，可以使用懒加载，spring采用的是提前暴露对象的方法。</p>
</li>
</ul>
<p><strong>懒加载@Lazy解决循环依赖问题</strong></p>
<p>​    Spring 启动的时候会把所有bean信息(包括XML和注解)解析转化成Spring能够识别的BeanDefinition并存到Hashmap里供下面的初始化时用，然后对每个 BeanDefinition 进行处理。普通 Bean 的初始化是在容器启动初始化阶段执行的，而被lazy-init&#x3D;true修饰的 bean 则是在从容器里第一次进行<strong>context.getBean() 时进行触发</strong>。</p>
<p><strong>三级缓存解决循环依赖问题</strong></p>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1glv7ivru2lj31980qcn13.jpg" alt="循环依赖问题" style="zoom: 33%;" />

<ol>
<li><p>Spring容器初始化ClassA通过构造器初始化对象后提前暴露到Spring容器中的singletonFactorys（三级缓存中）。</p>
</li>
<li><p>ClassA调用setClassB方法，Spring首先尝试从容器中获取ClassB，此时ClassB不存在Spring 容器中。</p>
</li>
<li><p>Spring容器初始化ClassB，ClasssB首先将自己暴露在三级缓存中，然后从Spring容器一级、二级、三级缓存中一次中获取ClassA 。</p>
</li>
<li><p>获取到ClassA后将自己实例化放入单例池中，实例 ClassA通过Spring容器获取到ClassB，完成了自己对象初始化操作。</p>
</li>
<li><p>这样ClassA和ClassB都完成了对象初始化操作，从而解决了循环依赖问题。</p>
</li>
</ol>
<div style="page-break-after: always;"></div>

<h3 id="Spring注解"><a href="#Spring注解" class="headerlink" title="Spring注解"></a>Spring注解</h3><h4 id="1、-SpringBoot"><a href="#1、-SpringBoot" class="headerlink" title="1、@SpringBoot"></a>1、@SpringBoot</h4><p>​    <strong>声明bean的注解</strong></p>
<p>​    <strong>@Component</strong> 通⽤的注解，可标注任意类为  Spring 组件</p>
<p>​    <strong>@Service</strong> 在业务逻辑层使用（service层）</p>
<p>​    <strong>@Repository</strong> 在数据访问层使用（dao层）</p>
<p>​    <strong>@Controller</strong> 在展现层使用，控制器的声明（controller层）</p>
<p>​    <strong>注入bean的注解</strong></p>
<p>​    <strong>@Autowired</strong>：默认按照类型来装配注入，**@Qualifier**：可以改成名称</p>
<p>​    <strong>@Resource</strong>：默认按照名称来装配注入，JDK的注解，新版本已经弃用</p>
<p><strong>@Autowired注解原理</strong> </p>
<p>​         @Autowired的使用简化了我们的开发，</p>
<p>​                实现 AutowiredAnnotationBeanPostProcessor 类，该类实现了 Spring 框架的一些扩展接口。<br>​                实现 BeanFactoryAware 接口使其内部持有了 BeanFactory（可轻松的获取需要依赖的的 Bean）。<br>​                实现 MergedBeanDefinitionPostProcessor 接口，实例化Bean 前获取到 里面的 @Autowired 信息并缓存下来；<br>​                实现 postProcessPropertyValues 接口， 实例化Bean 后从缓存取出注解信息，通过反射将依赖对象设置到 Bean 属性里面。</p>
<p><strong>@SpringBootApplication</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JpaApplication</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        SpringApplication.run(JpaApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>@SpringBootApplication</strong>注解等同于下面三个注解：</p>
<ul>
<li><strong>@SpringBootConfiguration：</strong> 底层是<strong>Configuration</strong>注解，说白了就是支持<strong>JavaConfig</strong>的方式来进行配置</li>
<li><strong>@EnableAutoConfiguration：</strong>开启<strong>自动配置</strong>功能</li>
<li><strong>@ComponentScan：</strong>就是<strong>扫描</strong>注解，默认是扫描<strong>当前类下</strong>的package</li>
</ul>
<p>其中<code>@EnableAutoConfiguration</code>是关键(启用自动配置)，内部实际上就去加载<code>META-INF/spring.factories</code>文件的信息，然后筛选出以<code>EnableAutoConfiguration</code>为key的数据，加载到IOC容器中，实现自动配置功能！</p>
<p>它主要加载了@SpringBootApplication注解主配置类，这个@SpringBootApplication注解主配置类里边最主要的功能就是SpringBoot开启了一个@EnableAutoConfiguration注解的自动配置功能。</p>
<p> <strong>@EnableAutoConfiguration作用：</strong></p>
<p>它主要利用了一个</p>
<p>EnableAutoConfigurationImportSelector选择器给Spring容器中来导入一些组件。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Import(EnableAutoConfigurationImportSelector.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> EnableAutoConfiguration </span><br></pre></td></tr></table></figure>





<h4 id="2、-SpringMVC"><a href="#2、-SpringMVC" class="headerlink" title="2、@SpringMVC"></a><strong>2、@SpringMVC</strong></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Controller</span> 声明该类为SpringMVC中的Controller</span><br><span class="line"><span class="meta">@RequestMapping</span> 用于映射Web请求</span><br><span class="line"><span class="meta">@ResponseBody</span> 支持将返回值放在response内，而不是一个页面，通常用户返回json数据</span><br><span class="line"><span class="meta">@RequestBody</span> 允许request的参数在request体中，而不是在直接连接在地址后面。</span><br><span class="line"><span class="meta">@PathVariable</span> 用于接收路径参数</span><br><span class="line"><span class="meta">@RequestMapping(&quot;/hello/&#123;name&#125;&quot;)</span>申明的路径，将注解放在参数中前，即可获取该值，通常作为Restful的接口实现方法。</span><br></pre></td></tr></table></figure>

<p><strong>SpringMVC原理</strong> </p>
<img src="https://img-blog.csdn.net/20181022224058617?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2F3YWtlX2xxaA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" style="zoom: 50%;" />

<ol>
<li>客户端（浏览器）发送请求，直接请求到  DispatcherServlet 。</li>
<li>DispatcherServlet 根据请求信息调⽤  HandlerMapping ，解析请求对应的  Handler 。</li>
<li>解析到对应的  Handler （也就是  Controller 控制器）后，开始由HandlerAdapter 适配器处理。</li>
<li>HandlerAdapter 会根据  Handler 来调⽤真正的处理器开处理请求，并处理相应的业务逻辑。</li>
<li>处理器处理完业务后，会返回⼀个  ModelAndView 对象， Model 是返回的数据对象</li>
<li>ViewResolver 会根据逻辑  View 查找实际的  View 。</li>
<li>DispaterServlet 把返回的  Model 传给  View （视图渲染）。</li>
<li>把  View 返回给请求者（浏览器）</li>
</ol>
<h4 id="3、-SpringMybatis"><a href="#3、-SpringMybatis" class="headerlink" title="3、@SpringMybatis"></a>3、@SpringMybatis</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Insert</span> ： 插入sql ,和xml insert sql语法完全一样</span><br><span class="line"><span class="meta">@Select</span> ： 查询sql, 和xml select sql语法完全一样</span><br><span class="line"><span class="meta">@Update</span> ： 更新sql, 和xml update sql语法完全一样</span><br><span class="line"><span class="meta">@Delete</span> ： 删除sql, 和xml delete sql语法完全一样</span><br><span class="line"><span class="meta">@Param</span> ： 入参</span><br><span class="line"><span class="meta">@Results</span> ： 设置结果集合<span class="meta">@Result</span> ： 结果</span><br><span class="line"><span class="meta">@ResultMap</span> ： 引用结果集合</span><br><span class="line"><span class="meta">@SelectKey</span> ： 获取最新插入id </span><br></pre></td></tr></table></figure>

<p><strong>mybatis如何防止sql注入？</strong></p>
<p>​    简单的说就是#{}是经过预编译的，是安全的，**$<strong>{}是未经过预编译的，仅仅是取变量的值，是非安全的，存在SQL注入。在编写mybatis的映射语句时，尽量采用</strong>“#{xxx}”<strong>这样的格式。如果需要实现动态传入表名、列名，还需要做如下修改：添加属性</strong>statementType&#x3D;”STATEMENT”<strong>，同时sql里的属有变量取值都改成</strong>${xxxx}**</p>
<p><strong>Mybatis和Hibernate的区别</strong> </p>
<p><strong>Hibernate 框架：</strong> </p>
<p>​    <strong>Hibernate</strong>是一个开放源代码的对象关系映射框架,它对JDBC进行了非常轻量级的对象封装,建立对象与数据库表的映射。是一个全自动的、完全面向对象的持久层框架。</p>
<p><strong>Mybatis框架：</strong></p>
<p>​    <strong>Mybatis</strong>是一个开源对象关系映射框架，原名：ibatis,2010年由谷歌接管以后更名。是一个半自动化的持久层框架。</p>
<p><strong>区别：</strong></p>
<p>  <strong>开发方面</strong></p>
<p>​    在项目开发过程当中，就速度而言：</p>
<p>​      hibernate开发中，sql语句已经被封装，直接可以使用，加快系统开发；</p>
<p>​      Mybatis 属于半自动化，sql需要手工完成，稍微繁琐；</p>
<p>​    但是，凡事都不是绝对的，如果对于庞大复杂的系统项目来说，复杂语句较多，hibernate 就不是好方案。</p>
<p>  <strong>sql优化方面</strong></p>
<p>​    Hibernate 自动生成sql,有些语句较为繁琐，会多消耗一些性能；</p>
<p>​    Mybatis 手动编写sql，可以避免不需要的查询，提高系统性能；</p>
<p>  <strong>对象管理比对</strong></p>
<p>​    Hibernate 是完整的对象-关系映射的框架，开发工程中，无需过多关注底层实现，只要去管理对象即可；</p>
<p>​    Mybatis 需要自行管理映射关系；</p>
<h4 id="4、-Transactional"><a href="#4、-Transactional" class="headerlink" title="4、@Transactional"></a>4、@Transactional</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@EnableTransactionManagement</span> </span><br><span class="line"><span class="meta">@Transactional</span></span><br></pre></td></tr></table></figure>

<p>注意事项：</p>
<p>​    ①事务函数中不要处理耗时任务，会导致长期占有数据库连接。</p>
<p>​    ②事务函数中不要处理无关业务，防止产生异常导致事务回滚。</p>
<p><strong>事务传播属性</strong></p>
<p><strong>1) REQUIRED（默认属性）</strong> 如果存在一个事务，则支持当前事务。如果没有事务则开启一个新的事务。 </p>
<ol start="2">
<li><p>MANDATORY  支持当前事务，如果当前没有事务，就抛出异常。 </p>
</li>
<li><p>NEVER  以非事务方式执行，如果当前存在事务，则抛出异常。 </p>
</li>
<li><p>NOT_SUPPORTED  以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 </p>
</li>
<li><p>REQUIRES_NEW  新建事务，如果当前存在事务，把当前事务挂起。 </p>
</li>
<li><p>SUPPORTS  支持当前事务，如果当前没有事务，就以非事务方式执行。</p>
</li>
</ol>
<p><strong>7) NESTED</strong> （<strong>局部回滚</strong>） 支持当前事务，新增Savepoint点，与当前事务同步提交或回滚。 <strong>嵌套事务一个非常重要的概念就是内层事务依赖于外层事务。外层事务失败时，会回滚内层事务所做的动作。而内层事务操作失败并不会引起外层事务的回滚。</strong></p>
<div style="page-break-after: always;"></div>

<h3 id="Spring源码阅读"><a href="#Spring源码阅读" class="headerlink" title="Spring源码阅读"></a>Spring源码阅读</h3><h4 id="1、Spring中的设计模式"><a href="#1、Spring中的设计模式" class="headerlink" title="1、Spring中的设计模式"></a><strong>1、Spring中的设计模式</strong></h4><p>参考：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485303&idx=1&sn=9e4626a1e3f001f9b0d84a6fa0cff04a&chksm=cea248bcf9d5c1aaf48b67cc52bac74eb29d6037848d6cf213b0e5466f2d1fda970db700ba41&token=255050878&lang=zh_CN%23rd">spring中的设计模式</a></p>
<p><strong>单例设计模式 :</strong> Spring 中的 Bean 默认都是单例的。</p>
<p><strong>⼯⼚设计模式 :</strong> Spring使⽤⼯⼚模式通过  BeanFactory 、 ApplicationContext 创建bean 对象。</p>
<p><strong>代理设计模式 :</strong> Spring AOP 功能的实现。</p>
<p><strong>观察者模式：</strong> Spring 事件驱动模型就是观察者模式很经典的⼀个应⽤。</p>
<p><strong>适配器模式：</strong>Spring AOP 的增强或通知(Advice)使⽤到了适配器模式、spring MVC 中也是⽤到了适配器模式适配 Controller 。</p>
<h1 id="八、SpringCloud篇"><a href="#八、SpringCloud篇" class="headerlink" title="八、SpringCloud篇"></a>八、SpringCloud篇</h1><h4 id="Why-SpringCloud"><a href="#Why-SpringCloud" class="headerlink" title="Why SpringCloud"></a>Why SpringCloud</h4><blockquote>
<p>​    Spring cloud 是一系列框架的有序集合。它利用 spring boot 的开发便利性巧妙地简化了分布式系统基础设施的开发，如<strong>服务发现注册</strong>、<strong>配置中心</strong>、<strong>消息总线</strong>、<strong>负载均衡</strong>、<strong>断路器</strong>、<strong>数据监控</strong>等，都可以用 spring boot 的开发风格做到一键启动和部署。</p>
</blockquote>
<table>
<thead>
<tr>
<th>SpringCloud（微服务解决方案）</th>
<th>Dubbo（分布式服务治理框架）</th>
</tr>
</thead>
<tbody><tr>
<td>Rest API （轻量、灵活、swagger）</td>
<td>RPC远程调用（高效、耦合）</td>
</tr>
<tr>
<td>Eureka、Nacos</td>
<td>Zookeeper</td>
</tr>
<tr>
<td>使用方便</td>
<td>性能好</td>
</tr>
<tr>
<td>即将推出SpringCloud2.0</td>
<td>断档5年后17年重启</td>
</tr>
</tbody></table>
<p>​    SpringBoot是Spring推出用于解决传统框架配置文件冗余,装配组件繁杂的基于Maven的解决方案,<strong>旨在快速搭建单个微服务</strong>，SpringCloud是依赖于SpringBoot的,而SpringBoot并不是依赖与SpringCloud,甚至还可以和Dubbo进行优秀的整合开发</p>
<p>​    MartinFlower 提出的微服务之间是通过RestFulApi进行通信，具体实现</p>
<ul>
<li>RestTemplate：基于HTTP协议</li>
<li>Feign：封装了ribbon和Hystrix 、RestTemplate 简化了客户端开发工作量</li>
<li>RPC：基于TCP协议，序列化和传输效率提升明显</li>
<li>MQ：异步解耦微服务之间的调用</li>
</ul>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmawejgpgwj30ht0bnt9d.jpg" alt="img" style="zoom:67%;" />

<h4 id="Spring-Boot"><a href="#Spring-Boot" class="headerlink" title="Spring Boot"></a>Spring Boot</h4><blockquote>
<p>Spring Boot 通过<strong>简单的步骤</strong>就可以创建一个 Spring 应用。</p>
<p>Spring Boot 为 Spring 整合第三方框架提供了<strong>开箱即用功能</strong>。</p>
<p>Spring Boot 的核心思想是<strong>约定大于配置</strong>。</p>
</blockquote>
<p><strong>Spring Boot 解决的问题</strong></p>
<ul>
<li><p>搭建后端框架时需要手动添加 Maven 配置，涉及很多 XML 配置文件，增加了搭建难度和时间成本。</p>
</li>
<li><p>将项目编译成 war 包，部署到 Tomcat 中，项目部署依赖 Tomcat，这样非常不方便。</p>
</li>
<li><p>应用监控做的比较简单，通常都是通过一个没有任何逻辑的接口来判断应用的存活状态。</p>
</li>
</ul>
<p><strong>Spring Boot 优点</strong></p>
<p><strong>自动装配：</strong>Spring Boot 会根据某些规则对所有配置的 Bean 进行初始化。可以减少了很多重复性的工作。</p>
<p>​    比如使用 MongoDB 时，只需加入 MongoDB 的 Starter 包，然后配置  的连接信息，就可以直接使用 MongoTemplate 自动装配来操作数据库了。简化了 Maven Jar 包的依赖，降低了烦琐配置的出错几率。</p>
<p><strong>内嵌容器：</strong>Spring Boot 应用程序可以不用部署到外部容器中，比如 Tomcat。</p>
<p>​    应用程序可以直接通过 Maven 命令编译成可执行的 jar 包，通过 java-jar 命令启动即可，非常方便。</p>
<p><strong>应用监控：</strong>Spring Boot 中自带监控功能 Actuator，可以实现对程序内部运行情况进行监控，</p>
<p>​    比如 Bean 加载情况、环境变量、日志信息、线程信息等。当然也可以自定义跟业务相关的监控，通过Actuator 的端点信息进行暴露。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spring-boot-starter-web          <span class="comment">//用于快速构建基于 Spring MVC 的 Web 项目。</span></span><br><span class="line">spring-boot-starter-data-redis   <span class="comment">//用于快速整合并操作 Redis。</span></span><br><span class="line">spring-boot-starter-data-mongodb <span class="comment">//用于对 MongoDB 的集成。</span></span><br><span class="line">spring-boot-starter-data-jpa     <span class="comment">//用于操作 MySQL。</span></span><br></pre></td></tr></table></figure>

<p><strong>自定义一个Starter</strong></p>
<ol>
<li><p>创建 Starter 项目，定义 Starter 需要的配置（Properties）类，比如数据库的连接信息；</p>
</li>
<li><p>编写自动配置类，自动配置类就是获取配置，根据配置来自动装配 Bean；</p>
</li>
<li><p>编写 spring.factories 文件加载自动配置类，Spring 启动的时候会扫描 spring.factories 文件，；</p>
</li>
<li><p>编写配置提示文件 spring-configuration-metadata.json（不是必须的），在添加配置的时候，我们想要知道具体的配置项是什么作用，可以通过编写提示文件来提示；</p>
</li>
<li><p>在项目中引入自定义 Starter 的 Maven 依赖，增加配置值后即可使用。</p>
</li>
</ol>
<p><strong>Spring Boot Admin</strong>（将 actuator 提供的数据进行可视化）</p>
<ul>
<li><p>显示应用程序的监控状态、查看 JVM 和线程信息</p>
</li>
<li><p>应用程序上下线监控  </p>
</li>
<li><p>可视化的查看日志、动态切换日志级别</p>
</li>
<li><p>HTTP 请求信息跟踪等实用功能</p>
</li>
</ul>
<h4 id="GateWay-x2F-Zuul"><a href="#GateWay-x2F-Zuul" class="headerlink" title="GateWay &#x2F; Zuul"></a>GateWay &#x2F; Zuul</h4><blockquote>
<p>GateWay⽬标是取代Netflflix Zuul，它基于Spring5.0+SpringBoot2.0+WebFlux等技术开发，提供<strong>统⼀的路由</strong>⽅式（反向代理）并且基于 <strong>Filter</strong>(定义过滤器对请求过滤，完成⼀些功能) 链的⽅式提供了⽹关基本的功能，例如：鉴权、流量控制、熔断、路径重写、⽇志监控。</p>
</blockquote>
<p><strong>组成：</strong></p>
<ul>
<li><p><strong>路由route：</strong> ⽹关最基础的⼯作单元。路由由⼀个ID、⼀个⽬标URL、⼀系列的断⾔（匹配条件判断）和Filter过滤器组成。如果断⾔为true，则匹配该路由。</p>
</li>
<li><p><strong>断⾔predicates：</strong>参考了Java8中的断⾔Predicate，匹配Http请求中的所有内容（类似于nginx中的location匹配⼀样），如果断⾔与请求相匹配则路由。</p>
</li>
<li><p><strong>过滤器filter：</strong>标准的Spring webFilter，使⽤过滤器在请求之前或者之后执⾏业务逻辑。</p>
<p>请求前<code>pre</code>类型过滤器：做<strong>参数校验</strong>、<strong>权限校验</strong>、<strong>流量监控</strong>、<strong>⽇志输出</strong>、<strong>协议转换</strong>等，</p>
<p>请求前<code>post</code>类型的过滤器：做<strong>响应内容</strong>、<strong>响应头</strong>的修改、<strong>⽇志的输出</strong>、<strong>流量监控</strong>等。</p>
</li>
</ul>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmc49l9babj31do0n7n13.jpg" alt="image-20210105001419761" style="zoom: 50%;" />

<p><strong>GateWayFilter</strong> 应⽤到单个路由路由上 、<strong>GlobalFilter</strong> 应⽤到所有的路由上</p>
<h4 id="Eureka-x2F-Zookeeper"><a href="#Eureka-x2F-Zookeeper" class="headerlink" title="Eureka &#x2F; Zookeeper"></a>Eureka &#x2F; Zookeeper</h4><blockquote>
<p>服务注册中⼼本质上是为了解耦服务提供者和服务消费者，为了⽀持弹性扩缩容特性，⼀个微服务的提供者的数量和分布往往是动态变化的。</p>
</blockquote>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmawwm3k7bj30o80ecq3u.jpg" alt="image-20210103231405882" style="zoom: 50%;" />

<table>
<thead>
<tr>
<th>区别</th>
<th>Zookeeper</th>
<th>Eureka</th>
<th>Nacos</th>
</tr>
</thead>
<tbody><tr>
<td>CAP</td>
<td>CP</td>
<td>AP</td>
<td>CP&#x2F;AP切换</td>
</tr>
<tr>
<td>可用性</td>
<td>选举期间不可用</td>
<td>自我保护机制，数据不是最新的</td>
<td></td>
</tr>
<tr>
<td>组成</td>
<td>Leader和Follower</td>
<td>节点平等</td>
<td></td>
</tr>
<tr>
<td>优势</td>
<td>分布式协调</td>
<td>注册与发现</td>
<td>注册中心和配置中心</td>
</tr>
<tr>
<td>底层</td>
<td>进程</td>
<td>服务</td>
<td>Jar包</td>
</tr>
</tbody></table>
<p><strong>Eureka</strong>通过<strong>⼼跳检测</strong>、<strong>健康检查</strong>和<strong>客户端缓存</strong>等机制，提⾼系统的灵活性、可伸缩性和可⽤性。</p>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmaxc493qyj30ji0a6mxx.jpg" alt="image-20210103232900353" style="zoom:67%;" />

<ol>
<li>us-east-1c、us-east-1d，us-east-1e代表不同的机房，<strong>每⼀个Eureka Server都是⼀个集群</strong>。</li>
<li>Service作为服务提供者向Eureka中注册服务，Eureka接受到注册事件会在<strong>集群和分区中进⾏数据同步</strong>，Client作为消费端（服务消费者）可以从Eureka中获取到服务注册信息，进⾏服务调⽤。</li>
<li>微服务启动后，会周期性地向Eureka<strong>发送⼼跳</strong>（默认周期为30秒）以续约⾃⼰的信息</li>
<li>Eureka在⼀定时间内<strong>（默认90秒）没有接收</strong>到某个微服务节点的⼼跳，Eureka将会注销该微服务节点</li>
<li>Eureka Client<strong>会缓存Eureka Server中的信息</strong>。即使所有的Eureka Server节点都宕掉，服务消费者依然可以使⽤缓存中的信息找到服务提供者</li>
</ol>
<p><strong>Eureka缓存</strong></p>
<blockquote>
<p>新服务上线后，服务消费者<strong>不能立即访问</strong>到刚上线的新服务，需要过⼀段时间后才能访问？或是将服务下线后，服务还是会被调⽤到，⼀段时候后<strong>才彻底停⽌服务</strong>，访问前期会导致频繁报错！</p>
</blockquote>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmaxmk97q0j30vw0j6gmu.jpg" alt="image-20210103233902439" style="zoom:50%;" />

<p>​    服务注册到注册中⼼后，服务实例信息是<strong>存储在Registry表</strong>中的，也就是内存中。但Eureka为了提⾼响应速度，在内部做了优化，加⼊了两层的缓存结构，将Client需要的实例信息，直接缓存起来，获取的时候直接从缓存中拿数据然后响应给 Client。 </p>
<ul>
<li><p>第⼀层缓存是<strong>readOnlyCacheMap</strong>，采⽤<strong>ConcurrentHashMap</strong>来存储数据的，主要负责定时与readWriteCacheMap进⾏数据同步，默认同步时间为 <strong>30</strong> 秒⼀次。</p>
</li>
<li><p>第⼆层缓存是<strong>readWriteCacheMap</strong>，采⽤<strong>Guava</strong>来实现缓存。缓存过期时间默认为<strong>180</strong>秒，当服务<strong>下线、过期、注册、状态变更</strong>等操作都会清除此缓存中的数据。</p>
</li>
<li><p>如果两级缓存都无法查询，会<strong>触发缓存的加载</strong>，从存储层拉取数据到缓存中，然后再返回给 Client。</p>
<p>Eureka之所以设计⼆级缓存机制，也是为了<strong>提⾼ Eureka Server 的响应速度</strong>，缺点是缓存会导致 Client<strong>获取不到最新的服务实例信息</strong>，然后导致⽆法快速发现新的服务和已下线的服务。</p>
</li>
</ul>
<p><strong>解决方案</strong></p>
<ul>
<li>我们可以<strong>缩短读缓存的更新时间</strong>让服务发现变得更加及时，或者<strong>直接将只读缓存关闭</strong>，同时可以缩短客户端如ribbon服务的定时刷新间隔，多级缓存也导致C层⾯（数据⼀致性）很薄弱。</li>
<li>Eureka Server 中会有<strong>定时任务去检测失效</strong>的服务，将服务实例信息从注册表中移除，也可以将这个失效检测的<strong>时间缩短</strong>，这样服务下线后就能够及时从注册表中清除。</li>
</ul>
<p><strong>自我保护机制开启条件</strong></p>
<ul>
<li>期望最小每分钟能够续租的次数（实例* 频率 * 比例&#x3D;&#x3D;10* 2 *0.85）</li>
<li>期望的服务实例数量（10）</li>
</ul>
<p><strong>健康检查</strong></p>
<ul>
<li><p>Eureka Client 会定时发送心跳给 Eureka Server 来证明自己处于健康的状态</p>
</li>
<li><p>集成SBA以后可以把所有健康状态信息一并返回给eureka</p>
</li>
</ul>
<h4 id="Feign-x2F-Ribbon"><a href="#Feign-x2F-Ribbon" class="headerlink" title="Feign &#x2F; Ribbon"></a>Feign &#x2F; Ribbon</h4><ul>
<li>Feign 可以与 Eureka 和 Ribbon 组合使用以支持负载均衡，</li>
<li>Feign 可以与 Hystrix 组合使用，支持熔断回退</li>
<li>Feign 可以与ProtoBuf实现快速的RPC调用</li>
</ul>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmbxsh2rfnj30uo0fgmxz.jpg" alt="img" style="zoom:80%;" />

<ul>
<li><p><strong>InvocationHandlerFactory 代理</strong></p>
<p>采用 JDK 的动态代理方式生成代理对象，当我们调用这个接口，实际上是要去调用远程的 HTTP API</p>
</li>
<li><p><strong>Contract 契约组件</strong></p>
<p>比如请求类型是 GET 还是 POST，请求的 URI 是什么</p>
</li>
<li><p><strong>Encoder 编码组件 \ Decoder 解码组件</strong></p>
<p>通过该组件我们可以将请求信息采用指定的编码方式进行编解码后传输</p>
</li>
<li><p><strong>Logger 日志记录</strong></p>
<p>负责 Feign 中记录日志的，可以指定 Logger 的级别以及自定义日志的输出</p>
</li>
<li><p><strong>Client 请求执行组件</strong></p>
<p>负责 HTTP 请求执行的组件，Feign 中默认的 Client 是通过 JDK 的 HttpURLConnection 来发起请求的，在每次发送请求的时候，都会创建新的 HttpURLConnection 链接，Feign 的性能会很差，可以通过扩展该接口，使用 Apache HttpClient 等基于连接池的高性能 HTTP 客户端。</p>
</li>
<li><p><strong>Retryer 重试组件</strong></p>
<p>负责重试的组件，Feign 内置了重试器，当 HTTP 请求出现 IO 异常时，Feign 会限定一个最大重试次数来进行重试操作。</p>
</li>
<li><p><strong>RequestInterceptor 请求拦截器</strong></p>
<p>可以为 Feign 添加多个拦截器，在请求执行前设置一些扩展的参数信息。</p>
</li>
</ul>
<p><strong>Feign最佳使用技巧</strong></p>
<ul>
<li><p>继承特性</p>
</li>
<li><p>拦截器</p>
<p>比如添加指定的请求头信息，这个可以用在服务间传递某些信息的时候。</p>
</li>
<li><p>GET 请求多参数传递</p>
</li>
<li><p>日志配置</p>
<p>FULL 会输出全部完整的请求信息。</p>
</li>
<li><p>异常解码器</p>
<p>异常解码器中可以获取异常信息，而不是简单的一个code，然后转换成对应的异常对象返回。</p>
</li>
<li><p>源码查看是如何继承Hystrix</p>
<p>HystrixFeign.builder 中可以看到继承了 Feign 的 Builder，增加了 Hystrix的SetterFactory， build 方法里，对 invocationHandlerFactory 进行了重写， create 的时候<strong>返回HystrixInvocationHandler</strong>， 在 invoke 的时候<strong>会将请求包装成 HystrixCommand</strong> 去执行，这里就自然的集成了 Hystrix</p>
</li>
</ul>
<p><strong>Ribbon</strong></p>
<img src="http://s0.lgstatic.com/i/image2/M01/93/96/CgotOV2Nux-AO2PcAAEcl4M1Zi4629.png" alt="img" style="zoom: 50%;" />



<p><strong>使用方式</strong></p>
<ul>
<li><p><strong>原生 API</strong>，Ribbon 是 Netflix 开源的，没有使用 Spring Cloud，需要使用 Ribbon 的原生 API。</p>
</li>
<li><p><strong>Ribbon + RestTemplate</strong>，整合Spring Cloud 后，可以基于 RestTemplate 提供负载均衡的服务</p>
</li>
<li><p><strong>Ribbon + Feign</strong></p>
<img src="http://s0.lgstatic.com/i/image2/M01/93/76/CgoB5l2NuyCALoefAAAdV1DlSHY088.png" alt="img" style="zoom: 67%;" /></li>
</ul>
<p><strong>负载均衡算法</strong></p>
<ul>
<li><p>RoundRobinRule 是<strong>轮询的算法</strong>，A和B轮流选择。</p>
</li>
<li><p>RandomRule 是<strong>随机算法</strong>，这个就比较简单了，在服务列表中随机选取。</p>
</li>
<li><p>BestAvailableRule 选择一个最<strong>小的并发请求 server</strong></p>
</li>
</ul>
<p><strong>自定义负载均衡算法</strong></p>
<ul>
<li>实现 Irule 接口</li>
<li>继承 AbstractLoadBalancerRule 类</li>
</ul>
<p><strong>自定义负载均衡使用场景</strong>（核心）</p>
<ul>
<li><p><strong>灰度发布</strong></p>
<p>灰度发布是能够平滑过渡的一种发布方式，在发布过程中，先发布一部分应用，让指定的用户使用刚发布的应用，等到测试没有问题后，再将其他的全部应用发布。如果新发布的有问题，只需要将这部分恢复即可，不用恢复所有的应用。</p>
</li>
<li><p><strong>多版本隔离</strong></p>
<p>多版本隔离跟灰度发布类似，为了兼容或者过度，某些应用会有多个版本，这个时候如何保证 1.0 版本的客户端不会调用到 1.1 版本的服务，就是我们需要考虑的问题。</p>
</li>
<li><p><strong>故障隔离</strong></p>
<p>当线上某个实例发生故障后，为了不影响用户，我们一般都会先留存证据，比如：线程信息、JVM 信息等，然后将这个实例重启或直接停止。然后线下根据一些信息分析故障原因，如果我能做到故障隔离，就可以直接将出问题的实例隔离，不让正常的用户请求访问到这个出问题的实例，只让指定的用户访问，这样就可以单独用特定的用户来对这个出问题的实例进行测试、故障分析等。</p>
</li>
</ul>
<h4 id="Hystrix-x2F-Sentinel"><a href="#Hystrix-x2F-Sentinel" class="headerlink" title="Hystrix &#x2F; Sentinel"></a>Hystrix &#x2F; Sentinel</h4><p><strong>服务雪崩场景</strong></p>
<p>自己即是服务消费者，同时也是服务提供者，同步调用等待结果导致资源耗尽</p>
<p><strong>解决方案</strong></p>
<p>服务方：扩容、限流，排查代码问题，增加硬件监控</p>
<p>消费方：使用Hystrix资源隔离，熔断降级，快速失败</p>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmby7y9ykzj30wr0ehac5.jpg" alt="img" style="zoom:150%;" />

<p><strong>Hystrix断路保护器的作用</strong></p>
<ul>
<li><strong>封装请求</strong>会将用户的操作进行统一封装，统一封装的目的在于进行统一控制。</li>
<li><strong>资源隔离限流</strong>会将对应的资源按照指定的类型进行隔离，比如<strong>线程池</strong>和<strong>信号量</strong>。<ul>
<li>计数器限流，例如5秒内技术1000请求，超数后限流，未超数重新计数</li>
<li>滑动窗口限流，解决计数器不够精确的问题，把一个窗口拆分多滚动窗口</li>
<li>令牌桶限流，类似景区售票，售票的速度是固定的，拿到令牌才能去处理请求</li>
<li>漏桶限流，生产者消费者模型，实现了恒定速度处理请求，能够绝对防止突发流量</li>
</ul>
</li>
<li><strong>失败回退</strong>其实是一个备用的方案，就是说当请求失败后，有没有备用方案来满足这个请求的需求。</li>
<li><strong>断路器</strong>这个是<strong>最核心</strong>的，，如果断路器处于打开的状态，那么所有请求都将失败，执行回退逻辑。如果断路器处于关闭状态，那么请求将会被正常执行。有些场景我们需要手动<strong>打开断路器强制降级</strong>。</li>
<li><strong>指标监控</strong>会对请求的生<strong>命周期进行监控</strong>，请求成功、失败、超时、拒绝等状态，都会被监控起来。</li>
</ul>
<p><strong>Hystrix使用上遇到的坑</strong></p>
<ul>
<li><p>配置可以对接<strong>配置中心</strong>进行动态调整</p>
<p>Hystrix 的配置项非常多，如果不对接配置中心，所有的配置只能在代码里修改，在集群部署的难以应对紧急情况，我们项目只设置一个 CommandKey，其他的都在配置中心进行指定，紧急情况如需隔离部分请求时，只需在配置中心进行修改以后，强制更新即可。</p>
</li>
<li><p>回退逻辑中可以<strong>手动埋点</strong>或者通过<strong>输出日志</strong>进行告警</p>
<p>当请求失败或者超时，会执行回退逻辑，如果有大量的回退，则证明某些服务出问题了，这个时候我们可以在回退的逻辑中进行埋点操作，上报数据给监控系统，也可以输出回退的日志，统一由日志收集的程序去进行处理，这些方式都可以将问题暴露出去，然后通过实时数据分析进行告警操作</p>
</li>
<li><p>用 <strong>ThreadLocal</strong>配合<strong>线程池隔离</strong>模式需当心</p>
<p>当我们用了线程池隔离模式的时候，被隔离的方法会包装成一个 Command 丢入到独立的线程池中进行执行，这个时候就是从 A 线程切换到了 B 线程，ThreadLocal 的数据就会丢失</p>
</li>
<li><p><strong>Gateway中</strong>多用信号量隔离</p>
<p>网关是所有请求的入口，路由的服务数量会很多，几十个到上百个都有可能，如果用线程池隔离，那么需要创建上百个独立的线程池，开销太大，用信号量隔离开销就小很多，还能起到限流的作用。</p>
</li>
</ul>
<p>[^常见问题]: Hystrix的超时时间要⼤于Ribbon的超时时间，因为Hystrix将请求包装了起来，特别需要注意的是，如果Ribbon开启了重试机制，⽐如重试3 次，Ribbon 的超时为 1 秒，那么Hystrix 的超时时间应该⼤于 3 秒，否则就会出现 Ribbon 还在重试中，⽽ Hystrix 已经超时的现象。</p>
<p><strong>Sentinel</strong> </p>
<blockquote>
<p>Sentinel是⼀个⾯向云原⽣微服务的流量控制、熔断降级组件。</p>
<p>替代Hystrix，针对问题：服务雪崩、服务降级、服务熔断、服务限流</p>
</blockquote>
<p>Hystrix区别：</p>
<ul>
<li>独⽴可部署Dashboard（基于 Spring Boot 开发）控制台组件</li>
<li>不依赖任何框架&#x2F;库，减少代码开发，通过UI界⾯配置即可完成细粒度控制</li>
</ul>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmbza4zixbj30kl09sq4p.jpg" alt="image-20210104212151598" style="zoom:80%;" />

<p><strong>丰富的应⽤场景</strong>：Sentinel 承接了阿⾥巴巴近 10 年的双⼗⼀⼤促流量的核⼼场景，例如秒杀、消息削峰填⾕、集群流量控制、实时熔断下游不可⽤应⽤等。</p>
<p><strong>完备的实时监控</strong>：可以看到500 台以下规模的集群的汇总也可以看到单机的秒级数据。</p>
<p><strong>⼴泛的开源⽣态：</strong>与 SpringCloud、Dubbo的整合。您只需要引⼊相应的依赖并进⾏简单的配置即可快速地接⼊ Sentinel。</p>
<p><strong>区别：</strong></p>
<ul>
<li>Sentinel不会像Hystrix那样放过⼀个请求尝试⾃我修复，就是明明确确按照时间窗⼝来，熔断触发后，时间窗⼝内拒绝请求，时间窗⼝后就恢复。</li>
<li>Sentinel Dashboard中添加的规则数据存储在内存，微服务停掉规则数据就消失，在⽣产环境下不合适。可以将Sentinel规则数据持久化到Nacos配置中⼼，让微服务从Nacos获取。</li>
</ul>
<table>
<thead>
<tr>
<th>#</th>
<th>Sentinel</th>
<th>Hystrix</th>
</tr>
</thead>
<tbody><tr>
<td>隔离策略</td>
<td>信号量隔离</td>
<td>线程池隔离&#x2F;信号量隔离</td>
</tr>
<tr>
<td>熔断降级策略</td>
<td>基于响应时间或失败比率</td>
<td>基于失败比率</td>
</tr>
<tr>
<td>实时指标实现</td>
<td>滑动窗口</td>
<td>滑动窗口（基于 RxJava）</td>
</tr>
<tr>
<td>扩展性</td>
<td>多个扩展点</td>
<td>插件的形式</td>
</tr>
<tr>
<td>限流</td>
<td>基于 QPS，支持基于调用关系的限流</td>
<td>不支持</td>
</tr>
<tr>
<td>流量整形</td>
<td>支持慢启动、匀速器模式</td>
<td>不支持</td>
</tr>
<tr>
<td>系统负载保护</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>控制台</td>
<td>开箱即用，可配置规则、查看秒级监控、机器发现等</td>
<td>不完善</td>
</tr>
<tr>
<td>常见框架的适配</td>
<td>Servlet、Spring Cloud、Dubbo、gRPC</td>
<td>Servlet、Spring Cloud Netflix</td>
</tr>
</tbody></table>
<h4 id="Config-x2F-Nacos"><a href="#Config-x2F-Nacos" class="headerlink" title="Config &#x2F; Nacos"></a>Config &#x2F; Nacos</h4><blockquote>
<p>Nacos是阿⾥巴巴开源的⼀个针对微服务架构中<strong>服务发现</strong>、<strong>配置管理</strong>和<strong>服务管理平台</strong>。</p>
<p>Nacos就是<strong>注册中⼼+配置中⼼</strong>的组合（Nacos&#x3D;Eureka+Confifig+Bus）</p>
</blockquote>
<p><strong>Nacos</strong>功能特性</p>
<ul>
<li>服务发现与健康检查</li>
<li>动态配置管理</li>
<li>动态DNS服务</li>
<li>服务和元数据管理</li>
</ul>
<p><strong>保护阈值：</strong></p>
<p>当服务A健康实例数&#x2F;总实例数 &lt; 保护阈值 的时候，说明健康实例真的不多了，这个时候保护阈值会被触发（状态true），nacos将会把该服务所有的实例信息（健康的+不健康的）全部提供给消费者，消费者可能访问到不健康的实例，请求失败，但这样也⽐造成雪崩要好，牺牲了⼀些请求，保证了整个系统的⼀个可⽤。</p>
<p><strong>Nacos</strong> 数据模型（领域模型）</p>
<ul>
<li><strong>Namespace</strong> 代表不同的环境，如开发dev、测试test、⽣产环境prod</li>
<li><strong>Group</strong> 代表某项⽬，⽐如爪哇云项⽬</li>
<li><strong>Service</strong> 某个项⽬中具体xxx服务</li>
<li><strong>DataId</strong> 某个项⽬中具体的xxx配置⽂件</li>
</ul>
<p>可以通过 Spring Cloud 原⽣注解 <code>@RefreshScope</code> 实现配置⾃动更新</p>
<h4 id="Bus-x2F-Stream"><a href="#Bus-x2F-Stream" class="headerlink" title="Bus &#x2F; Stream"></a>Bus &#x2F; Stream</h4><blockquote>
<p>Spring Cloud Stream 消息驱动组件帮助我们更快速，更⽅便的去构建<strong>消息驱动</strong>微服务的</p>
<p>本质：屏蔽掉了底层不同<strong>MQ</strong>消息中间件之间的差异，统⼀了<strong>MQ</strong>的编程模型，降低了学习、开发、维护<strong>MQ</strong>的成本，⽬前⽀持Rabbit、Kafka两种消息</p>
</blockquote>
<h4 id="Sleuth-x2F-Zipkin"><a href="#Sleuth-x2F-Zipkin" class="headerlink" title="Sleuth &#x2F; Zipkin"></a><strong>Sleuth &#x2F; Zipkin</strong></h4><p><strong>全链路追踪</strong></p>
<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmc3avezqrj30xb0lw76z.jpg" alt="image-20210104234058218" style="zoom:67%;" />

<p><strong>Trace ID</strong>：当请求发送到分布式系统的⼊⼝端点时，Sleuth为该请求创建⼀个唯⼀的跟踪标识Trace ID，在分布式系统内部流转的时候，框架始终保持该唯⼀标识，直到返回给请求⽅</p>
<p><strong>Span ID</strong>：为了统计各处理单元的时间延迟，当请求到达各个服务组件时，也是通过⼀个唯⼀标识SpanID来标记它的开始，具体过程以及结束。</p>
<p>Spring Cloud Sleuth （追踪服务框架）可以追踪服务之间的调⽤，Sleuth可以记录⼀个服务请求经过哪些服务、服务处理时⻓等，根据这些，我们能够理清各微服务间的调⽤关系及进⾏问题追踪分析。</p>
<p><strong>耗时分析</strong>：通过 Sleuth 了解采样请求的耗时，分析服务性能问题（哪些服务调⽤⽐较耗时）</p>
<p><strong>链路优化</strong>：发现频繁调⽤的服务，针对性优化等</p>
<p><strong>聚合展示</strong>：数据信息发送给 Zipkin 进⾏聚合，利⽤ Zipkin 存储并展示数据。</p>
<h3 id="安全认证"><a href="#安全认证" class="headerlink" title="安全认证"></a><strong>安全认证</strong></h3><ul>
<li><p>Session</p>
<p>认证中最常用的一种方式，也是最简单的。存在<strong>多节点session丢失</strong>的情况，可通过<strong>nginx粘性Cookie</strong>和Redis集中式Session存储解决</p>
</li>
<li><p>HTTP Basic Authentication </p>
<p>服务端针对请求头中base64加密的Authorization 和用户名和密码进行<strong>校验</strong>。</p>
</li>
<li><p>Token</p>
<p>Session 只是一个 key，<strong>会话信息存储在后端</strong>。而 Token 中会存储用户的信息，然后通过加密算法进行加密，只有服务端才能解密，<strong>服务端拿到 Token 后进行解密获取用户信息</strong>。</p>
</li>
<li><p>JWT认证</p>
</li>
</ul>
<blockquote>
<p>JWT（JSON Web Token）用户提供用户名和密码给认证服务器，服务器验证用户提交信息的合法性；如果验证成功，会产生并返回一个 Token，用户可以使用这个 Token 访问服务器上受保护的资源。</p>
</blockquote>
<img src="http://s0.lgstatic.com/i/image2/M01/AB/87/CgotOV3WUG2ARl98AAD_xcd-ElM857.png" alt="img" style="zoom:70%;" />

<ol>
<li>认证服务提供认证的 API，校验用户信息，返回认证结果</li>
<li>通过JWTUtils中的RSA算法，生成JWT token，token里封装用户id和有效期</li>
<li>服务间参数通过请求头进行传递，服务内部通过 ThreadLocal 进行上下文传递。</li>
<li>Hystrix导致ThreadLocal失效的问题可以通过，重写 Hystrix 的 Callable 方法，传递需要的数据。</li>
</ol>
<p><strong>Token最佳实践</strong></p>
<ul>
<li><p>设置<strong>较短（合理）的过期时间</strong>。</p>
</li>
<li><p>注销的 Token <strong>及时清除</strong>（放入 Redis 中做一层过滤）。</p>
<p>虽然不能修改 Token 的信息，但是能在验证层面做一层过滤来进行处理。</p>
</li>
<li><p>监控 Token 的<strong>使用频率</strong>。</p>
<p>为了防止数据被别人爬取，最常见的就是监控使用频率，程序写出来的爬虫程序访问频率是有迹可循的 </p>
</li>
<li><p>核心功能敏感操作可以使用<strong>动态验证</strong>（验证码）。</p>
<p>比如提现的功能，要求在提现时再次进行验证码的验证，防止不是本人操作。</p>
</li>
<li><p><strong>网络环境、浏览器</strong>信息等识别。</p>
<p>银行 APP 对环境有很高的要求，使用时如果断网，APP 会自动退出，重新登录，因为网络环境跟之前使用的不一样了，还有一些浏览器的信息之类的判断，这些都是可以用来保证后端 API 的安全。</p>
</li>
<li><p><strong>加密密钥</strong>支持动态修改。</p>
<p>如果 Token 的加密密钥泄露了，也就意味着别人可以伪造你的 Token，可以将密钥存储在配置中心，以支持动态修改刷新，需要注意的是建议在流量低峰的时候去做更换的操作，否则 Token 全部失效，所有在线的请求都会重新申请 Token，并发量会比较大。</p>
</li>
</ul>
<h3 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h3><p><strong>痛点：</strong></p>
<ul>
<li><p>服务数量多，业务变动频繁，一周一发布</p>
</li>
<li><p>灰度发布能降低发布失败风险，<strong>减少影响范围</strong></p>
<p>通过灰度发布，先让一部分用户体验新的服务，或者只让测试人员进行测试，等功能正常后再全部发布，这样能降低发布失败带来的影响范围。 </p>
</li>
<li><p>当发布出现故障时，可以<strong>快速回滚</strong>，不影响用户</p>
<p>灰度后如果发现这个节点有问题，那么只需回滚这个节点即可，当然不回滚也没关系，通过灰度策略隔离，也不会影响正常用户</p>
</li>
</ul>
<p>可以通过Ribbon的负载均衡策略进行灰度发布，可以使用更可靠的Discovery</p>
<p><strong>Discovery</strong></p>
<blockquote>
<p>基于Discovery 服务注册发现、Ribbon 负载均衡、Feign 和 RestTemplate 调用等组件的企业级微服务开源解决方案，包括灰度发布、灰度路由、服务隔离等功能</p>
</blockquote>
<img src="https://s0.lgstatic.com/i/image3/M01/54/41/CgpOIF3nXSaAB9bRAAE8rktrUyY037.png" alt="img" style="zoom:50%;" />

<ol>
<li><p>首先将需要发布的服务从转发过程中移除，等流量剔除之后再发布。</p>
</li>
<li><p>部分机器中的版本进行升级，用户默认还是请求老的服务，通过版本来支持测试请求。</p>
</li>
<li><p>测试完成之后，让新的版本接收正常流量，然后部署下一个节点，以此类推。</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grayVersions = &#123;<span class="string">&quot;discovery-article-service&quot;</span>:[<span class="string">&quot;1.01&quot;</span>]&#125;</span><br></pre></td></tr></table></figure>



<h3 id="多版本隔离"><a href="#多版本隔离" class="headerlink" title="多版本隔离"></a>多版本隔离</h3><img src="https://s0.lgstatic.com/i/image3/M01/54/41/Cgq2xl3nXSeAZMTOAAE2sCaIhPE668.png" alt="img" style="zoom:50%;" />



<p><strong>本地复用测试服务</strong>-Eureka Zone亮点</p>
<p>​    <strong>region</strong> 地理上的分区，比如北京、上海等</p>
<p>​    <strong>zone</strong> 可以简单理解为 region 内的具体机房</p>
<p>​    在调用的过程中会优先选择相同的 zone 发起调用，当找不到相同名称的 zone 时会选择其他的 zone 进行调用，我们可以利用这个特性来解决本地需要启动多个服务的问题。</p>
<p>[^]: 当你访问修改的服务 A 时，这个服务依赖了 B、C 两个服务，B 和 C 本地没有启动，B 和 C 找不到相同的 zone 就会选择其他的 zone 进行调用，也就是会调用到测试环境部署的 B 和 C 服务，这样一来就解决了本地部署多个服务的问题。</p>
<h4 id="各组件调优"><a href="#各组件调优" class="headerlink" title="各组件调优"></a><strong>各组件调优</strong></h4><p>当你对网关进行压测时，会发现并发量一直上不去，错误率也很高。因为你用的是默认配置，这个时候我们就需要去调整配置以达到最优的效果。</p>
<p>首先我们可以对容器进行调优，最常见的就是<strong>内置的 Tomcat</strong> 容器了，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server.tomcat.accept-count <span class="comment">//请求队列排队数</span></span><br><span class="line">server.tomcat.max-threads <span class="comment">//最大线程数</span></span><br><span class="line">server.tomcat.max-connections <span class="comment">//最大连接数</span></span><br></pre></td></tr></table></figure>

<p><strong>Hystrix</strong> 的信号量（semaphore）隔离模式，并发量上不去很大的原因都在这里，信号量默认值是 100，也就是最大并发只有 100，超过 100 就得等待。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//信号量</span></span><br><span class="line">zuul.semaphore.max-semaphores <span class="comment">//信号量：最大并发数</span></span><br><span class="line"><span class="comment">//线程池</span></span><br><span class="line">hystrix.threadpool.<span class="keyword">default</span>.coreSize <span class="comment">//最大线程数</span></span><br><span class="line">hystrix.threadpool.<span class="keyword">default</span>.maximumSize <span class="comment">//队列的大</span></span><br><span class="line">hystrix.threadpool.<span class="keyword">default</span>.maxQueueSize <span class="comment">//等参数</span></span><br></pre></td></tr></table></figure>

<p>配置<strong>Gateway</strong>并发信息，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gateway.host.max-per-route-connections <span class="comment">//每个路由的连接数 </span></span><br><span class="line">gateway.host.max-total-connections <span class="comment">//总连接数</span></span><br></pre></td></tr></table></figure>

<p>调整<strong>Ribbon</strong> 的并发配置，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ribbon.MaxConnectionsPerHost <span class="comment">//单服务并发数</span></span><br><span class="line">ribbon.MaxTotalConnections   <span class="comment">//总并发数</span></span><br></pre></td></tr></table></figure>

<p>修改<strong>Feign</strong>默认的HttpURLConnection 替换成 httpclient 来提高性能</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">feign.httpclient.max-connections-per-route<span class="comment">//每个路由的连接数</span></span><br><span class="line">feign.httpclient.max-connections <span class="comment">//总连接数</span></span><br></pre></td></tr></table></figure>

<p>Gateway+配置中心实现动态路由</p>
<p>Feign+配置中心实现动态日志</p>
<h1 id="九、分布式篇"><a href="#九、分布式篇" class="headerlink" title="九、分布式篇"></a><strong>九、分布式篇</strong></h1><blockquote>
<p>分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。</p>
</blockquote>
<h3 id="发展历程"><a href="#发展历程" class="headerlink" title="发展历程"></a><strong>发展历程</strong></h3><ul>
<li><p>入口级负载均衡</p>
<ul>
<li>网关负载均衡</li>
<li>客户端负载均衡</li>
</ul>
</li>
<li><p>单应用架构</p>
<ul>
<li>应用服务和数据服务分离</li>
<li>应用服务集群</li>
<li>应用服务中心化SAAS</li>
</ul>
</li>
<li><p>数据库主备读写分离</p>
<ul>
<li>全文搜索引擎加快数据统计</li>
<li>缓存集群缓解数据库读压力</li>
<li>分布式消息中间件缓解数据库写压力</li>
<li>数据库水平拆分适应微服务</li>
<li>数据库垂直拆分解决慢查询</li>
</ul>
</li>
<li><p>划分上下文拆分微服务</p>
<ul>
<li>服务注册发现（Eureka、Nacos）</li>
<li>配置动态更新（Config、Apollo）</li>
<li>业务灰度发布（Gateway、Feign）</li>
<li>统一安全认证（Gateway、Auth）</li>
<li>服务降级限流（Hystrix、Sentinel）</li>
<li>接口检查监控（Actuator、Prometheus）</li>
<li>服务全链路追踪（Sleuth、Zipkin）</li>
</ul>
</li>
</ul>
<h3 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h3><ul>
<li><strong>一致性</strong>（2PC、3PC、Paxos、Raft）<ul>
<li>强一致性：<strong>数据库一致性</strong>，牺牲了性能<ul>
<li><strong>ACID</strong>：原子性、一致性、隔离性、持久性</li>
</ul>
</li>
<li>弱一致性：<strong>数据库和缓存</strong>，<strong>延迟双删、重试</strong></li>
<li>单调读一致性：<strong>缓存一致性</strong>，ID或者IP哈希</li>
<li>最终一致性：<strong>边缘业务</strong>，消息队列</li>
</ul>
</li>
<li><strong>可用性</strong>（多级缓存、读写分离）<ul>
<li><strong>BASE</strong> 基本可用：限流导致响应速度慢、降级导致用户体验差<ul>
<li>Basically Availabe 基本可用  </li>
<li>Soft state 软状态</li>
<li>Eventual Consistency 最终一致性</li>
</ul>
</li>
</ul>
</li>
<li>分区容忍性（一致性Hash解决扩缩容问题）</li>
</ul>
<div style="page-break-after: always;"></div>

<h3 id="一致性-1"><a href="#一致性-1" class="headerlink" title="一致性"></a>一致性</h3><h4 id="XA方案"><a href="#XA方案" class="headerlink" title="XA方案"></a>XA方案</h4><p><strong>2PC</strong>协议：两阶段提交协议，P是指<strong>准备</strong>阶段，C是指<strong>提交</strong>阶段</p>
<ul>
<li>准备阶段：询问是否可以开始，写Undo、Redo日志，收到响应</li>
<li>提交阶段：执行Redo日志进行<strong>Commit</strong>，执行Undo日志进行<strong>Rollback</strong></li>
</ul>
<p><strong>3PC</strong>协议：将提交阶段分为<strong>CanCommit</strong>、<strong>PreCommit</strong>、<strong>DoCommit</strong>三个阶段</p>
<p><strong>CanCommit</strong>：发送canCommit请求，并开始等待</p>
<p><strong>PreCommit</strong>：收到全部Yes，写Undo、Redo日志。超时或者No，则中断</p>
<p><strong>DoCommit</strong>：执行Redo日志进行<strong>Commit</strong>，执行Undo日志进行<strong>Rollback</strong> </p>
<p>区别是第二步，参与者<strong>自身增加了超时</strong>，如果<strong>失败可以及时释放资源</strong></p>
<h4 id="Paxos算法"><a href="#Paxos算法" class="headerlink" title="Paxos算法"></a><strong>Paxos算法</strong></h4><blockquote>
<p>如何在一个发生异常的分布式系统中，快速且正确地在集群内部对某个数据的值达成一致</p>
</blockquote>
<p>​    参与者（例如Kafka）的一致性可以由协调者（例如Zookeeper）来保证，<strong>协调者的一致性就只能由Paxos保证了</strong></p>
<p>Paxos算法中的角色：</p>
<ul>
<li><strong>Client</strong>：客户端、例如，对分布式文件服务器中文件的写请求。</li>
<li><strong>Proposer</strong>：提案发起者，根据Accept返回选择最大N对应的V，发送[N+1,V]</li>
<li><strong>Acceptor</strong>：决策者，Accept以后会拒绝小于N的提案，并把自己的[N,V]返回给Proposer</li>
<li><strong>Learners</strong>：最终决策的学习者、学习者充当该协议的复制因素</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//算法约束</span></span><br><span class="line">P1:一个Acceptor必须接受它收到的第一个提案。</span><br><span class="line"><span class="comment">//考虑到半数以上才作数，一个Accpter得接受多个相同v的提案</span></span><br><span class="line">P2a:如果某个v的提案被accept，那么被Acceptor接受编号更高的提案必须也是v</span><br><span class="line">P2b:如果某个v的提案被accept，那么从Proposal提出编号更高的提案必须也是v</span><br><span class="line"><span class="comment">//如何确保v的提案Accpter被选定后，Proposal都能提出编号更高的提案呢</span></span><br><span class="line">针对任意的[Mid,Vid]，有半数以上的Accepter集合S，满足以下二选一：</span><br><span class="line">  S中接受的提案都大于Mid</span><br><span class="line">  S中接受的提案若小于Mid，编号最大的那个值为Vid</span><br></pre></td></tr></table></figure>

<p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmlato63bnj319m0u0wmi.jpg" alt="image-20210112225118095"></p>
<p>面试题：如何保证Paxos算法活性</p>
<p>​    假设存在这样一种极端情况，有两个Proposer依次提出了一系列编号递增的提案，导致最终陷入死循环，没有value被选定</p>
<ul>
<li><strong>通过选取主Proposer</strong>，规定只有主Proposer才能提出议案。只要主Proposer和过半的Acceptor能够正常网络通信，主Proposer提出一个编号更高的提案，该提案终将会被批准。</li>
<li>每个Proposer发送提交提案的时间设置为<strong>一段时间内随机</strong>，保证不会一直死循环</li>
</ul>
<h4 id="ZAB算法"><a href="#ZAB算法" class="headerlink" title="ZAB算法"></a><strong>ZAB算法</strong></h4><h4 id="Raft算法"><a href="#Raft算法" class="headerlink" title="Raft算法"></a>Raft算法</h4><blockquote>
<p>Raft 是一种为了管理复制日志的一致性算法</p>
</blockquote>
<p>Raft使用<strong>心跳机制</strong>来触发选举。当server启动时，初始状态都是<strong>follower</strong>。每一个server都有一个定时器，超时时间为election timeout（<strong>一般为150-300ms</strong>），如果某server<strong>没有超时的情况下收到</strong>来自领导者或者候选者的任何消息，<strong>定时器重启</strong>，如果超时，它就<strong>开始一次选举</strong>。</p>
<p><strong>Leader异常</strong>：异常期间Follower会超时选举，完成后Leader比较彼此步长</p>
<p><strong>Follower异常：</strong>恢复后直接同步至Leader当前状态</p>
<p><strong>多个Candidate：</strong>选举时失败，失败后超时继续选举</p>
<h4 id="数据库和Redis的一致性"><a href="#数据库和Redis的一致性" class="headerlink" title="数据库和Redis的一致性"></a>数据库和Redis的一致性</h4><p><strong>全量缓存保证高效读取</strong></p>
<img src="/Users/suhongliu/Library/Application Support/typora-user-images/image-20210418185425386.png" alt="image-20210418185425386" style="zoom:50%;" />

<p>所有数据都存储在缓存里，读服务在查询时不会再降级到数据库里，所有的请求都完全依赖缓存。此时，因降级到数据库导致的毛刺问题就解决了。但全量缓存并<strong>没有解决更新时的分布式事务</strong>问题，反而把问题放大了。因为全量缓存<strong>对数据更新要求更加严格</strong>，要求所有数据库<strong>已有数据和实时更新</strong>的数据必须完全同步至缓存，不能有遗漏。对于此问题，一种有效的方案是采用<strong>订阅数据库的 Binlog</strong> 实现数据同步</p>
<img src="/Users/suhongliu/Library/Application Support/typora-user-images/image-20210418185457610.png" alt="image-20210418185457610" style="zoom:50%;" />

<p>​    现在很多开源工具（如<strong>阿里的 Canal</strong>等）可以模拟主从复制的协议。通过模拟协议读取主数据库的 Binlog 文件，从而获取主库的所有变更。对于这些变更，它们开放了各种接口供业务服务获取数据。</p>
<img src="/Users/suhongliu/Library/Application Support/typora-user-images/image-20210418185516743.png" alt="image-20210418185516743" style="zoom:50%;" />

<p>​    将 Binlog 的中间件挂载至目标数据库上，就可以<strong>实时获取该数据库的所有变更数据</strong>。对这些变更数据解析后，便可<strong>直接写入缓存里</strong>。优点还有：</p>
<ul>
<li><p>大幅提升了读取的速度，降低了延迟</p>
</li>
<li><p>Binlog 的主从复制是基于 <strong>ACK</strong> 机制， 解决了分布式事务的问题</p>
<p>如果同步缓存失败了，被消费的 Binlog 不会被确认，下一次会重复消费，数据最终会写入缓存中</p>
</li>
</ul>
<p><strong>缺点</strong>不可避免：1、增加复杂度 2、消耗缓存资源 3、需要筛选和压缩数据 4、极端情况数据丢失</p>
<img src="/Users/suhongliu/Library/Application Support/typora-user-images/image-20210418185549520.png" alt="image-20210418185549520" style="zoom:50%;" />

<p>可以通过异步校准方案进行补齐，但是会损耗数据库性能。但是此方案会隐藏中间件使用错误的细节，线上环境前期更重要的是记录日志排查在做后续优化，不能本末倒置。</p>
<div style="page-break-after: always;"></div>

<h3 id="可用性-1"><a href="#可用性-1" class="headerlink" title="可用性"></a>可用性</h3><h4 id="心跳检测"><a href="#心跳检测" class="headerlink" title="心跳检测"></a><strong>心跳检测</strong></h4><blockquote>
<p>以<strong>固定的频率</strong>向其他节点汇报当前节点状态的方式。收到心跳，说明网络和节点的状态是健康的。心跳汇报时，一般会携带一些附加的<strong>状态、元数据，以便管理</strong></p>
</blockquote>
<p><strong>周期检测心跳机制</strong>：超时未返回</p>
<p><strong>累计失效检测机制</strong>：重试超次数</p>
<h4 id="多机房实时热备"><a href="#多机房实时热备" class="headerlink" title="多机房实时热备"></a><strong>多机房实时热备</strong></h4><img src="/Users/suhongliu/Library/Application Support/typora-user-images/image-20210418185610597.png" alt="6.png" style="zoom:50%;" />

<p>两套缓存集群可以分别部署到不同城市的机房。读服务也相应地部署到不同城市或不同分区。在承接请求时，不同机房或分区的读服务只依赖同样属性的缓存集群。此方案有两个好处。</p>
<ol>
<li><strong>提升了性能。</strong>读服务不要分层，读服务要尽可能地和缓存数据源靠近。</li>
<li><strong>增加了可用。</strong>当单机房出现故障时，可以秒级将所有流量都切换至存活的机房或分区</li>
</ol>
<p>此方案虽然带来了性能和可用性的提升，但代价是资源成本的上升。</p>
<div style="page-break-after: always;"></div>

<h3 id="分区容错性"><a href="#分区容错性" class="headerlink" title="分区容错性"></a>分区容错性</h3><blockquote>
<p>分布式系统对于错误包容的能力</p>
</blockquote>
<p>通过限流、降级、兜底、重试、负载均衡等方式增强系统的健壮性</p>
<h4 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h4><p><img src="https://i.loli.net/2021/01/14/fmYEJy9N7Zjp2Xd.png" alt="image-20210114154435003"></p>
<ol>
<li><strong>Leader</strong>把指令添加到日志中，发起 RPC 给其他的服务器，让他们复制这条信息</li>
<li><strong>Leader</strong>会不断的重试，直到所有的 Follower响应了ACK并复制了所有的日志条目</li>
<li>通知所有的<strong>Follower</strong>提交，同时Leader该表这条日志的状态，并返回给客户端</li>
</ol>
<h4 id="主备（Master-Slave）"><a href="#主备（Master-Slave）" class="headerlink" title="主备（Master-Slave）"></a><strong>主备（Master-Slave）</strong></h4><p>​    主机宕机时，备机接管主机的一切工作，主机恢复正常后，以自动（<strong>热备</strong>）或手动（<strong>冷备</strong>）方式将服务切换到主机上运行，<strong>Mysql</strong>和<strong>Redis</strong>中常用。</p>
<p>​    MySQL之间数据复制的基础是<strong>二进制日志文件</strong>（binary log fifile）。它的数据库中所有操作都会以<strong>“事件”</strong>的方式记录在二进制日志中，其他数据库作为slave通过一个<strong>I&#x2F;O线程与主服务器保持通信</strong>，并<strong>监控</strong>master的二进制日志文件的变化，如果发现master二进制日志文件<strong>发生变化</strong>，则会把变化复制到自己的<strong>中继日志</strong>中，然后slave的一个SQL线程会把相关的“事件”<strong>执行</strong>到自己的数据库中，以此实现从数据库和主数据库的<strong>一致性</strong>，也就实现了<strong>主从复制</strong></p>
<h4 id="互备（Active-Active）"><a href="#互备（Active-Active）" class="headerlink" title="互备（Active-Active）"></a><strong>互备（Active-Active）</strong></h4><p>​    指两台主机<strong>同时运行</strong>各自的服务工作且<strong>相互监测</strong>情况。在数据库高可用部分，常见的互备是<strong>MM</strong>模式。MM模式即<strong>Multi-Master</strong>模式，指一个系统存在多个master，每个master都具有<strong>read-write</strong>能力，会根据<strong>时间戳</strong>或<strong>业务逻辑</strong>合并版本。</p>
<h4 id="集群（Cluster）模式"><a href="#集群（Cluster）模式" class="headerlink" title="集群（Cluster）模式"></a><strong>集群（Cluster）模式</strong></h4><p>​    是指有多个节点在运行，同时可以通过主控节点<strong>分担服务</strong>请求。如Zookeeper。集群模式需要解决主控节点<strong>本身的高可用</strong>问题，一般采用主备模式。</p>
<div style="page-break-after: always;"></div>

<h3 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h3><h4 id="XA方案-1"><a href="#XA方案-1" class="headerlink" title="XA方案"></a>XA方案</h4><p><strong>两阶段提交</strong> | <strong>三阶段提交</strong></p>
<ul>
<li>准备阶段的资源锁定，存在性能问题，严重时会造成死锁问题</li>
<li>提交事务请求后，出现网络异常，部分数据收到并执行，会造成一致性问</li>
</ul>
<h4 id="TCC方案"><a href="#TCC方案" class="headerlink" title="TCC方案"></a>TCC方案</h4><p><strong>Try Confirm Cancel &#x2F; 短事务</strong></p>
<ul>
<li><p><strong>Try</strong> 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行<strong>锁定或者预留</strong></p>
</li>
<li><p><strong>Confirm</strong> 阶段：这个阶段说的是在各个服务中<strong>执行实际的操作</strong></p>
</li>
<li><p><strong>Cancel</strong> 阶段：如果任何一个服务的业务方法执行出错，那么就需要<strong>进行补偿</strong>&#x2F;回滚</p>
</li>
</ul>
<h4 id="Saga方案"><a href="#Saga方案" class="headerlink" title="Saga方案"></a><strong>Saga方案</strong></h4><p>事务性补偿 &#x2F; 长事务</p>
<ul>
<li>流程<strong>长</strong>、流程<strong>多</strong>、调用第三方业务</li>
</ul>
<h4 id="本地消息表（eBay）"><a href="#本地消息表（eBay）" class="headerlink" title="本地消息表（eBay）"></a><strong>本地消息表（eBay）</strong></h4><h4 id="MQ最终一致性"><a href="#MQ最终一致性" class="headerlink" title="MQ最终一致性"></a><strong>MQ最终一致性</strong></h4><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmr1k3dfbxj31h00pkjy8.jpg" alt="image-20210117220405706" style="zoom:50%;" />

<p>比如阿里的 RocketMQ 就支持消息事务（核心：<strong>双端确认，重试幂等</strong>）</p>
<ol>
<li>A**(订单)** 系统先发送一个 <strong>prepared</strong> 消息到 mq，prepared 消息发送失败则取消操作不执行了</li>
<li>发送成功后，那么执行本地事务，执行成功和和失败发送<strong>确认和回滚</strong>消息到mq</li>
<li>如果发送了确认消息，那么此时 B**(仓储)** 系统会接收到确认消息，然后执行本地的事务</li>
<li>mq 会自动<strong>定时轮询</strong>所有 prepared 消息回调的接口，确认事务执行状态</li>
<li>B 的事务失败后自动<strong>不断重试</strong>直到成功，达到一定次数后发送报警由人工来<strong>手工回滚</strong>和<strong>补偿</strong></li>
</ol>
<h4 id="最大努力通知方案（订单-gt-积分）"><a href="#最大努力通知方案（订单-gt-积分）" class="headerlink" title="最大努力通知方案（订单 -&gt; 积分）"></a>最大努力通知方案（订单 -&gt; 积分）</h4><ol>
<li>系统 A 本地事务执行完之后，发送个消息到 MQ；</li>
<li>这里会有个专门消费 MQ 的<strong>最大努力通知服务</strong>，接着调用系统 B 的接口；</li>
<li>要是系统 B 执行失败了，就定时尝试重新调用系统 B，<strong>反复 N 次</strong>，最后还是不行就<strong>放弃</strong></li>
</ol>
<p>你找一个严格<strong>资金</strong>要求绝对不能错的场景，你可以说你是用的 <strong>TCC 方案</strong>；</p>
<p>如果是一般的分布式事务场景，例如<strong>积分</strong>数据，可以用可靠消息<strong>最终一致性方案</strong></p>
<p>如果分布式场景<strong>允许不一致</strong>，可以使用最大努力通知方案</p>
<div style="page-break-after: always;"></div>

<h3 id="面试题-3"><a href="#面试题-3" class="headerlink" title="面试题"></a>面试题</h3><h4 id="分布式Session实现方案"><a href="#分布式Session实现方案" class="headerlink" title="分布式Session实现方案"></a>分布式Session实现方案</h4><ul>
<li>基于JWT的Token，数据从cache或者数据库中获取</li>
<li>基于Tomcat的Redis，简单配置conf文件</li>
<li>基于Spring的Redis，支持SpringCloud和Springb</li>
</ul>

      
    </div>

    
    
    


    <div>
      
    </div>

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>l




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/5a56f011/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lion.png">
      <meta itemprop="name" content="swimminghao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="swimminghao's blog">
      <meta itemprop="description" content="swimminghao的学习博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | swimminghao's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/5a56f011/" class="post-title-link" itemprop="url">2、【对线面试官】今天来聊聊Java泛型</a>
        </h2>

        <div class="post-meta-container">

          

          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 19:57:47" itemprop="dateCreated datePublished" datetime="2022-02-28T19:57:47+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-03-10 09:48:07" itemprop="dateModified" datetime="2022-03-10T09:48:07+08:00">2022-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">技术</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/posts/5a56f011/#waline-comments" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" id="/posts/5a56f011/" data-xid="/posts/5a56f011/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>#2、【对线面试官】今天来聊聊Java泛型</p>
<h2 id="泛型了解"><a href="#泛型了解" class="headerlink" title="泛型了解"></a>泛型了解</h2><ol>
<li>在Java中的泛型简单来说就是：在创建对象或调用方法的时候才明确下具体的类型</li>
<li>使用泛型的好处就是代码更加简洁（不再需要强制转换），程序更加健壮（在编译期间没有警告，在运行期就不会出现ClassCastException异常）</li>
</ol>
<h2 id="工作中用得多吗"><a href="#工作中用得多吗" class="headerlink" title="工作中用得多吗"></a>工作中用得多吗</h2><ol>
<li>在操作集合的时候，还是很多的，毕竟方便啊。List lists &#x3D; new ArrayList&lt;&gt;();lists.add （”面试造火箭”）；</li>
<li>如果是其他场景的话，那就是在写「基础组件」的时候了。</li>
</ol>
<h2 id="你是怎么写的"><a href="#你是怎么写的" class="headerlink" title="你是怎么写的"></a>你是怎么写的</h2><ol>
<li><p>再明确一下泛型就是「在创建对象或调用方法的时候才明确下具体的类型」</p>
</li>
<li><p>而组件为了做到足够的通用性，是不知道「用户」传入什么类型参数进来的所以在这种情况下用泛型就是很好的实践。</p>
</li>
<li><p>这块可以参考SpringData JPA的JpaRepository写法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">JpaRepository</span>&lt;T, ID&gt; <span class="keyword">extends</span> <span class="title class_">PagingAndSortingRepository</span>&lt;T, ID&gt;, QueryByExampleExecutor&lt;T&gt; &#123;</span><br><span class="line"></span><br><span class="line"> List&lt;T&gt; <span class="title function_">findAll</span><span class="params">()</span>;</span><br><span class="line"></span><br><span class="line"> List&lt;T&gt; <span class="title function_">findAll</span><span class="params">(Sort sort)</span>;</span><br><span class="line"></span><br><span class="line"> List&lt;T&gt; <span class="title function_">findAllById</span><span class="params">(Iterable&lt;ID&gt; ids)</span>;</span><br><span class="line"></span><br><span class="line"> &lt;S <span class="keyword">extends</span> <span class="title class_">T</span>&gt; List&lt;S&gt; <span class="title function_">saveAll</span><span class="params">(Iterable&lt;S&gt; entities)</span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">void</span> <span class="title function_">flush</span><span class="params">()</span>;</span><br><span class="line"></span><br><span class="line"> &lt;S <span class="keyword">extends</span> <span class="title class_">T</span>&gt; S <span class="title function_">saveAndFlush</span><span class="params">(S entity)</span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">void</span> <span class="title function_">deleteInBatch</span><span class="params">(Iterable&lt;T&gt; entities)</span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">void</span> <span class="title function_">deleteAllInBatch</span><span class="params">()</span>;</span><br><span class="line"></span><br><span class="line"> T <span class="title function_">getOne</span><span class="params">(ID id)</span>;</span><br><span class="line"></span><br><span class="line"> <span class="meta">@Override</span></span><br><span class="line"> &lt;S <span class="keyword">extends</span> <span class="title class_">T</span>&gt; List&lt;S&gt; <span class="title function_">findAll</span><span class="params">(Example&lt;S&gt; example)</span>;</span><br><span class="line"></span><br><span class="line"> <span class="meta">@Override</span></span><br><span class="line"> &lt;S <span class="keyword">extends</span> <span class="title class_">T</span>&gt; List&lt;S&gt; <span class="title function_">findAll</span><span class="params">(Example&lt;S&gt; example, Sort sort)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>要写组件，还是离不开Java反射机制（能够从运行时获取信息），所以一般组件是泛型+反射来实现的。</p>
</li>
<li><p>回到我所讲的组件吧，背景是这样的：我这边有个需求，需要根据某些字段进行聚合。</p>
</li>
<li><p>换到SQL其实就是select sum（column 1),sum(column2) from table group by fie ld1,field2</p>
</li>
<li><p>需要sum和group by的列肯定是由业务方自己传入，而SQL的表其实就是我们的POJO（传入的字段也肯定是POJO的属性）</p>
</li>
<li><p>单个业务实际可以在参数上写死POJO，但为了做得更加通用，我把入参设置为泛型</p>
</li>
<li><p>拿到参数后，通过反射获取其字段具体的值，做累加就好了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 传入 需要group by 和 sum 的字段名</span></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">cacheMap</span><span class="params">(List&lt;String&gt; groupByKeys, List&lt;String&gt; sumValues)</span> &#123;</span><br><span class="line">  <span class="built_in">this</span>.groupByKeys = groupByKeys;</span><br><span class="line">  <span class="built_in">this</span>.sumValues = sumValues;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">excute</span><span class="params">(T e)</span> &#123;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 从pojo 取出需要group by 的字段 list</span></span><br><span class="line">  List&lt;Object&gt; key = buildPrimaryKey(e);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// primaryMap 是存储结果的Map</span></span><br><span class="line">  <span class="type">T</span> <span class="variable">value</span> <span class="operator">=</span> primaryMap.get(key);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 如果从存储结果找到有相应记录</span></span><br><span class="line">  <span class="keyword">if</span> (value != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> (String elem : sumValues) &#123;</span><br><span class="line">      <span class="comment">// 反射获取对应的字段，做累加处理</span></span><br><span class="line">      <span class="type">Field</span> <span class="variable">field</span> <span class="operator">=</span> getDeclaredField(elem, e);</span><br><span class="line">      <span class="keyword">if</span> (field.get(e) <span class="keyword">instanceof</span> Integer) &#123;</span><br><span class="line">        field.set(value, (Integer) field.get(e) + (Integer) field.get(value));</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (field.get(e) <span class="keyword">instanceof</span> Long) &#123;</span><br><span class="line">        field.set(value, (Long) field.get(e) + (Long) field.get(value));</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;类型异常,请处理异常&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 处理时间记录</span></span><br><span class="line">    <span class="type">Field</span> <span class="variable">field</span> <span class="operator">=</span> getDeclaredField(<span class="string">&quot;updated&quot;</span>, value);</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">null</span> != field) &#123;</span><br><span class="line">      field.set(value, DateTimeUtils.getCurrentTime());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// group by 字段 第一次进来</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      primaryMap.put(key, Tclone(e));</span><br><span class="line">      createdMap.put(key, DateTimeUtils.getCurrentTime());</span><br><span class="line">    &#125;<span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">      log.info(<span class="string">&quot;first put value error &#123;&#125;&quot;</span> , e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>理解了泛型的作用之后，再去审视自己代码时，就可以判断是否需要用到泛型了。</p>
</li>
</ol>
<h2 id="价值体现"><a href="#价值体现" class="headerlink" title="价值体现"></a>价值体现</h2><ol>
<li>主要是在平时工作中，写代码的时候会多想想，遇到能用到的地方会优化下代码</li>
</ol>

      
    </div>

    
    
    


    <div>
      
    </div>

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>l




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/6f559dce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lion.png">
      <meta itemprop="name" content="swimminghao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="swimminghao's blog">
      <meta itemprop="description" content="swimminghao的学习博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | swimminghao's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/6f559dce/" class="post-title-link" itemprop="url">30、【对线面试官】CMS垃圾回收器</a>
        </h2>

        <div class="post-meta-container">

          

          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 19:57:47" itemprop="dateCreated datePublished" datetime="2022-02-28T19:57:47+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-03-10 09:48:07" itemprop="dateModified" datetime="2022-03-10T09:48:07+08:00">2022-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">技术</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/posts/6f559dce/#waline-comments" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" id="/posts/6f559dce/" data-xid="/posts/6f559dce/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="30、【对线面试官】CMS垃圾回收器"><a href="#30、【对线面试官】CMS垃圾回收器" class="headerlink" title="30、【对线面试官】CMS垃圾回收器"></a>30、【对线面试官】CMS垃圾回收器</h1><h2 id="今天还是来聊聊CMS垃圾收集器呗？"><a href="#今天还是来聊聊CMS垃圾收集器呗？" class="headerlink" title="今天还是来聊聊CMS垃圾收集器呗？"></a>今天还是来聊聊CMS垃圾收集器呗？</h2><ul>
<li>如果用Seria和 Parallel系列的垃圾收集器：在垃圾回收的时，用户线程都会完全停止，直至垃圾回收结束！</li>
<li>CMS的全称： Concurrent Mark Sweep，翻译过来是「并发标记清除」</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/1u2iZp_20211229164510.png"></p>
<ul>
<li>用CMS对比上面的垃圾收集器（ Seria和Parllel和 parNew）：它最大的不同点就是「并发」：在GC线程工作的时候，用户线程「不会完全停止」，用户线程在「部分场景下」与GC线程一起并发执行</li>
<li>无论是什么垃圾收集器， Stop The Word&#x2F;是一定无法避免的！</li>
<li>CMS只是在「部分」的GC场景下可以让GC线程与用户线程并发执行</li>
<li>目的：为了避免「老年代GC」出现「长时间」的卡顿（ Stop The Word )</li>
</ul>
<h2 id="CMS工作流程"><a href="#CMS工作流程" class="headerlink" title="CMS工作流程"></a>CMS工作流程</h2><ul>
<li><p>CMS可以简单分为5个步骤：初始标记、并发标记、并发预清理、重新标记以及并发清除</p>
<ul>
<li><p>从步骤可看出，CMS主要是实现了「标记清除」垃圾回收算法</p>
</li>
<li><p>「初始标记」</p>
<ul>
<li>「初始标记」会标记 GCroots「直接关联」的对象以及「年轻代」指向「老年代」的对象</li>
<li>「初始标记」这个过程是会发生 Stop The Word的。但这个阶段的速度算是很快的，因为没有「向下追溯」（只标记一层）</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/FqsTqd_20211229162246.png"></p>
</li>
<li><p>「并发标记」</p>
<ul>
<li>「并发标记」这个过程是不会停止用户线程的（不会发生 Stop The Word）。这一阶段主要是从 GC Roots向下「追溯」，标记所有可达的对象</li>
<li>并发标记」在GC的角度而言，是比较耗费时间的（需要追溯）</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/cUUH7w_20211229162544.png"></p>
</li>
<li><p>「并发预处理」</p>
<ul>
<li>「并发预处理」这个阶段主要是：希望能减少下一个阶段「重新标记」所消耗的时间</li>
<li>因为下一个阶段「重新标记」是需要Stop The World的，「并发标记」这个阶段由于用户线程是没有被挂起的，所以对象是有可能发生变化的</li>
<li>可能有些对象，从新生代晋升到了老年代。可能有些对象，直接分配到了老年代（大对象）。可能老年代或者新生代的对象引用发生了变化</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/NeI2CU_20211229163018.png"></p>
</li>
<li><p>「重新标记」</p>
<ul>
<li>「重新标记」阶段会 Stop The Word，这个过程的停顿时间其实很大程度上取决于上面「并发预处理」阶段</li>
<li>这是一个追赶的过程：边在标记存活对象，一边用户线程在执行产生垃圾）</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/o97JPO_20211229163156.png"></p>
</li>
<li><p>「并发清除」</p>
<ul>
<li>一边用户线程在执行，一边GC线程在回收不可达的对象</li>
<li>这个过程，还是有可能用户线程在不断产生垃圾，但只能留到下一次GC进行处<br>理了，产生的这些垃圾被叫做“浮动垃圾”</li>
<li>完了以后会重置CMS算法相关的内部数据，为下一次GC循环做准备</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/TJihOR_20211229163307.png"></p>
</li>
</ul>
</li>
</ul>
<h2 id="为什么要扫年轻代？"><a href="#为什么要扫年轻代？" class="headerlink" title="为什么要扫年轻代？"></a>为什么要扫年轻代？</h2><ul>
<li>CMS主要回收老年代的对象。年轻代有可能会指向老年代的对象，不扫就不知道是不是垃圾了</li>
</ul>
<h2 id="「并发预处理」问题解决"><a href="#「并发预处理」问题解决" class="headerlink" title="「并发预处理」问题解决"></a>「并发预处理」问题解决</h2><ul>
<li>针对老年代的对象，其实还是可以借助类 card table的存储（将老年代对象发生变化所对应的卡页标记为 dirty）</li>
<li>所以「并发预处理」这个阶段会扫描可能由于「并发标记」时导致老年代发生变化的对象，会再扫描一遍标记为diy的卡页</li>
<li>对于新生代的对象，我们还是得遍历新生代来看看在「并发标记」过程中有没有对象引用了老年代.</li>
<li>JVM里给我们提供了很多「参数」，有可能在这个过程中会触发一次minor GC（触发了 minor GC是意味着就可以更少地遍历新生代的对象）</li>
</ul>
<h2 id="相比G1，那你觉得CMS有什么缺点呢？"><a href="#相比G1，那你觉得CMS有什么缺点呢？" class="headerlink" title="相比G1，那你觉得CMS有什么缺点呢？"></a>相比G1，那你觉得CMS有什么缺点呢？</h2><ul>
<li><p>1.空间需要预留：CMS垃圾收集器可以一边回收垃圾，一边处理用户线程，那需要在这个过程中保证有充足的内存空间供用户使用。</p>
<ul>
<li>如果CMS运行过程中预留的空间不够用了，会报错（ Concurrent Mode Failure），这时会启动 Serial Old垃圾收集器进行老年代的垃圾回收，会导致停顿的时间很长</li>
</ul>
</li>
<li><p>2.内存碎片问题：CMS本质上是实现了「标记清除算法」的收集器（从过程就可以看得出），这会意味着会产生内存碎片</p>
<ul>
<li>由于碎片太多，又可能会导致内存空间不足所触发 full GC，CMS一般会在触发full GC这个过程对碎片进行整理</li>
<li>整理涉及到「移动」&#x2F;「标记」，那这个过程肯定会 Stop The Word的，如果内存足够大（意味着可能装载的对象足够多），那这个过程卡顿也是需要一定的时间的。</li>
</ul>
</li>
<li><p>使用CMS的弊端好像就是一个死循环</p>
<ul>
<li>1.内存碎片过多，导致空间利用率减低。</li>
<li>2.空间本身就需要预留给用户线程使用，现在碎片内存又加剧了空间的问题，导致有可能垃圾收集器降级为 Serial old，卡顿时间更长</li>
<li>3.要处理内存碎片的问题（整理），同样会卡顿</li>
</ul>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li><p>CMS把垃圾回收的过程给”细分”了，然后在某些阶段可以不停止用户线程，一边回收垃圾，一边处理请求，来减少每次垃圾回收时 Stop The Word的时间</p>
</li>
<li><p>中间也做了很多的优化（ dirty card标记、可能中途触发 minor gca等等，在我理解下，这些都提供了CMS的相关参数配置</p>
</li>
<li><p>CMS垃圾回收器设计目的：</p>
<ul>
<li>为了避免「老年代 GC」出现「长时间」的卡顿（Stop The World）</li>
</ul>
</li>
<li><p>CMS垃圾回收器回收过程：</p>
<ul>
<li>初始标记、并发标记、并发预处理、重新标记和并发清除。初始标记以及重新标记这两个阶段会Stop The World</li>
</ul>
</li>
<li><p>CMS垃圾回收器的弊端：</p>
<ul>
<li>会产生内存碎片&amp;&amp;需要空间预留：停顿时间是不可预知的</li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/KNqlDT_20211229164021.png"></p>

      
    </div>

    
    
    


    <div>
      
    </div>

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>l




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/e93a2b49/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lion.png">
      <meta itemprop="name" content="swimminghao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="swimminghao's blog">
      <meta itemprop="description" content="swimminghao的学习博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | swimminghao's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/e93a2b49/" class="post-title-link" itemprop="url">31、【对线面试官】G1垃圾收集器</a>
        </h2>

        <div class="post-meta-container">

          

          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 19:57:47" itemprop="dateCreated datePublished" datetime="2022-02-28T19:57:47+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-03-10 09:48:07" itemprop="dateModified" datetime="2022-03-10T09:48:07+08:00">2022-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">技术</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/posts/e93a2b49/#waline-comments" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" id="/posts/e93a2b49/" data-xid="/posts/e93a2b49/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="31、【对线面试官】G1垃圾收集器"><a href="#31、【对线面试官】G1垃圾收集器" class="headerlink" title="31、【对线面试官】G1垃圾收集器"></a>31、【对线面试官】G1垃圾收集器</h1><h2 id="要不这次来聊聊G1垃圾收集器？"><a href="#要不这次来聊聊G1垃圾收集器？" class="headerlink" title="要不这次来聊聊G1垃圾收集器？"></a>要不这次来聊聊G1垃圾收集器？</h2><ul>
<li><p>CMS垃圾收集器的升级</p>
</li>
<li><p>G1垃圾收集器可以给你设定一个你希望Stop The Word停顿时间，G1垃圾收集器会根据这个时间尽量满足你</p>
<ul>
<li><p>在前面我在介绍JM堆的时候，堆的内存分布是以「物理」空间进行隔离</p>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/qjMhU8_20211229164725.png"></p>
</li>
<li><p>在G1垃圾收集器的世界上，堆的划分不再是「物理」形式，而是以「逻辑」的形式进行划分</p>
</li>
<li><p>不过的「分代」概念在G1垃圾收集器的世界还是一样奏效的</p>
</li>
<li><p>比如说：新对象一般会分配到Eden区经过默认15次的 Minor GC新生代的对象如果还存活，会移交到老年代等等。</p>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/SwXVef_20211229165004.png"></p>
</li>
<li><p>堆被划分了多个同等份的区域，在G1里每个区域叫做Region</p>
</li>
<li><p>G1中，还有一种叫 Humongous（大对象）区域，其实就是用来存储特别大的对象（大于 Region内存的一半）</p>
</li>
<li><p>一旦发现没有引用指向大对象，就可直接在年轻代的 Minor GC中被回收掉</p>
</li>
<li><p>之所以要将「堆空间」进行「细分」多个小的区域，是因为像以前的垃圾收集器都是对堆进行「物理」划分，如果堆空间（内存）大的时候，每次进行「垃圾回收」都需要对一整块大的区域进行回收，那收集的时间是不好控制的；而划分多个小区域之后，那对这些「小区域」回收就容易控制它的「收集时间」了</p>
</li>
</ul>
</li>
</ul>
<h2 id="GC过程"><a href="#GC过程" class="headerlink" title="GC过程"></a>GC过程</h2><ul>
<li><p>在G1收集器中，可以主要分为有Minor GC（ Young GC）和 Mixed GC，也有些特殊场景可能会发生 Full GC</p>
<ul>
<li><p>Minor GC</p>
<ul>
<li><p>G1的 Minor GC其实触发时机跟前面提到过的垃圾收集器都是一样的</p>
</li>
<li><p>等到Eden区满了之后，会触发 Minor GC。 Minor GCI同样也是会发生 Stop The World的</p>
</li>
<li><p>要补充说明的是：在G1的世界里，新生代和老年代所占堆的空间是没那么固定的（会动态根据「最大停顿时间」进行调整）</p>
</li>
<li><p>这块会给我们提供参数进行配置就好了</p>
</li>
<li><p>所以，动态地改变收集年轻代 Region的个数可以「控制」 Minor GCI的开销</p>
</li>
<li><p>Minor GC我认为可以简单分为为三个步骤：根扫描、更新&amp;&amp;处理RSet、复制对象</p>
<p>1）第一步应该很好理解，因为这跟之前CMS是类似的，可以理解为初始标记的过程</p>
<p>2）第二步就是处理RSet的信息并且扫描，将老年代对象持有年轻代对象的相关引用都加入到 GC Roots下，避免被回收掉</p>
<p>​        涉及到「Rset」的概念</p>
<p>​    （1）上ー次我们聊CMS回收过程的时候，同样讲到了 Minor GC，它是通过「卡表」（ cart table）来避免全表扫描老年代的对象</p>
<p>​    （2）因为 Minor GC是回收年轻代的对象，但如果老年代有对象引用着年轻代，那这些被老年代引用的对象也不能回收掉</p>
<p>​    （3）同样的，在G1也有这种问题（毕竟是Minor GC）。CMS是卡表，而G1解决「跨代引用」的问题的存储一般叫做RSet</p>
<p>​    （4）只要记住，RSet这种存储在每个 Region都会有，它记录着「其他 Region引用了当前 Regiong的对象关系」</p>
<p>​    <img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/FpUxzX_20211229170010.png"></p>
<p>​    （5）对于年轻代的 Region，它的RSet只保存了来自老年代的引用（因为年轻代的没必要存储啊，自己都要做 Minor GC了</p>
<p>​    （6）而对于老年代的 Region来说，它的RSet也只会保存老年代对它的引用（在G1垃圾收集器，老年代回收之前，都会先对年轻代进行回收，所以没必要保存年轻代的引用）</p>
<p>3）第三步：把扫描之后存活的对象往「空的 Survivor区」或者老年代」存放，其他的Eden区进行清除</p>
<p>​    （1）这里要提下的是，在G1还有另一个名词，叫做CSet</p>
<p>​    （2）它的全称是 Collection Set，保存了一次GC中「将执行垃圾回收」的 Region。CSet中的所有存活对象都会被转移到别的可用 Region上</p>
<p>​    （3）在 Minor GC的最后，会处理下软引用、弱引用、 JNI Weak等引用，结束收集</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>总结</p>
<ul>
<li><p>总结起来就是：扫描、处理跨 Region引用、收集至CSet、复制清除、处理引用</p>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/WZo9bF_20211229170433.png"></p>
</li>
</ul>
</li>
</ul>
<h2 id="MixedGC过程"><a href="#MixedGC过程" class="headerlink" title="MixedGC过程"></a>MixedGC过程</h2><ul>
<li>当堆空间的占用率达到一定阈值后会触发 Mixed GC（默认45%，由参数决定）</li>
<li>Mixed GC会依赖「全局并发标记」统计后的 Region数据</li>
<li>「全局并发标记」它的过程跟CMS非常类型，步骤大概是：初始标记（STW）、并发标记、最终标记（ST）以及清理（ST）<ul>
<li>说明： Mixed GC它一定会回收年轻代，并会采集部分老年代的Region进行回收的，所以它是一个混合GC</li>
<li>「初始标记」，<ul>
<li>这个过程是「共用」了 Minor GC的 Stop The World（Mixed GC一定会发生 Minor GC），复用了「扫描 GC Roots的操作</li>
<li>在这个过程中，老年代和新生代都会扫</li>
<li>总的来说，「初始标记」这个过程还是比较快的，毕竟没有追溯遍历嘛</li>
</ul>
</li>
<li>「并发标记」<ul>
<li>这个阶段不会 Stop The World，GC线程与用户线程一起执行，GC线程负责收集各个 Region的存活对象信息</li>
<li>从 GC Roots往下追溯，査找整个堆存活的对象，比较耗时</li>
</ul>
</li>
<li>「重新标记」<ul>
<li>跟CMS又一样，标记那些在「并发标记」阶段发生变化的对象</li>
<li>CMS在「重新标记」阶段，应该会重新扫描所有的线程栈和整个年轻代作为root,G1不是<ul>
<li>在G1中解決「并发标记」阶段导致引用变更的问题，使用的是SATB算法</li>
<li>可以简单理解为：在GC开始的时候，它为存活的对象做了一次「快照」</li>
<li>在「并发阶段」时，把每一次发生引用关系变化时旧的引用值给记下来</li>
<li>然后在「重新标记」阶段只扫描着块「发生过变化」的引用，看有没有对象还是存活的，加入到「 GC Roots」上</li>
<li>不过SATB算法有个小的问题，就是：如果在开始时，G1就认为它是活的，那就在此次GC中不会对它回收，即便可能在「并发阶段」上对象已经变为了垃圾。</li>
<li>所以，G1也有可能会存在「浮动垃圾」</li>
<li>但是总的来说，对于G1而言，问题不大（毕竟它不是追求一次把所有的垃圾都清除掉，而是注重 Stop The Worlde时间）</li>
</ul>
</li>
</ul>
</li>
<li>「清理」<ul>
<li>这个阶段也是会 Stop The World的，主要清点和重置标记状态，会根据「停顿预模型」（其实就是设定的停顿时间），来决定本次GC回收多少 Region</li>
<li>一般来说， Mixed GC会选定所有的年轻代 Region，部分「回收价值高」的老年代 Region（回收价值高其实就是垃圾多）进行采集</li>
<li>最后 Mixed GC进行清除还是通过「拷贝」&#x2F;「复制」的方式去干的</li>
<li>所以在G1中，一次回收未必是将所有的垃圾进行回收的，G1会依据停顿时间做出选择 Region数量</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="什么时候发生full-GC"><a href="#什么时候发生full-GC" class="headerlink" title="什么时候发生full GC"></a>什么时候发生full GC</h2><ul>
<li>如果在 Mixed GC中无法跟上用户线程分配内存的速度，导致老年代填满无法继续进行 Mixed GC，就又会降级到 serial oldGC来收集整个 GC heap</li>
<li>其实跟CMS是非常类似的都是因为空间不足</li>
<li>不过uGC这个场景相较于CMS还是很少的，毕竟G1没有像CMS「内存碎片」这种问题</li>
</ul>
<h2 id="G1垃圾收集器特点："><a href="#G1垃圾收集器特点：" class="headerlink" title="G1垃圾收集器特点："></a><strong>G1垃圾收集器特点</strong>：</h2><ul>
<li>从原来的「物理」分代，变成现在的「逻辑」分代，将堆内存「逻辑」划分为多个Region</li>
<li>使用CSet来存储可回收Region的集合</li>
<li>使用RSet来处理跨代引用的问题（注意：RSet不保留 年轻代相关的引用关系）</li>
<li>G1可简单分为：Minor GC 和Mixed GC以及Full GC</li>
<li>【Eden区满则触发】Minor GC 回收过程可简单分为：(STW) 扫描 GC Roots、更新&amp;&amp;处理Rset、复制清除</li>
<li>全局并发标记的过程跟CMS过程差不多：初始标记（STW）、并发标记、最终标记（STW）以及清理（STW）</li>
<li>【整堆空间占一定比例则触发】Mixed GC 依赖「全局并发标记」，得到CSet(可回收Region)，就进行「复制清除」</li>
<li>使用SATB算法来处理「并发标记」阶段对象引用存在变更的问题</li>
<li><strong>亮点&amp;&amp;重点</strong>：提供可停顿时间参数供用户设置（<strong>G1会尽量满足该停顿时间来调整 GC时回收Region的数量</strong>）</li>
<li>R大描述G1原理的时候，他提到：从宏观的角度看G1，主要分为两块「<strong>全局并发标记</strong>」和「<strong>拷贝存活对象</strong>」</li>
</ul>

      
    </div>

    
    
    


    <div>
      
    </div>

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>l




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/b8eb8241/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lion.png">
      <meta itemprop="name" content="swimminghao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="swimminghao's blog">
      <meta itemprop="description" content="swimminghao的学习博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | swimminghao's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/b8eb8241/" class="post-title-link" itemprop="url">32、【对线面试官】如何实现幂等和去重？</a>
        </h2>

        <div class="post-meta-container">

          

          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 19:57:47" itemprop="dateCreated datePublished" datetime="2022-02-28T19:57:47+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-03-10 09:48:07" itemprop="dateModified" datetime="2022-03-10T09:48:07+08:00">2022-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">技术</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/posts/b8eb8241/#waline-comments" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" id="/posts/b8eb8241/" data-xid="/posts/b8eb8241/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="如何实现去重和幂等"><a href="#如何实现去重和幂等" class="headerlink" title="如何实现去重和幂等"></a>如何实现去重和幂等</h1><h2 id="去重与幂等"><a href="#去重与幂等" class="headerlink" title="去重与幂等"></a>去重与幂等</h2><ul>
<li>区别<ul>
<li>「去重」是对请求或者消息在「一定时间内」进行去重「N次」</li>
<li>「幂等」则是保证请求或消息在「任意时间内」进行处理，都需要保证它的结果是一致</li>
</ul>
</li>
<li>以项目举例，我维护的「消息管理平台」是有「去重」的功能的：「5分钟相同内容消息去重」「1小时内模板去重」「一天内渠道达到N次阈值去重」.</li>
<li>再次强调下「幂等」和「去重」的本质：「唯一Key」+「存储」</li>
</ul>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><ul>
<li>不同的业务场景，唯一Key是不一样的，由业务決定</li>
<li>存储选择挺多的，比如「本地缓存」&#x2F;「 Redis」&#x2F;「 MYSQL」&#x2F;「 Hbase」等等，具体选取什么，也跟业务有关</li>
<li>比如说，在「消息管理平台」这个场景下，我存储选择的「 Redis」（读写性能优越）， Redis也有「过期时间」方便解决「一定时间内」的问题</li>
<li>而唯一Key，自然就是根据不同的业务构建不同的。</li>
<li>比如说「5分钟相同内容消息去重」，我直接MD5请求参数作为唯一Key。「1小时模板去重」则是「模板ID+ userid」作为唯一Key，「ー天内渠道去重」则是「渠道ID+ userid」作为唯一Key.</li>
</ul>
<h2 id="提到了「去重」了，你听过布隆过滤器吗？"><a href="#提到了「去重」了，你听过布隆过滤器吗？" class="headerlink" title="提到了「去重」了，你听过布隆过滤器吗？"></a>提到了「去重」了，你听过布隆过滤器吗？</h2><ul>
<li>布隆过滤器的底层数据结构可以理解为bitmap， bitmap也可以简单理解为是一个数组，元素只存储0和1，所以它占用的空间相对较小</li>
<li>当一个元素要存入 bitmap时，其实是要去看存储到 bitmap的哪个位置，这时一般用的就是「哈希算法」，存进去的位置标记为1</li>
<li>标记为1的位置表示存在，标记为0的位置标示不存在</li>
<li>布隆过滤器是可以以较低的空间占用来判断元素是否存在进而用于去重，但是它也有对应的缺点</li>
<li>只要使用哈希算法离不开「哈希冲突」，导致有存在「误判」的情况</li>
<li>在布隆过滤器中，如果元素判定为存在，那该元素「未必」真实存在。如果元素判定为不存在，那就肯定是不存在</li>
<li>这应该不用我多解释了吧？（结合「哈希算法」和「标记为1的位置表示存在，标记为0的位置表示不存在」这两者就能得出上面结论）</li>
<li>布隆过滤器也不能「删除」元素（也是哈希算法的局限性，在布隆过滤器中是不能准确定位一个元素的）</li>
<li>如果要用的话，布隆过滤器的实现可以直接上 guava已经实现好的，不过这个是单机的</li>
<li>而分布式下的布隆过滤器，一般现在会用 Redis，但也不是每个公司都会部暑布隆过潓器的 Redis版（还是有局限，像我以前公司就没有）</li>
<li>所以，目前我负责的项目都是没有用布隆过滤器的</li>
</ul>
<h2 id="去重开销大"><a href="#去重开销大" class="headerlink" title="去重开销大"></a>去重开销大</h2><ul>
<li>如果「去重」开销比较大，可以考虑建立「多层过滤」的逻辑</li>
<li>比如，先看看『本地缓存』能不能过滤一部分，剩下「强校验」交由『远程存储』（常见的 Redis或者DB）进行二次过滤</li>
</ul>
<h2 id="kafka场景"><a href="#kafka场景" class="headerlink" title="kafka场景"></a>kafka场景</h2><ul>
<li>当时你说在处理订单时实现了 at least one+幂等</li>
<li>幂等处理时：前置过滤使用的是 Redis，强一致校验时使用的是DB唯一索引，也是为了提高性能，唯一Key好像就是「订单编号+订单状态」</li>
</ul>
<h2 id="方案的场景适用"><a href="#方案的场景适用" class="headerlink" title="方案的场景适用"></a>方案的场景适用</h2><ol>
<li>一般我们需要对数据强一致性校验，就直接上 MYSQL（DB），毕竟有事务的支持</li>
<li>「本地缓存」如果业务适合，那可以作为一个「前置」判断</li>
<li>Redis高性能读写，前置判断和后置均可</li>
<li>而 Hbasel则一般用于庞大数据量的场景下（ Redis内存太贵，DB不够灵活也不适合单表存大量数据）</li>
</ol>
<h2 id="幂等"><a href="#幂等" class="headerlink" title="幂等"></a>幂等</h2><ul>
<li>至于幂等，一般的方案下存储还是「Redis」和「数据库」</li>
<li>最最最最常见的就是数据库「唯一索」来实现幂等（我所负责的好几个项目都是用这个）</li>
<li>构建「唯一Key」是业务相关的事了（一般是用自己的业务ID进行拼接，生成一个有意义”的唯一Key</li>
<li>当然，也有用「 Redis」和「 MYSQL」实现分布式锁来实现幂等的（：）</li>
<li>但 Redis’分布式锁是不能完全保证安全的，而MNSL实现分布式锁（乐观锁和悲观锁），不过还是看业务吧，我是没用到过的</li>
<li>网上有很多实现「幂等」的方案，本质上都是围绕着「存储」和「唯一Key」做了些变种，然后取了个名字</li>
</ul>

      
    </div>

    
    
    


    <div>
      
    </div>

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>l




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/63b182f/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lion.png">
      <meta itemprop="name" content="swimminghao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="swimminghao's blog">
      <meta itemprop="description" content="swimminghao的学习博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | swimminghao's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/63b182f/" class="post-title-link" itemprop="url">33、【对线面试官】Redis主从架构</a>
        </h2>

        <div class="post-meta-container">

          

          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 19:57:47" itemprop="dateCreated datePublished" datetime="2022-02-28T19:57:47+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-03-10 09:48:07" itemprop="dateModified" datetime="2022-03-10T09:48:07+08:00">2022-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">技术</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/posts/63b182f/#waline-comments" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" id="/posts/63b182f/" data-xid="/posts/63b182f/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="33、【对线面试官】Redis主从架构"><a href="#33、【对线面试官】Redis主从架构" class="headerlink" title="33、【对线面试官】Redis主从架构"></a>33、【对线面试官】Redis主从架构</h1><h2 id="要不你来讲讲你公司的Redis是什么架构的咯？"><a href="#要不你来讲讲你公司的Redis是什么架构的咯？" class="headerlink" title="要不你来讲讲你公司的Redis是什么架构的咯？"></a>要不你来讲讲你公司的Redis是什么架构的咯？</h2><ul>
<li>我前公司的Redis架构是「分片集群」，使用的是「Proxy」层来对Key进行分流到不同的Redis服务器上</li>
<li>支持动态扩容、故障恢复等等…</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/exJQS5_20211229222731.png"></p>
<h2 id="那你来聊下Proxy-层的架构和基本实现原理？"><a href="#那你来聊下Proxy-层的架构和基本实现原理？" class="headerlink" title="那你来聊下Proxy.层的架构和基本实现原理？"></a>那你来聊下Proxy.层的架构和基本实现原理？</h2><ul>
<li><p>抱歉，这块由中间件团队负责，具体我也没仔细看过</p>
</li>
<li><p>不过，我可以给你讲讲现有常见开源的Redis架构</p>
<ul>
<li><p>在之前提到了Redis有持久化机制，即便Redis重启了，可以依靠RDB或者AOF文件对数据进行重新加载</p>
</li>
<li><p>但在这时，只有一台Redis服务器存储着所有的数据，此时如果Redis服务器「暂时」没办法修复了，那依赖Redis的服务就没了</p>
</li>
<li><p>所以，为了Redis「高可用」，现在基本都会给Redis做「备份」：多启一台Redis服务器，形成「主从架构」</p>
</li>
<li><p>「从服务器」的数据由「主服务器」复制过去，主从服务器的数据是一致的</p>
</li>
<li><p>如果主服务器挂了，那可以「手动」把「从服务器」升级为「主服务器」，缩短不可用时间</p>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/jCY34w_20211229225726.png"></p>
</li>
</ul>
</li>
</ul>
<h2 id="那「主服务器」是如何把自身的数据「复制」给「从服务器」的呢？"><a href="#那「主服务器」是如何把自身的数据「复制」给「从服务器」的呢？" class="headerlink" title="那「主服务器」是如何把自身的数据「复制」给「从服务器」的呢？"></a>那「主服务器」是如何把自身的数据「复制」给「从服务器」的呢？</h2><ul>
<li>「复制」也叫「同步」，在Redis使用的是「PSYNC」命令进行同步，该命令有两种模型：完全重同步和部分重同步</li>
<li>可以简单理解为：如果是第一次「同步」，从服务器没有复制过任何的主服务器，或者从服务器要复制的主服务器跟上次复制的主服务器不一样，那就会采用「完全重同步」模式进行复制</li>
<li>如果只是由于网络中断，只是「短时间」断连，那就会采用「部分重同步」模式进行复制</li>
<li>（假如主从服务器的数据差距实在是过大了，还是会采用「完全重同步」模式进行复制）</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/8nL2eT_20211229225855.png"></p>
<h2 id="同步原理"><a href="#同步原理" class="headerlink" title="同步原理"></a>同步原理</h2><ul>
<li><p>主服务器要复制数据到从服务器，首先是建立Socket「连接」，这个过程会干一些信息校验啊、身份校验啊等事情</p>
</li>
<li><p>然后从服务器就会发「PSYNC」命令给主服务器，要求同步（这时会带「服务器ID」RUNID和「复制进度」offset参数。如果从服务器是新的，那就没有）</p>
</li>
<li><p>主服务器发现这是一个新的从服务器（因为参数没带上来），就会采用「完全重同步」模式，并把「服务器ID」（runld）和「复制进度」（offset）发给从服务器，从服务器就会记下这些信息。</p>
</li>
<li><p>随后，主服务器会在后台生成RDB文件，通过前面建立好的连接发给从服务器从服务器收到RDB文件后，首先把自己的数据清空，然后对RDB文件进行加载恢复</p>
</li>
<li><p>这个过程中，主服务器也没闲着（继续接收着客户端的请求）</p>
</li>
<li><p>主服务器把生成RDB文件「之后修改的命令」会用「ouffer.」记录下来，等到从服务器加载完RDB之后，主服务器会把「buffer.」记录下的命令都发给从服务器</p>
</li>
<li><p>这样一来，主从服务器就达到了数据一致性了（复制过程是异步的，所以数据是『最终一致性』）</p>
</li>
</ul>
<h2 id="那「部分重同步」的过程呢？"><a href="#那「部分重同步」的过程呢？" class="headerlink" title="那「部分重同步」的过程呢？"></a>那「部分重同步」的过程呢？</h2><ul>
<li><p>嗯，其实就是靠「offset」来进行部分重同步。每次主服务器传播命令的时候，都会把「offset」给到从服务器</p>
</li>
<li><p>主服务器和从服务器都会将「offset」保存起来（如果两边的offset存在差异，那么说明主从服务器数据未完全同步）</p>
</li>
<li><p>从服务器断连之后进行重连，就会发「PSYNC」命令给主服务器，同样也会带着RUNID和offset（重连之后，这些信息还是存在的）</p>
</li>
<li><p>主服务器收到命令之后，看RUNID是否能对得上，对得上，说明这可能以前就同步过一部分了</p>
</li>
<li><p>接着检查该「offset在主服务器里还是否存在（主服务器记录主从服务器offset的信息用的是环形buffer，如果该ouffer）满了，会覆盖以前的记录。而记录客户端的修改命令用的是另一个buffer）</p>
</li>
<li><p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/4mdp0i_20211229230139.png"></p>
</li>
<li><p>如果从backlog_buffer找到了，那就把从缺失的一部分offer开始，把对应的修改命令发给从服务器</p>
</li>
<li><p>如果从环形ouffer（backlog._buffer）没找到，那只能使用「完全重同步」模式再次进行主从复制了</p>
<ul>
<li><p>懂了，无非就是有个关联关系记录下来，只不过存储是环形（可能会造成覆盖）</p>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/oGR8JD_20211229230354.png"></p>
</li>
</ul>
</li>
</ul>
<h2 id="Redis主库如果挂了，你还是得「手动」将从库升级为主库啊？你知道有什么办法能做到「自动」进行故障恢复吗？"><a href="#Redis主库如果挂了，你还是得「手动」将从库升级为主库啊？你知道有什么办法能做到「自动」进行故障恢复吗？" class="headerlink" title="Redis主库如果挂了，你还是得「手动」将从库升级为主库啊？你知道有什么办法能做到「自动」进行故障恢复吗？"></a>Redis主库如果挂了，你还是得「手动」将从库升级为主库啊？你知道有什么办法能做到「自动」进行故障恢复吗？</h2><ul>
<li><p>哨兵</p>
<ul>
<li><p>「哨兵」干的事情主要就是：监控（监控主服务器的状态）、选主（主服务器挂了，在从服务器选出一个作为主服务器）、通知（故障发送消息给管理员）和配置（作为配置中心，提供当前主服务器的信息）</p>
</li>
<li><p>可以把「哨兵」当做是运行在「特殊」模式下的Redis服务器，为了「高可用」，哨兵也是集群架构的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/swimminghao/picture@main/img/iPv3vB_20211229230508.png"></p>
</li>
<li><p>首先它需要跟Redis主从服务器创建对应的连接（获取它们的信息）</p>
</li>
<li><p>每个哨兵不断地用ping命令看主服务器有没有下线，如果主服务器在「配置时间」内没有正常响应，那当前哨兵就「主观」认为该主服务器下线了</p>
</li>
<li><p>其他「哨兵」同样也会ping该主服务器，如果「足够多」（还是看配置）的哨兵认为该主服务器已经下线，那就认为「客观下线」，这时就要对主服务器执行故障转移操作。</p>
</li>
<li><p>「哨兵」之间会选出一个「领头」，选出领头的规则也比较多，总的来说就是先到先得（哪个快，就选哪个）</p>
</li>
<li><p>由「领头哨兵」对已下线的主服务器进行故障转移</p>
<ul>
<li>过程<ul>
<li>首先要在「从服务器」上挑选出一个，来作为主服务器</li>
<li>（这里也挑选讲究，比如：从库的配置优先级、要判断哪个从服务器的复制offset最大、RunID大小、跟master断开连接的时长…）</li>
<li>然后，以前的从服务器都需要跟新的主服务器进行「主从复制」</li>
<li>已经下线的主服务器，再次重连的时候，需要让他成为新的主服务器的从服务器</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="了解，我想问问，Redis在主从复制和故障转移的过程中会导致数据丢失吗"><a href="#了解，我想问问，Redis在主从复制和故障转移的过程中会导致数据丢失吗" class="headerlink" title="了解，我想问问，Redis在主从复制和故障转移的过程中会导致数据丢失吗"></a>了解，我想问问，Redis在主从复制和故障转移的过程中会导致数据丢失吗</h2><ul>
<li><p>会的</p>
<ul>
<li><p>1）从上面的「主从复制」流程来看，这个过程是异步的（在复制的过程中：主服务器会一直接收请求，然后把修改命令发给从服务器）</p>
</li>
<li><p>假如主服务器的命令还没发完给从服务器，自己就挂掉了。这时候想要让从服务器顶上主服务器，但从服务器的数据是不全的</p>
</li>
<li><p>2）还有另一种情况就是：有可能哨兵认为主服务器挂了，但真实是主服务器并没有挂（网络抖动），而哨兵已经选举了一台从服务器当做是主服务器了，此时「客户端」还没反应过来，还继续写向旧主服务器写数据</p>
</li>
<li><p>等到旧主服务器重连的时候，已经被纳入到新主服务器的从服务器了…所以，那段时间里，客户端写进旧主服务器的数据就丢了</p>
</li>
</ul>
</li>
<li><p>上面这两种情况（主从复制延迟&amp;&amp;脑裂），都可以通过配置来「尽可能」避免数据的丢失</p>
</li>
<li><p>（达到一定的阈值，直接禁止主服务器接收写请求，企图减少数据丢失的风险）</p>
</li>
</ul>
<h2 id="要不再来聊聊Redis分片集群？"><a href="#要不再来聊聊Redis分片集群？" class="headerlink" title="要不再来聊聊Redis分片集群？"></a>要不再来聊聊Redis分片集群？</h2><ul>
<li>分片集群就是往每个Redis服务器存储一部分数据，所有的Redis服务器数据加起来，才组成完整的数据（分布式）</li>
<li>要想组成分片集群，那就需要对key进行「路由」（分片）<ul>
<li>现在一般的路由方案有两种：「客户端路由」（SDK）和「服务端路由」（Proxy）</li>
<li>客户端路由的代表（Redis Cluster），服务端路由的代表（Codis）</li>
<li>区别？</li>
</ul>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>Redis实现高可用</strong>：</p>
<ul>
<li>AOF&#x2F;RDB持久化机制</li>
<li>主从架构（主服务器挂了，手动由从服务器顶上）</li>
<li>引入哨兵机制自动故障转义</li>
</ul>
<p><strong>主从复制原理</strong>：</p>
<ul>
<li>PSYNC命令两种模式：完全重同步、部分重同步</li>
<li>完全重同步：主从服务器建立连接、主服务器生成RDB文件发给从服务器、主服务器不阻塞（相关修改命令记录至buffer）、将修改命令发给从服务器</li>
<li>部分重同步：从服务器断线重连，发送RunId和offset给主服务器，主服务器判断offset和runId，将还未同步给从服务器的offset相关指令进行发送</li>
</ul>
<p><strong>哨兵机制</strong>：</p>
<ul>
<li>哨兵可以理解为特殊的Redis服务器，一般会组成哨兵集群</li>
<li>哨兵主要工作是监控、告警、配置以及选主</li>
<li>当主服务器发生故障时，会「选出」一台从服务器来顶上「客观下线」的服务器，由「领头哨兵」进行切换</li>
</ul>
<p><strong>数据丢失</strong>：</p>
<ul>
<li>Redis的主从复制和故障转移阶段都有可能发生数据丢失问题（通过配置尽可能避免）</li>
</ul>

      
    </div>

    
    
    


    <div>
      
    </div>

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>l




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/9/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/11/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">swimminghao</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">971k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">14:43</span>
  </span>
</div>

<span id="sitetime"></span>
<script language=javascript>
    function siteTime(){
        window.setTimeout("siteTime()", 1000);
        var seconds = 1000;
        var minutes = seconds * 60;
        var hours = minutes * 60;
        var days = hours * 24;
        var years = days * 365;
        var today = new Date();
        var todayYear = today.getFullYear();
        var todayMonth = today.getMonth()+1;
        var todayDate = today.getDate();
        var todayHour = today.getHours();
        var todayMinute = today.getMinutes();
        var todaySecond = today.getSeconds();
        /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
        year - 作为date对象的年份，为4位年份值
        month - 0-11之间的整数，做为date对象的月份
        day - 1-31之间的整数，做为date对象的天数
        hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
        minutes - 0-59之间的整数，做为date对象的分钟数
        seconds - 0-59之间的整数，做为date对象的秒数
        microseconds - 0-999之间的整数，做为date对象的毫秒数 */
        var t1 = Date.UTC(2022,02,28,00,00,00); //你的建站时间
        var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
        var diff = t2-t1;
        var diffYears = Math.floor(diff/years);
        var diffDays = Math.floor((diff/days)-diffYears*365);
        var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
        var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
        var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
        document.getElementById("sitetime").innerHTML=" 本站已安全运行 "+diffYears+" Year "+diffDays+" Days "+diffHours+" Hours "+diffMinutes+" m "+diffSeconds+" s";
    }
    siteTime();
</script>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        访问人数：<span id="busuanzi_value_site_uv"></span>
      </span>人
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
       访问总量：<span id="busuanzi_value_site_pv"></span>
      </span>次
    </span>


<!--
  本文总阅读量：<span id="busuanzi_value_page_pv"></span>次
-->

</div>


<!--
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

--><script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-cn","enable":true,"serverURL":"waline-server-nu.vercel.app","placeholder":"请文明评论呀","avatar":"mm","pageSize":10,"visitor":false,"comment_count":true,"requiredFields":[],"meta":["nick","mail","link"],"libUrl":"https://cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js","el":"#waline-comments","path":"/page/10/"}</script>
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() => 
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => {
    new Waline(CONFIG.waline);
  });
});
</script>
  <script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.js"></script>
  <script>
      pbOptions = {};
        pbOptions.iconStyle = "default";
        pbOptions.boxForm = "horizontal";
        pbOptions.position = "middleCenter";
        pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      new needShareButton('#needsharebutton-postbottom', pbOptions);
  </script>
</body>
</html>
